{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\*\\*\\* Note! This notebook is a repost, I made the original private after some ensembling and postprocessing steps put it into the top 10 on the leaderboard. Kaggle doesn't allow specific versions of a notebook to be made private and I didn't think a top 10 solution should be shared \\*\\*\\*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook constructs a prediction model for the Predict Future Sales competition that is the final project for the Coursera course \"[How to Win a Data Science Competition](http://www.coursera.org/learn/competitive-data-science/home/welcome)\". The task is to predict monthly sales for various items in different retail outlets of the Russian company 1C.  \n",
    "\n",
    "I spent several months on this as practice using pandas, so some parts are a bit more complicated than might be expected of a typical short project submission.\n",
    "\n",
    "There are some other very good notebooks for this competition which are well worth looking at and taught me a lot:\n",
    "https://www.kaggle.com/dlarionov/feature-engineering-xgboost  \n",
    "https://www.kaggle.com/gordotron85/future-sales-xgboost-top-3  \n",
    "https://www.kaggle.com/deepdivelm/feature-engineering-lightgbm-exploring-performance  \n",
    "\n",
    "This is the top-scoring public notebook at the time of writing (0.84325, place 51 on the public leaderboard), which is mainly because of two novel feature types which work well when combined together. First, there is an item name group feature that groups together items with very similar names that are likely to refer to different versions of the same item (e.g. different editions of the same game or music album). Second, the way the test set was generated was exploited to count how many items sold in the month being predicted were in the same group as the item being predicted (e.g. same category, same name group). This combines well with the item name group feature to detect new items which are part of large multi-format releases that are likely to sell well. Detecting high-selling new items is one of the hardest challenges for the model in this competition (and has to be performed manually to get a really high score, I think).\n",
    "\n",
    "I hope you find the notebook interesting, and I welcome feedback - suggestions for improvements, advice about parts that are unclear, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.053912,
     "end_time": "2021-04-28T18:11:27.348187",
     "exception": false,
     "start_time": "2021-04-28T18:11:27.294275",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data loading and preprocessing, utility function definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.049686,
     "end_time": "2021-04-28T18:11:27.448493",
     "exception": false,
     "start_time": "2021-04-28T18:11:27.398807",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Imports and data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "papermill": {
     "duration": 1.032316,
     "end_time": "2021-04-28T18:11:28.530522",
     "exception": false,
     "start_time": "2021-04-28T18:11:27.498206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few utility functions used throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, silent=True, allow_categorical=True, float_dtype=\"float32\"):\n",
    "    \"\"\" \n",
    "    Iterates through all the columns of a dataframe and downcasts the data type\n",
    "     to reduce memory usage. Can also factorize categorical columns to integer dtype.\n",
    "    \"\"\"\n",
    "    def _downcast_numeric(series, allow_categorical=allow_categorical):\n",
    "        \"\"\"\n",
    "        Downcast a numeric series into either the smallest possible int dtype or a specified float dtype.\n",
    "        \"\"\"\n",
    "        if pd.api.types.is_sparse(series.dtype) is True:\n",
    "            return series\n",
    "        elif pd.api.types.is_numeric_dtype(series.dtype) is False:\n",
    "            if pd.api.types.is_datetime64_any_dtype(series.dtype):\n",
    "                return series\n",
    "            else:\n",
    "                if allow_categorical:\n",
    "                    return series\n",
    "                else:\n",
    "                    codes, uniques = series.factorize()\n",
    "                    series = pd.Series(data=codes, index=series.index)\n",
    "                    series = _downcast_numeric(series)\n",
    "                    return series\n",
    "        else:\n",
    "            series = pd.to_numeric(series, downcast=\"integer\")\n",
    "        if pd.api.types.is_float_dtype(series.dtype):\n",
    "            series = series.astype(float_dtype)\n",
    "        return series\n",
    "\n",
    "    if silent is False:\n",
    "        start_mem = np.sum(df.memory_usage()) / 1024 ** 2\n",
    "        print(\"Memory usage of dataframe is {:.2f} MB\".format(start_mem))\n",
    "    if df.ndim == 1:\n",
    "        df = _downcast_numeric(df)\n",
    "    else:\n",
    "        for col in df.columns:\n",
    "            df.loc[:, col] = _downcast_numeric(df.loc[:,col])\n",
    "    if silent is False:\n",
    "        end_mem = np.sum(df.memory_usage()) / 1024 ** 2\n",
    "        print(\"Memory usage after optimization is: {:.2f} MB\".format(end_mem))\n",
    "        print(\"Decreased by {:.1f}%\".format(100 * (start_mem - end_mem) / start_mem))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def shrink_mem_new_cols(matrix, oldcols=None, allow_categorical=False):\n",
    "    # Calls reduce_mem_usage on columns which have not yet been optimized\n",
    "    if oldcols is not None:\n",
    "        newcols = matrix.columns.difference(oldcols)\n",
    "    else:\n",
    "        newcols = matrix.columns\n",
    "    matrix.loc[:,newcols] = reduce_mem_usage(matrix.loc[:,newcols], allow_categorical=allow_categorical)\n",
    "    oldcols = matrix.columns  # This is used to track which columns have already been downcast\n",
    "    return matrix, oldcols\n",
    "\n",
    "\n",
    "def list_if_not(s, dtype=str):\n",
    "    # Puts a variable in a list if it is not already a list\n",
    "    if type(s) not in (dtype, list):\n",
    "        raise TypeError\n",
    "    if (s != \"\") & (type(s) is not list):\n",
    "        s = [s]\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.049382,
     "end_time": "2021-04-28T18:11:28.630332",
     "exception": false,
     "start_time": "2021-04-28T18:11:28.58095",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Load the provided data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "papermill": {
     "duration": 3.762579,
     "end_time": "2021-04-28T18:11:32.444498",
     "exception": false,
     "start_time": "2021-04-28T18:11:28.681919",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "items = pd.read_csv(\"items.csv.zip\")\n",
    "shops = pd.read_csv(\"shops.csv\")\n",
    "train = pd.read_csv(\"sales_train.csv.zip\")#, parse_dates=['date'])\n",
    "test = pd.read_csv(\"test.csv.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the date column to the datetime dtype to enable datetime operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "papermill": {
     "duration": 3.762579,
     "end_time": "2021-04-28T18:11:32.444498",
     "exception": false,
     "start_time": "2021-04-28T18:11:28.681919",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train[\"date\"] = pd.to_datetime(train[\"date\"], format=\"%d.%m.%Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.049628,
     "end_time": "2021-04-28T18:11:32.545881",
     "exception": false,
     "start_time": "2021-04-28T18:11:32.496253",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.048834,
     "end_time": "2021-04-28T18:11:32.643753",
     "exception": false,
     "start_time": "2021-04-28T18:11:32.594919",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The training dataframe is cleaned with standard steps  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge some duplicate shops\n",
    "train[\"shop_id\"] = train[\"shop_id\"].replace({0: 57, 1: 58, 11: 10, 40: 39})\n",
    "# Keep only shops that are in the test set\n",
    "train = train.loc[train.shop_id.isin(test[\"shop_id\"].unique()), :]\n",
    "\n",
    "# Drop training items with extreme or negative sale counts\n",
    "train = train[(train[\"item_cnt_day\"] > 0) & (train[\"item_cnt_day\"] < 1000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix wrong prices\n",
    "\n",
    "Some of prices may be wrong. Let's find them. At first we look for prices with big difference between min and max price for each item and find the most frequent normal prices for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# For each item get price with mode value > 5\n",
    "def amode(col):\n",
    "    i = 0\n",
    "    res = 0\n",
    "    count = col.value_counts().index\n",
    "    while res <= 5 and i < len(count):\n",
    "        res = count[i]\n",
    "        i += 1\n",
    "    return res\n",
    "\n",
    "def alast(col):\n",
    "    return res\n",
    "    \n",
    "# Group train dataset by prices, aggregate by price mode\n",
    "item_prices = train[['item_id', 'item_price']].groupby('item_id').agg({'item_price': [np.min, \n",
    "                                                                                      np.max, \n",
    "                                                                                      amode]})\n",
    "# Add feature for difference between min and max prices\n",
    "item_prices['price_diff'] = abs(item_prices.item_price.amax/item_prices.item_price.amin)\n",
    "\n",
    "# Get all prices with the difference between min and max prices more than 15 and min price less than 5\n",
    "# Save indexes of these prices\n",
    "wrong_prices = item_prices[(item_prices.item_price.amin <= 5) & \n",
    "                           (item_prices.price_diff >= 15)].sort_values('price_diff', ascending=False)\n",
    "\n",
    "wrong_prices.head()\n",
    "\n",
    "for i_id in list(wrong_prices.index):\n",
    "    train.loc[(train.item_id == i_id) & \n",
    "              (train.item_price <= 5), 'item_price'] = wrong_prices.loc[i_id, 'item_price'].amode\n",
    "    \n",
    "del wrong_prices\n",
    "gc.collect()\n",
    "\n",
    "# Also drop training items with extreme or negative prices\n",
    "train = train[(train[\"item_price\"] > 0) & (train[\"item_price\"] < 50000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.053208,
     "end_time": "2021-04-28T18:11:34.280403",
     "exception": false,
     "start_time": "2021-04-28T18:11:34.227195",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.050656,
     "end_time": "2021-04-28T18:11:34.384271",
     "exception": false,
     "start_time": "2021-04-28T18:11:34.333615",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The test data seems to be every possible combination (the cartesian product) of shops and items that registered a sale in the test month, with the target as the total month's sales made for each of these shop-item combinations. Here a training matrix is made that replicates this structure for every month in the training data period. The test items are concatenated to the end of the training data so that features can be generated for the test period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "papermill": {
     "duration": 0.065775,
     "end_time": "2021-04-28T18:11:34.500373",
     "exception": false,
     "start_time": "2021-04-28T18:11:34.434598",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_testlike_train(sales_train, test=None):\n",
    "    indexlist = []\n",
    "    for i in sales_train.date_block_num.unique():\n",
    "        x = itertools.product(\n",
    "            [i],\n",
    "            sales_train.loc[sales_train.date_block_num == i].shop_id.unique(),\n",
    "            sales_train.loc[sales_train.date_block_num == i].item_id.unique(),\n",
    "        )\n",
    "        indexlist.append(np.array(list(x)))\n",
    "    df = pd.DataFrame(\n",
    "        data=np.concatenate(indexlist, axis=0),\n",
    "        columns=[\"date_block_num\", \"shop_id\", \"item_id\"],\n",
    "    )\n",
    "\n",
    "    # Add revenue column to sales_train\n",
    "    sales_train[\"item_revenue_day\"] = sales_train[\"item_price\"] * sales_train[\"item_cnt_day\"]\n",
    "    # Aggregate item_id / shop_id item_cnts and revenue at the month level\n",
    "    sales_train_grouped = sales_train.groupby([\"date_block_num\", \"shop_id\", \"item_id\"]).agg(\n",
    "        item_cnt_month=pd.NamedAgg(column=\"item_cnt_day\", aggfunc=\"sum\"),\n",
    "        item_revenue_month=pd.NamedAgg(column=\"item_revenue_day\", aggfunc=\"sum\"),\n",
    "    )\n",
    "\n",
    "    # Merge the grouped data with the index\n",
    "    df = df.merge(\n",
    "        sales_train_grouped, how=\"left\", on=[\"date_block_num\", \"shop_id\", \"item_id\"],\n",
    "    )\n",
    "\n",
    "    if test is not None:\n",
    "        test[\"date_block_num\"] = 34\n",
    "        test[\"date_block_num\"] = test[\"date_block_num\"].astype(np.int8)\n",
    "        test[\"shop_id\"] = test.shop_id.astype(np.int8)\n",
    "        test[\"item_id\"] = test.item_id.astype(np.int16)\n",
    "        test = test.drop(columns=\"ID\")\n",
    "\n",
    "        df = pd.concat([df, test[[\"date_block_num\", \"shop_id\", \"item_id\"]]])\n",
    "\n",
    "    # Fill empty item_cnt entries with 0\n",
    "    df.item_cnt_month = df.item_cnt_month.fillna(0)\n",
    "    df.item_revenue_month = df.item_revenue_month.fillna(0)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "papermill": {
     "duration": 23.143354,
     "end_time": "2021-04-28T18:11:57.693556",
     "exception": false,
     "start_time": "2021-04-28T18:11:34.550202",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "matrix = create_testlike_train(train, test)\n",
    "del(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function reduce_mem_usage downcasts datatypes to reduce memory usage, which is necessary to prevent memory overflow errors in the Kaggle notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "papermill": {
     "duration": 23.143354,
     "end_time": "2021-04-28T18:11:57.693556",
     "exception": false,
     "start_time": "2021-04-28T18:11:34.550202",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 405.44 MB\n",
      "Memory usage after optimization is: 152.04 MB\n",
      "Decreased by 62.5%\n"
     ]
    }
   ],
   "source": [
    "matrix = reduce_mem_usage(matrix, silent=False)\n",
    "oldcols = matrix.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.051209,
     "end_time": "2021-04-28T18:11:57.796356",
     "exception": false,
     "start_time": "2021-04-28T18:11:57.745147",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Feature engineering  \n",
    "In this section predictor feature columns are generated and added to the matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.050933,
     "end_time": "2021-04-28T18:11:57.90026",
     "exception": false,
     "start_time": "2021-04-28T18:11:57.849327",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Item name groups with fuzzywuzzy\n",
    "\n",
    "Items in the items table are ordered alphabetically according to the item_name field, so that similar items are generally listed next to each other. For example, the first two items in the table below are the same game \"Fuse\" for two different consoles, followed by two different licensing options for the same internet security program. This ordering can be used to help group related items together.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "papermill": {
     "duration": 0.079826,
     "end_time": "2021-04-28T18:11:58.030271",
     "exception": false,
     "start_time": "2021-04-28T18:11:57.950445",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_name</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3565</th>\n",
       "      <td>Fuse [PS3, английская версия]</td>\n",
       "      <td>3565</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3566</th>\n",
       "      <td>Fuse [Xbox 360, английская версия]</td>\n",
       "      <td>3566</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3567</th>\n",
       "      <td>G Data Internet Security 2013 (1ПК / 1 год) (G...</td>\n",
       "      <td>3567</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3568</th>\n",
       "      <td>G Data Internet Security 2013 (3ПК / 1 год) (G...</td>\n",
       "      <td>3568</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3569</th>\n",
       "      <td>GABIN  The Best Of Gabin  2CD</td>\n",
       "      <td>3569</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              item_name  item_id  \\\n",
       "3565                      Fuse [PS3, английская версия]     3565   \n",
       "3566                 Fuse [Xbox 360, английская версия]     3566   \n",
       "3567  G Data Internet Security 2013 (1ПК / 1 год) (G...     3567   \n",
       "3568  G Data Internet Security 2013 (3ПК / 1 год) (G...     3568   \n",
       "3569                      GABIN  The Best Of Gabin  2CD     3569   \n",
       "\n",
       "      item_category_id  \n",
       "3565                19  \n",
       "3566                23  \n",
       "3567                76  \n",
       "3568                76  \n",
       "3569                55  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items.query(\"item_id>3564\").head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell groups similar items together by sequentially looping through items, measuring the similarity of the names of ajacent items using the string matching package fuzzywuzzy (https://github.com/seatgeek/fuzzywuzzy), and assigning items to the same group if their match value is above a threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "papermill": {
     "duration": 10.183104,
     "end_time": "2021-04-28T18:12:08.265598",
     "exception": false,
     "start_time": "2021-04-28T18:11:58.082494",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "\n",
    "def add_item_name_groups(matrix, train, items, sim_thresh, feature_name=\"item_name_group\"):\n",
    "    def partialmatchgroups(items, sim_thresh=sim_thresh):\n",
    "        def strip_brackets(string):\n",
    "            string = re.sub(r\"\\(.*?\\)\", \"\", string)\n",
    "            string = re.sub(r\"\\[.*?\\]\", \"\", string)\n",
    "            return string\n",
    "\n",
    "        items = items.copy()\n",
    "        items[\"nc\"] = items.item_name.apply(strip_brackets)\n",
    "        items[\"ncnext\"] = np.concatenate((items[\"nc\"].to_numpy()[1:], np.array([\"\"])))\n",
    "\n",
    "        def partialcompare(s):\n",
    "            return fuzz.partial_ratio(s[\"nc\"], s[\"ncnext\"])\n",
    "\n",
    "        items[\"partialmatch\"] = items.apply(partialcompare, axis=1)\n",
    "        # Assign groups\n",
    "        grp = 0\n",
    "        for i in range(items.shape[0]):\n",
    "            items.loc[i, \"partialmatchgroup\"] = grp\n",
    "            if items.loc[i, \"partialmatch\"] < sim_thresh:\n",
    "                grp += 1\n",
    "        items = items.drop(columns=[\"nc\", \"ncnext\", \"partialmatch\"])\n",
    "        return items\n",
    "\n",
    "    items = partialmatchgroups(items)\n",
    "    items = items.rename(columns={\"partialmatchgroup\": feature_name})\n",
    "    items = items.drop(columns=\"partialmatchgroup\", errors=\"ignore\")\n",
    "\n",
    "    items[feature_name] = items[feature_name].apply(str)\n",
    "    items[feature_name] = items[feature_name].factorize()[0]\n",
    "    matrix = matrix.merge(items[[\"item_id\", feature_name]], on=\"item_id\", how=\"left\")\n",
    "    train = train.merge(items[[\"item_id\", feature_name]], on=\"item_id\", how=\"left\")\n",
    "    return matrix, train\n",
    "\n",
    "\n",
    "matrix, train = add_item_name_groups(matrix, train, items, 65)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.050709,
     "end_time": "2021-04-28T18:12:08.36996",
     "exception": false,
     "start_time": "2021-04-28T18:12:08.319251",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Music artist / first word of item name  \n",
    "\n",
    "This function assigns music items into groups according to the artist name, which is extracted from the item name with regular expressions according to 3 common patterns used to indicate the artist name (all uppercase, separated from the release title by a doublespace, or separated by dot-space (. ).  \n",
    "For non-music categories, the items are grouped according to the first word in the item name instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "papermill": {
     "duration": 2.989192,
     "end_time": "2021-04-28T18:12:11.411023",
     "exception": false,
     "start_time": "2021-04-28T18:12:08.421831",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "def add_first_word_features(matrix, items=items, feature_name=\"artist_name_or_first_word\"):\n",
    "    # This extracts artist names for music categories and adds them as a feature.\n",
    "    def extract_artist(st):\n",
    "        st = st.strip()\n",
    "        if st.startswith(\"V/A\"):\n",
    "            artist = \"V/A\"\n",
    "        elif st.startswith(\"СБ\"):\n",
    "            artist = \"СБ\"\n",
    "        else:\n",
    "            # Retrieves artist names using the double space or all uppercase pattern\n",
    "            mus_artist_dubspace = re.compile(r\".{2,}?(?=\\s{2,})\")\n",
    "            match_dubspace = mus_artist_dubspace.match(st)\n",
    "            mus_artist_capsonly = re.compile(r\"^([^a-zа-я]+\\s)+\")\n",
    "            match_capsonly = mus_artist_capsonly.match(st)\n",
    "            candidates = [match_dubspace, match_capsonly]\n",
    "            candidates = [m[0] for m in candidates if m is not None]\n",
    "            # Sometimes one of the patterns catches some extra words so choose the shortest one\n",
    "            if len(candidates):\n",
    "                artist = min(candidates, key=len)\n",
    "            else:\n",
    "                # If neither of the previous patterns found something, use the dot-space pattern\n",
    "                mus_artist_dotspace = re.compile(r\".{2,}?(?=\\.\\s)\")\n",
    "                match = mus_artist_dotspace.match(st)\n",
    "                if match:\n",
    "                    artist = match[0]\n",
    "                else:\n",
    "                    artist = \"\"\n",
    "        artist = artist.upper()\n",
    "        artist = re.sub(r\"[^A-ZА-Я ]||\\bTHE\\b\", \"\", artist)\n",
    "        artist = re.sub(r\"\\s{2,}\", \" \", artist)\n",
    "        artist = artist.strip()\n",
    "        return artist\n",
    "\n",
    "    items = items.copy()\n",
    "    all_stopwords = stopwords.words(\"russian\")\n",
    "    all_stopwords = all_stopwords + stopwords.words(\"english\")\n",
    "\n",
    "    def first_word(string):\n",
    "        # This cleans the string of special characters, excess spaces and stopwords then extracts the first word\n",
    "        string = re.sub(r\"[^\\w\\s]\", \"\", string)\n",
    "        string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "        tokens = string.lower().split()\n",
    "        tokens = [t for t in tokens if t not in all_stopwords]\n",
    "        token = tokens[0] if len(tokens) > 0 else \"\"\n",
    "        return token\n",
    "\n",
    "    music_categories = [55, 56, 57, 58, 59, 60]\n",
    "    items.loc[items.item_category_id.isin(music_categories), feature_name] = items.loc[\n",
    "        items.item_category_id.isin(music_categories), \"item_name\"\n",
    "    ].apply(extract_artist)\n",
    "    items.loc[items[feature_name] == \"\", feature_name] = \"other music\"\n",
    "    items.loc[~items.item_category_id.isin(music_categories), feature_name] = items.loc[\n",
    "        ~items.item_category_id.isin(music_categories), \"item_name\"\n",
    "    ].apply(first_word)\n",
    "    items.loc[items[feature_name] == \"\", feature_name] = \"other non-music\"\n",
    "    items[feature_name] = items[feature_name].factorize()[0]\n",
    "    matrix = matrix.merge(items[[\"item_id\", feature_name]], on=\"item_id\", how=\"left\",)\n",
    "    return matrix\n",
    "\n",
    "\n",
    "matrix = add_first_word_features(\n",
    "    matrix, items=items, feature_name=\"artist_name_or_first_word\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.051751,
     "end_time": "2021-04-28T18:12:11.513824",
     "exception": false,
     "start_time": "2021-04-28T18:12:11.462073",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Item name length as a feature\n",
    "The name of the item_name field is surprisingly predictive, presumably because similar items often have similar length names. This is recorded both from the raw item name and the name cleaned of special characters and bracketed terms, which often contain information about release formats that obscure similarities between items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "papermill": {
     "duration": 1.574616,
     "end_time": "2021-04-28T18:12:13.140382",
     "exception": false,
     "start_time": "2021-04-28T18:12:11.565766",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_item_name(string):\n",
    "    # Removes bracketed terms, special characters and extra whitespace\n",
    "    string = re.sub(r\"\\[.*?\\]\", \"\", string)\n",
    "    string = re.sub(r\"\\(.*?\\)\", \"\", string)\n",
    "    string = re.sub(r\"[^A-ZА-Яa-zа-я0-9 ]\", \"\", string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    string = string.lower()\n",
    "    return string\n",
    "\n",
    "items[\"item_name_cleaned_length\"] = items[\"item_name\"].apply(clean_item_name).apply(len)\n",
    "items[\"item_name_length\"] = items[\"item_name\"].apply(len)\n",
    "matrix = matrix.merge(items[['item_id', 'item_name_length', 'item_name_cleaned_length']], how='left', on='item_id')\n",
    "items = items.drop(columns=['item_name_length', 'item_name_cleaned_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "papermill": {
     "duration": 1.963919,
     "end_time": "2021-04-28T18:12:15.155549",
     "exception": false,
     "start_time": "2021-04-28T18:12:13.19163",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created name features\n"
     ]
    }
   ],
   "source": [
    "print(\"Created name features\")\n",
    "matrix, oldcols = shrink_mem_new_cols(matrix, oldcols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.051242,
     "end_time": "2021-04-28T18:12:15.258377",
     "exception": false,
     "start_time": "2021-04-28T18:12:15.207135",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Time features\n",
    "Day and month-resolution time features are created from the training dataframe, e.g. number of days since the first and last sale of each item.\n",
    "\n",
    "The time since the first sale of each items is also used to create a mean sales-per-day feature (\"item_cnt_day_avg\"), which is potentially useful to correct sales counts for items which are less than a month old and therefore were not available to buy for the entire preceding month.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "papermill": {
     "duration": 0.086102,
     "end_time": "2021-04-28T18:12:15.39602",
     "exception": false,
     "start_time": "2021-04-28T18:12:15.309918",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import calendar\n",
    "import holidays\n",
    "\n",
    "def add_time_features(m, train, correct_item_cnt_day=False):\n",
    "    from pandas.tseries.offsets import Day, MonthBegin, MonthEnd\n",
    "\n",
    "    def item_shop_age_months(m):\n",
    "        m[\"item_age\"] = m.groupby(\"item_id\")[\"date_block_num\"].transform(\n",
    "            lambda x: x - x.min()\n",
    "        )\n",
    "        # Sales tend to plateau after 12 months\n",
    "        m[\"new_item\"] = m[\"item_age\"] == 0\n",
    "        m[\"new_item\"] = m[\"new_item\"].astype(\"int8\")\n",
    "        m[\"shop_age\"] = (\n",
    "            m.groupby(\"shop_id\")[\"date_block_num\"]\n",
    "            .transform(lambda x: x - x.min())\n",
    "            .astype(\"int8\")\n",
    "        )\n",
    "        return m\n",
    "\n",
    "    # Add dummy values for the test month so that features are created correctly\n",
    "    dummies = m.loc[m.date_block_num == 34, [\"date_block_num\", \"shop_id\", \"item_id\"]]\n",
    "    dummies = dummies.assign(\n",
    "        date=pd.to_datetime(\"2015-11-30\"), item_price=1, item_cnt_day=0, item_revenue_day=0,\n",
    "    )\n",
    "    train = pd.concat([train, dummies])\n",
    "    del dummies\n",
    "\n",
    "    month_last_day = train.groupby(\"date_block_num\").date.max().rename(\"month_last_day\")\n",
    "    month_last_day[~month_last_day.dt.is_month_end] = (\n",
    "        month_last_day[~month_last_day.dt.is_month_end] + MonthEnd()\n",
    "    )\n",
    "    month_first_day = train.groupby(\"date_block_num\").date.min().rename(\"month_first_day\")\n",
    "    month_first_day[~month_first_day.dt.is_month_start] = (\n",
    "        month_first_day[~month_first_day.dt.is_month_start] - MonthBegin()\n",
    "    )\n",
    "    month_length = (month_last_day - month_first_day + Day()).rename(\"month_length\")\n",
    "    first_shop_date = train.groupby(\"shop_id\").date.min().rename(\"first_shop_date\")\n",
    "    first_item_date = train.groupby(\"item_id\").date.min().rename(\"first_item_date\")\n",
    "    first_shop_item_date = (\n",
    "        train.groupby([\"shop_id\", \"item_id\"]).date.min().rename(\"first_shop_item_date\")\n",
    "    )\n",
    "    first_item_name_group_date = (\n",
    "        train.groupby(\"item_name_group\").date.min().rename(\"first_name_group_date\")\n",
    "    )\n",
    "\n",
    "    m = m.merge(month_first_day, left_on=\"date_block_num\", right_index=True, how=\"left\")\n",
    "    m = m.merge(month_last_day, left_on=\"date_block_num\", right_index=True, how=\"left\")\n",
    "    m = m.merge(month_length, left_on=\"date_block_num\", right_index=True, how=\"left\")\n",
    "    m = m.merge(first_shop_date, left_on=\"shop_id\", right_index=True, how=\"left\")\n",
    "    m = m.merge(first_item_date, left_on=\"item_id\", right_index=True, how=\"left\")\n",
    "    m = m.merge(\n",
    "        first_shop_item_date, left_on=[\"shop_id\", \"item_id\"], right_index=True, how=\"left\"\n",
    "    )\n",
    "    m = m.merge(\n",
    "        first_item_name_group_date, left_on=\"item_name_group\", right_index=True, how=\"left\"\n",
    "    )\n",
    "\n",
    "    # Calculate how long the item was sold for in each month and use this to calculate average sales per day\n",
    "    m[\"shop_open_days\"] = m[\"month_last_day\"] - m[\"first_shop_date\"] + Day()\n",
    "    m[\"item_first_sale_days\"] = m[\"month_last_day\"] - m[\"first_item_date\"] + Day()\n",
    "    m[\"item_in_shop_days\"] = (\n",
    "        m[[\"shop_open_days\", \"item_first_sale_days\", \"month_length\"]].min(axis=1).dt.days\n",
    "    )\n",
    "    m = m.drop(columns=\"item_first_sale_days\")\n",
    "    m[\"item_cnt_day_avg\"] = m[\"item_cnt_month\"] / m[\"item_in_shop_days\"]\n",
    "    m[\"month_length\"] = m[\"month_length\"].dt.days\n",
    "\n",
    "    # Calculate the time differences from the beginning of the month so they can be used as features without lagging\n",
    "    m[\"shop_open_days\"] = m[\"month_first_day\"] - m[\"first_shop_date\"]\n",
    "    m[\"first_item_sale_days\"] = m[\"month_first_day\"] - m[\"first_item_date\"]\n",
    "    m[\"first_shop_item_sale_days\"] = m[\"month_first_day\"] - m[\"first_shop_item_date\"]\n",
    "    m[\"first_name_group_sale_days\"] = m[\"month_first_day\"] - m[\"first_name_group_date\"]\n",
    "    m[\"shop_open_days\"] = m[\"shop_open_days\"].dt.days.fillna(0).clip(lower=0)\n",
    "    m[\"first_item_sale_days\"] = (\n",
    "        m[\"first_item_sale_days\"].dt.days.fillna(0).clip(lower=0).replace(0, 9999)\n",
    "    )\n",
    "    m[\"first_shop_item_sale_days\"] = (\n",
    "        m[\"first_shop_item_sale_days\"].dt.days.fillna(0).clip(lower=0).replace(0, 9999)\n",
    "    )\n",
    "    m[\"first_name_group_sale_days\"] = (\n",
    "        m[\"first_name_group_sale_days\"].dt.days.fillna(0).clip(lower=0).replace(0, 9999)\n",
    "    )\n",
    "\n",
    "    # Add days since last sale\n",
    "    def last_sale_days(matrix):\n",
    "        last_shop_item_dates = []\n",
    "        for dbn in range(1, 35):\n",
    "            lsid_temp = (\n",
    "                train.query(f\"date_block_num<{dbn}\")\n",
    "                .groupby([\"shop_id\", \"item_id\"])\n",
    "                .date.max()\n",
    "                .rename(\"last_shop_item_sale_date\")\n",
    "                .reset_index()\n",
    "            )\n",
    "            lsid_temp[\"date_block_num\"] = dbn\n",
    "            last_shop_item_dates.append(lsid_temp)\n",
    "\n",
    "        last_shop_item_dates = pd.concat(last_shop_item_dates)\n",
    "        matrix = matrix.merge(\n",
    "            last_shop_item_dates, on=[\"date_block_num\", \"shop_id\", \"item_id\"], how=\"left\"\n",
    "        )\n",
    "\n",
    "        def days_since_last_feat(m, feat_name, date_feat_name, missingval):\n",
    "            m[feat_name] = (m[\"month_first_day\"] - m[date_feat_name]).dt.days\n",
    "            m.loc[m[feat_name] > 2000, feat_name] = missingval\n",
    "            m.loc[m[feat_name].isna(), feat_name] = missingval\n",
    "            return m\n",
    "\n",
    "        matrix = days_since_last_feat(\n",
    "            matrix, \"last_shop_item_sale_days\", \"last_shop_item_sale_date\", 9999\n",
    "        )\n",
    "\n",
    "        matrix = matrix.drop(columns=[\"last_shop_item_sale_date\"])\n",
    "        return matrix\n",
    "\n",
    "    def add_seasons_and_weekends(matrix, train):\n",
    "        date_blocks = pd.DataFrame(train.groupby(\"date_block_num\").agg({\"date\": \"min\"}))\n",
    "\n",
    "        def add_season(col):\n",
    "            if 0 < col <= 2 or col == 12:\n",
    "                return 'winter'\n",
    "            if 3 <= col < 6:\n",
    "                return 'spring'\n",
    "            if 6 <= col < 9:\n",
    "                return 'summer'\n",
    "            if 9 <= col < 12:\n",
    "                return 'autumn'\n",
    "            return np.nan\n",
    "\n",
    "        # get number of holidays + weekend in each month    \n",
    "        ru_holidays = []\n",
    "\n",
    "        for date, name in sorted(holidays.RU(years=[2013, 2014, 2015]).items()):\n",
    "            ru_holidays.append(date)\n",
    "\n",
    "        def add_holidays_and_weekends(row):\n",
    "            business_dates = pd.bdate_range(f\"{row.year}-{row.month}-01\", f\"{row.year}-{row.month}-{row.days_in_month}\")\n",
    "            business_dates = [b for b in business_dates if b not in ru_holidays]\n",
    "            return row.days_in_month - len(business_dates)\n",
    "\n",
    "        date_blocks[\"year\"] = date_blocks.date.dt.year\n",
    "        date_blocks[\"month\"] = date_blocks.date.dt.month\n",
    "        date_blocks[\"days_in_month\"] = date_blocks.date.dt.daysinmonth.astype(np.int8) \n",
    "        date_blocks[\"season\"] = date_blocks.month.apply(add_season)\n",
    "        date_blocks[\"holidays_and_weekends_in_month\"] = date_blocks.apply(add_holidays_and_weekends, axis=1).astype(np.int8)\n",
    "        date_blocks.drop([\"date\", \"year\", \"month\", \"days_in_month\"], axis=1, inplace=True)\n",
    "\n",
    "        matrix = matrix.merge(date_blocks, left_on=\"date_block_num\", right_index=True, how=\"left\")\n",
    "\n",
    "        return matrix\n",
    "    \n",
    "    m = last_sale_days(m)\n",
    "    # Month id feature\n",
    "    m[\"month\"] = m[\"month_first_day\"].dt.month\n",
    "\n",
    "    m = m.drop(\n",
    "        columns=[\n",
    "            \"first_day\",\n",
    "            \"month_first_day\",\n",
    "            \"month_last_day\",\n",
    "            \"first_shop_date\",\n",
    "            \"first_item_date\",\n",
    "            \"first_name_group_date\",\n",
    "            \"item_in_shop_days\",\n",
    "            \"first_shop_item_date\",\n",
    "            \"month_length\",\n",
    "        ],\n",
    "        errors=\"ignore\",\n",
    "    )\n",
    "\n",
    "    m = item_shop_age_months(m)\n",
    "\n",
    "    if correct_item_cnt_day == True:\n",
    "        m[\"item_cnt_month_original\"] = m[\"item_cnt_month\"]\n",
    "        m[\"item_cnt_month\"] = m[\"item_cnt_day_avg\"] * m[\"month_length\"]\n",
    "\n",
    "    m = add_seasons_and_weekends(m, train)\n",
    "    \n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "papermill": {
     "duration": 44.568578,
     "end_time": "2021-04-28T18:13:00.017133",
     "exception": false,
     "start_time": "2021-04-28T18:12:15.448555",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time features created\n"
     ]
    }
   ],
   "source": [
    "matrix = add_time_features(matrix, train, False)\n",
    "print(\"Time features created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.052584,
     "end_time": "2021-04-28T18:13:00.379709",
     "exception": false,
     "start_time": "2021-04-28T18:13:00.327125",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Price features  \n",
    "\n",
    "The price of the item in the last month in which it was sold, and its price relative to other items in the same category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "papermill": {
     "duration": 0.067926,
     "end_time": "2021-04-28T18:13:00.501112",
     "exception": false,
     "start_time": "2021-04-28T18:13:00.433186",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_price_features(matrix, train):\n",
    "    # Get mean prices per month from train dataframe\n",
    "    price_features = train.groupby([\"date_block_num\", \"item_id\"]).item_price.mean()\n",
    "    price_features = pd.DataFrame(price_features)\n",
    "    price_features = price_features.reset_index()\n",
    "    # Calculate normalized differenced from mean category price per month\n",
    "    price_features = price_features.merge(\n",
    "        items[[\"item_id\", \"item_category_id\"]], how=\"left\", on=\"item_id\"\n",
    "    )\n",
    "    price_features[\"norm_diff_cat_price\"] = price_features.groupby(\n",
    "        [\"date_block_num\", \"item_category_id\"]\n",
    "    )[\"item_price\"].transform(lambda x: (x - x.mean()) / x.mean())\n",
    "    # Retain only the necessary features\n",
    "    price_features = price_features[\n",
    "        [\n",
    "            \"date_block_num\",\n",
    "            \"item_id\",\n",
    "            \"item_price\",\n",
    "            \"norm_diff_cat_price\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    features = [\n",
    "        \"item_price\",\n",
    "        \"norm_diff_cat_price\",\n",
    "    ]\n",
    "    newnames = [\"last_\" + f for f in features]\n",
    "    aggs = {f: \"last\" for f in features}\n",
    "    renames = {f: \"last_\" + f for f in features}\n",
    "    features = []\n",
    "    for dbn in range(1, 35):\n",
    "        f_temp = (\n",
    "            price_features.query(f\"date_block_num<{dbn}\")\n",
    "            .groupby(\"item_id\")\n",
    "            .agg(aggs)\n",
    "            .rename(columns=renames)\n",
    "        )\n",
    "        f_temp[\"date_block_num\"] = dbn\n",
    "        features.append(f_temp)\n",
    "    features = pd.concat(features).reset_index()\n",
    "    matrix = matrix.merge(features, on=[\"date_block_num\", \"item_id\"], how=\"left\")\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "papermill": {
     "duration": 4.30382,
     "end_time": "2021-04-28T18:13:04.85857",
     "exception": false,
     "start_time": "2021-04-28T18:13:00.55475",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "matrix = add_price_features(matrix, train)\n",
    "del(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.052081,
     "end_time": "2021-04-28T18:13:04.964343",
     "exception": false,
     "start_time": "2021-04-28T18:13:04.912262",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Item category features  \n",
    "In addition to the item categories provided with the data, I also manually defined two additional category groupings - supercategory (e.g. \"games\", \"music\") and platform (e.g. \"PS4\", \"mp3\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = matrix.merge(items[['item_id', 'item_category_id']], on='item_id', how='left')\n",
    "\n",
    "platform_map = {\n",
    "    0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 8, 10: 1, 11: 2,\n",
    "    12: 3, 13: 4, 14: 5, 15: 6, 16: 7, 17: 8, 18: 1, 19: 2, 20: 3, 21: 4, 22: 5,\n",
    "    23: 6, 24: 7, 25: 8, 26: 9, 27: 10, 28: 0, 29: 0, 30: 0, 31: 0, 32: 8, 33: 11,\n",
    "    34: 11, 35: 3, 36: 0, 37: 12, 38: 12, 39: 12, 40: 13, 41: 13, 42: 14, 43: 15,\n",
    "    44: 15, 45: 15, 46: 14, 47: 14, 48: 14, 49: 14, 50: 14, 51: 14, 52: 14, 53: 14,\n",
    "    54: 8, 55: 16, 56: 16, 57: 17, 58: 18, 59: 13, 60: 16, 61: 8, 62: 8, 63: 8, 64: 8,\n",
    "    65: 8, 66: 8, 67: 8, 68: 8, 69: 8, 70: 8, 71: 8, 72: 8, 73: 0, 74: 10, 75: 0,\n",
    "    76: 0, 77: 0, 78: 0, 79: 8, 80: 8, 81: 8, 82: 8, 83: 8,\n",
    "}\n",
    "matrix['platform_id'] = matrix['item_category_id'].map(platform_map)\n",
    "\n",
    "supercat_map = {\n",
    "    0: 0, 1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 7: 1, 8: 2, 9: 2, 10: 1, 11: 1, 12: 1,\n",
    "    13: 1, 14: 1, 15: 1, 16: 1, 17: 1, 18: 3, 19: 3, 20: 3, 21: 3, 22: 3, 23: 3,\n",
    "    24: 3, 25: 0, 26: 2, 27: 3, 28: 3, 29: 3, 30: 3, 31: 3, 32: 2, 33: 2, 34: 2,\n",
    "    35: 2, 36: 2, 37: 4, 38: 4, 39: 4, 40: 4, 41: 4, 42: 5, 43: 5, 44: 5, 45: 5,\n",
    "    46: 5, 47: 5, 48: 5, 49: 5, 50: 5, 51: 5, 52: 5, 53: 5, 54: 5, 55: 6, 56: 6,\n",
    "    57: 6, 58: 6, 59: 6, 60: 6, 61: 0, 62: 0, 63: 0, 64: 0, 65: 0, 66: 0, 67: 0,\n",
    "    68: 0, 69: 0, 70: 0, 71: 0, 72: 0, 73: 7, 74: 7, 75: 7, 76: 7, 77: 7, 78: 7,\n",
    "    79: 2, 80: 2, 81: 0, 82: 0, 83: 0\n",
    "}\n",
    "matrix['supercategory_id'] = matrix['item_category_id'].map(supercat_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.054288,
     "end_time": "2021-04-28T18:13:08.800954",
     "exception": false,
     "start_time": "2021-04-28T18:13:08.746666",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Shop city and shop type\n",
    "(from https://www.kaggle.com/dlarionov/feature-engineering-xgboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "papermill": {
     "duration": 1.896395,
     "end_time": "2021-04-28T18:13:10.753735",
     "exception": false,
     "start_time": "2021-04-28T18:13:08.85734",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_shop_type(col):\n",
    "    if 'ТЦ' in col:\n",
    "        return 1\n",
    "    if 'ТРЦ' in col or 'МТРЦ' in col:\n",
    "        return 2\n",
    "    if 'ТК' in col:\n",
    "        return 3\n",
    "    if 'ТРК' in col:\n",
    "        return 4\n",
    "    for c in ['Якутск Орджоникидзе', 'Жуковский', 'Воронеж (Плехановская, 13)', 'Магазин С21']:\n",
    "        if c in col:\n",
    "            return 5\n",
    "    return 0\n",
    "\n",
    "def add_shop_feats(matrix, shops):\n",
    "    shops.loc[\n",
    "        shops.shop_name == 'Сергиев Посад ТЦ \"7Я\"', \"shop_name\"\n",
    "    ] = 'СергиевПосад ТЦ \"7Я\"'\n",
    "    shops[\"city\"] = shops[\"shop_name\"].str.split(\" \").map(lambda x: x[0])\n",
    "    shops.loc[shops.city == \"!Якутск\", \"city\"] = \"Якутск\"\n",
    "    shops[\"city_code\"] = shops[\"city\"].factorize()[0]\n",
    "    \n",
    "    shops[\"shop_type\"] = shops.shop_name.apply(add_shop_type)\n",
    "    \n",
    "    shop_labels = shops[[\"shop_id\", \"city_code\", \"shop_type\"]]\n",
    "    matrix = matrix.merge(shop_labels, on='shop_id', how='left')\n",
    "    return matrix\n",
    "\n",
    "matrix = add_shop_feats(matrix, shops)\n",
    "del(shops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.053194,
     "end_time": "2021-04-28T18:13:10.860623",
     "exception": false,
     "start_time": "2021-04-28T18:13:10.807429",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Shop and item category clustering\n",
    "\n",
    "Shops and item categories are grouped into clusters according to their sales profiles. \n",
    "The following function performs and plots the results of a principle component analysis decomposition and clustering of the shops and item categories.\n",
    "\n",
    "The proportion of explained variance between items explained by each of the PCA dimensions is plotted, and the individual items are plotted according to their scores on the PCA dimensions and coloured according to their cluster assignment.\n",
    "\n",
    "The silhouette score (a metric of clustering quality) for different values of the cluster number parameter is also plotted. These plots were used to decide the number of clusters.\n",
    "\n",
    "For both shops and item categories, over 80% of differences occur on a single dimension, indicating that differences are mainly in magnitude rather than proportion. The item component score plots show that the clustering is mainly into a large cluster containing the large majority of items, and a few clusters containing outlier items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "papermill": {
     "duration": 0.29023,
     "end_time": "2021-04-28T18:13:11.205754",
     "exception": false,
     "start_time": "2021-04-28T18:13:10.915524",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "\n",
    "def cluster_feature(matrix, target_feature, clust_feature, level_feature, n_components=4, n_clusters=5, aggfunc=\"mean\", exclude=None):\n",
    "    start_month = 20\n",
    "    end_month = 32\n",
    "    pt = matrix.query(f\"date_block_num>{start_month} & date_block_num<={end_month}\")\n",
    "    if exclude is not None:\n",
    "        pt = matrix[~matrix[clust_feature].isin(exclude)]\n",
    "    pt = pt.pivot_table(values=target_feature, columns=clust_feature, index=level_feature, fill_value=0, aggfunc=aggfunc)\n",
    "    pt = pt.transpose()\n",
    "    pca = PCA(n_components=10)\n",
    "    components = pca.fit_transform(pt)\n",
    "    components = pd.DataFrame(components)\n",
    "    # Plot PCA explained variance\n",
    "    sns.set_theme()\n",
    "    features = list(range(pca.n_components_))\n",
    "    fig = plt.figure(figsize=(10,4))\n",
    "    ax = fig.add_subplot(121)\n",
    "#     ax.bar(features, pca.explained_variance_ratio_, color=\"black\")\n",
    "    sns.barplot(x=features, y=pca.explained_variance_ratio_, ax=ax)\n",
    "    plt.title(\"Variance by PCA components\")\n",
    "    plt.xlabel(\"component\")\n",
    "    plt.ylabel(\"explained variance\")\n",
    "    plt.xticks(features)\n",
    "\n",
    "    scorelist = []\n",
    "    nrange = range(2, 10)\n",
    "    for n in nrange:\n",
    "        clusterer = AgglomerativeClustering(n_clusters=n)\n",
    "        labels = clusterer.fit_predict(components)\n",
    "        silscore = silhouette_score(pt, labels)\n",
    "        scorelist.append(silscore)\n",
    "    ax = fig.add_subplot(122)\n",
    "    sns.lineplot(x=nrange, y=scorelist, ax=ax)\n",
    "    plt.title(\"Clustering quality by number of clusters\")\n",
    "    plt.xlabel(\"n clusters\")\n",
    "    plt.ylabel(\"silhouette score\")\n",
    "\n",
    "    pca = PCA(n_components=n_components)\n",
    "    components = pca.fit_transform(pt)\n",
    "    components = pd.DataFrame(components)\n",
    "    clusterer = AgglomerativeClustering(n_clusters=n_clusters, linkage=\"average\")\n",
    "    labels = clusterer.fit_predict(components)\n",
    "    x = components[0]\n",
    "    y = components[1]\n",
    "    fig = plt.figure(figsize=(10, 4))\n",
    "    ax = fig.add_subplot(111)\n",
    "    sns.scatterplot(x=x, y=y, hue=labels, palette=sns.color_palette(\"hls\", n_clusters), ax=ax)\n",
    "    plt.title(\"Items by cluster\")\n",
    "    plt.xlabel(\"component 1 score\")\n",
    "    plt.ylabel(\"component 2 score\")\n",
    "    for i, txt in enumerate(pt.index.to_list()):\n",
    "        ax.annotate(str(txt), (x[i], y[i]))\n",
    "    groups = {}\n",
    "    for i, s in enumerate(pt.index):\n",
    "        groups[s] = labels[i]\n",
    "    return groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.053194,
     "end_time": "2021-04-28T18:13:10.860623",
     "exception": false,
     "start_time": "2021-04-28T18:13:10.807429",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Item categories are clustered according to their mean sales in each month of the year. The principle component plot shows that 3 categories are outliers in this respect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "papermill": {
     "duration": 3.980666,
     "end_time": "2021-04-28T18:13:15.23941",
     "exception": false,
     "start_time": "2021-04-28T18:13:11.258744",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAm4AAAEcCAYAAAB+qjhEAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAABA/klEQVR4nO3deZyNdf/H8dc5M3NmMZjdjKUUQvmNbWwlMpIlW8TtVkoptyRSSJStVGQrLVoVFXeIspdbipRI9kpJljH7gtnOLOf6/aFOToOOnDNnjnk/H48eD+d7nfO9Pudjpt59r81kGIaBiIiIiJR5Zk8XICIiIiLOUXATERER8RIKbiIiIiJeQsFNRERExEsouImIiIh4CQU3ERERES+h4CYicpZt27bRpk0bt+7j+PHj1K1bl6KiIrfuR0QuPwpuIuIx8fHxbN26FYCPPvqIf//73x6uyLsMGDCAJUuWeLoMESlFCm4iIuVUcXGxp0sQkYuk4CYiHnfo0CEmTpzIrl27aNy4MXFxcQAUFBQwbdo0brrpJq6//nomTJhAfn4+8OchzTfeeINWrVrRunVrNmzYwBdffEHHjh1p3rw58+bNs+9jz5499OrViyZNmnD99dfz7LPPXrCmefPm0aJFC+Lj4/nkk0/sc1x//fUOgefTTz+le/fu55wjPz+f5557jnbt2tG0aVP+/e9/2+s/29krjwBz585l1KhRAFitVkaNGkWLFi2Ii4ujd+/epKWlMXv2bHbs2MGUKVNo3LgxU6ZMsffynnvuoXnz5nTs2JE1a9bY5x07diwTJ07k/vvvp1GjRmzbtu2CPRCRssfX0wWIiNSqVYvJkyezZMkSFi1aZB+fMWMGR48eZcWKFfj6+jJq1ChefvllHn30UQDS0tKwWq18+eWXLF++nCeeeIIbbriBZcuWkZiYSO/evbn11lupUaMGU6dO5a677qJnz57k5OTw888/n7eetLQ0MjMz2bx5M7t27WLw4ME0aNCA2NhYQkJC2LJlC23btgXg448/pmfPnuecZ9q0afzyyy8sXryYiIgIdu/ejdl8cf+/vHz5crKzs9m0aRMWi4UffviBgIAARo4cyc6dO+nevTt9+vQBIDc3l3vvvZfhw4fzxhtvcPDgQe655x6uueYaateuDcCqVat4/fXXee211ygsLLyoWkTE87TiJiJlkmEYfPjhh4wbN46QkBCCg4P5z3/+w+rVq+3v8fX15YEHHsDPz48uXbqQmZnJXXfdRXBwMHXq1KF27dr89NNP9vcePXqUjIwMKlSoQKNGjS64/xEjRmCxWGjevDlt27Zl7dq1APTs2dO+ApeVlcWWLVvo2rVric/bbDaWLVvG+PHjqVKlCj4+PjRp0gSLxXJRffD19SUrK4sjR47g4+NDgwYNCA4OPud7N23aRLVq1ejduze+vr5ce+21dOzYkXXr1tnf0759e5o2bYrZbMbf3/+iahERz9OKm4iUSRkZGeTl5dGrVy/7mGEY2Gw2++uQkBB8fHwACAgIACA8PNy+3d/fn5ycHACmTp3Kiy++SOfOnalevTrDhg2jXbt259x3pUqVCAoKsr+uWrUqKSkpAPTo0YPOnTuTm5vL2rVriYuLIyoqqsQcmZmZWK1WatSo8U9bYN9fUlISjzzyCKdOnaJ79+6MHDkSPz+/Eu9NSEhgz5499kPNcOY8trMP5cbExFxSPSLiWQpuIlImmEwmh9ehoaEEBASwevVqqlSpcsnz16xZk1mzZmGz2fj0008ZPnw427Ztcwhofzh16hS5ubn2bYmJidSpUweAKlWq0LhxYz799FM+/vjj814JGxoair+/P8eOHaNevXoXrC0wMJC8vDz769TUVPuf/fz8GDZsGMOGDeP48eMMHjyYq666yn549GwxMTE0a9aM+fPn/31DRMQr6VCpiJQJ4eHhJCcnU1BQAIDZbKZPnz4888wzpKenA5CcnMzmzZv/0fwff/wxGRkZmM1mKlWqZN/H+cydO5eCggJ27NjBpk2b6NSpk31bjx49eOuttzh48CC33HLLOT9vNpvp3bs3zz77LMnJyRQXF/P999/bv9/Z6tWrx5o1aygsLGTv3r2sX7/evu2bb77hp59+ori4mODgYHx9fe11R0REcOzYMft7b7rpJn777TdWrFhBYWEhhYWF7Nmzh0OHDl1cs0SkzFJwE5EyoWXLltSuXZvWrVvTokULAEaPHs2VV15J3759adKkCQMHDuTw4cP/aP7Nmzdz66230rhxY6ZOncrs2bPth1f/KiIigkqVKnHjjTcyatQoJk2aRK1atezbO3ToQEJCAh06dCAwMPC8+3zssce45ppruP3222nevDkzZsxwONT7h4cffpijR4/SvHlz5s6dS7du3ezb0tLSGD58OE2bNqVLly40b96cHj16AHDXXXexfv16mjVrxtNPP01wcDBvvfUWa9as4cYbb6R169bMmDHjnGFRRLyTyTAMw9NFiIh4m5tvvpkpU6Zw/fXXe7oUESlHtOImInKR1q9fj8lkomXLlp4uRUTKGV2cICJyEQYMGMAvv/zC9OnTL/qebCIil0qHSkVERES8hP53UURERMRLKLiJiIiIeAkFNxEREREvUW4uTsjMzMFm8+zpfOHhwaSnZ5fa/tq3b+3w2mq10qtXHx55ZAwAn3yynIUL3yEjI53Y2EaMGzeRyMjIUquvtPvhDdQTR+qHI/WjJPXEkfpRkrf1xGw2ERpa4bzby1Rws1qtPPPMM3z99df4+/vTqFEjnnrqKQ4fPszYsWPJysoiJCSEadOmUbNmzYua22YzPB7c/qijtHz22Z93mM/NzaVHj47cdFN7bDaDnTt3MG/ey7z44jxq1LiCF16YwcSJ43jppddLrT4o3X54C/XEkfrhSP0oST1xpH6UdDn1pEwFt+effx5/f3/7PZLS0tIAmDhxIv3796dHjx58/PHHTJgwgQULFni4Wu/yxRcbCQkJo2HDxgBs3bqFdu1u5uqrz9wNfuDA++jZszMJCcepVq26J0sVERGR8ygz57jl5OSwYsUKRowYYX/YdEREBOnp6Rw4cICuXbsC0LVrVw4cOEBGRoYny/U6a9euolOnLg4P8j77TjB//PnXX38p9dpERETEOWVmxe3YsWOEhITw0ksvsW3bNipUqMCIESMICAigSpUq+Pj4AODj40NUVBSJiYmEhYV5uGrvkJSUyK5dOxk79kn7WIsWrZg0aRw9e/amRo0azJ//BiaTifz8fA9WKiIicvEMwyAzM5WCgnzA8bBoSor5nM8I9iwTFksAoaGRDgsqzigzwa24uJhjx45x7bXX8thjj7F7926GDBnCCy+84JL5w8ODXTLPpYqMrOjW+Q3DIL2oCLNhIsxy5q93yZKFNG3alIYN69nf16XLzWRmJjNx4liys7O5++67qVChAtdcc5Xbazxbae7LW6gnjtQPR+pHSeqJo/LYj5SUFHx9zURGXoHJVGYOJp6XYdjIyEgD8omMjLqoz5aZ4BYTE4Ovr6/9kGjDhg0JDQ0lICCA5ORkiouL8fHxobi4mJSUFGJiYi5q/vT0bI+fnBgZWZHU1NNum9/qa+Ibaz4rM07iazLROzyExr4Wli1bzp133l1i37fc0p1bbukOwNGjR3jllVcIDY1xa41nc3c/vJF64kj9cKR+lKSeOCqv/UhNTScsrArFxQCOq2u+vmaKisraihtUqFCZ1NRkTKZAh3Gz2XTBxaYyE0vDwsJo0aIFX331FQCHDx8mPT2dmjVrUr9+fVatWgXAqlWrqF+/vg6T/oXJBD8WF7E0LQurzSCn2MaClAw27PmetLQU4uNvdni/1Wrl119/wTAMkpKSmD59Kn36/JtKlSp56BuIiIj8MzZbMT4+ZWYtyik+Pr7YbMUX/bky9S0nT57MuHHjmDZtGr6+vkyfPp1KlSoxadIkxo4dyyuvvEKlSpWYNm2ap0stc0w+Zr7IOFlifPknH3PTTfEEBTneE6agoIDJk58gIeE4QUEV6NKlG/fdN6S0yhUREXGpiz1XzNP+ab1lKrjVqFGDhQsXlhivVasWS5Ys8UBFXsRmUN3fj5/zHC8u6D/mcW7y9Xe4ghSgYsWKvPvu4tKsUEREpNw4evQIU6dO4uTJk1SuXJknnphMjRpXXPK8ZeZQqVwam83gporBBJr/TPCVfXxoFBhQIrSJiIiIe82Y8Sy9evVh8eKP6NWrD88//4xL5i1TK25yacILbYyvFs2JoiLMQDVfX4ILyt4JmSIiIp5WsPMb8tcux8jKwBQSRkDn27A0aemSuTMzMzh48Edmz34ZgJtv7sjs2dPJzMwkNDT0kuZWcLuMGAZULrBR+Y+FVIU2ERGREgp2fkPe0oVQWACAkZVx5jW4JLwlJycTERHlcA/aiIhIUlKSLzm46VCpiIiIlCv5a5fbQ5tdYcGZ8TJOwU1ERETKFSPr3I/NPN/4xapSpQppaSkUn7mxHMXFxaSlpRIVVeWS51ZwExERkXLFFHLue8Geb/xihYaGUbv2NWzYsB6ADRvWU6dO3Us+TAoKbiIiIlLOBHS+DfwsjoN+ljPjLjJ69DiWLv0v/fr1YunS/zJ69OMumVcXJ4iIiEi58scFCO66qhTgyitr8sYb77psvj8ouImIiEi5Y2nS0qVBrbToUKmIiIiIl1BwExEREfESCm4iIiIiXkLBTURERMRLKLiJiIiIeAkFNxEREREvoeAmIiIi4kIvvTSHPn2607p1HL/++otL59Z93ERERKTc+a3gG3bnLyfXyCDIFEbDgNuoaXHNfd1uvPEm+vTpx4MP3u+S+c6m4CYiIiLlym8F3/Bt3kKKKQAg18jg27yFAC4Jbw0bNrrkOc5Hh0pFRESkXNmdv9we2v5QTAG785d7qCLnKbiJiIhIuZJrZFzUeFmi4CYiIiLlSpAp7KLGyxIFNxERESlXGgbchg8WhzEfLDQMuM1DFTlPFyeIiIhIufLHBQjuuqp0zpzn+eKLz8nISOfhhx+kUqXKvPfehy6ZW8FNREREyp2alpYuC2p/9fDDo3n44dFumVuHSkVERES8hIKbiIiIiJdQcBMRERHxEgpuIiIiIl5CwU1ERETESyi4iYiIiHgJ3Q5ERERExIVOnsziqacmkJBwHD8/P6pXv4LRo8cRGhp6yXOXyRW3l156ibp163Lw4EEAdu3aRffu3enYsSP33nsv6enpHq5QRERE5NxMJhP9+9/FokUfsWDBf6lWrTrz5s11ydxlLrjt37+fXbt2Ua1aNQBsNhujR49mwoQJrF+/nri4OGbMmOHhKkVERMSbbc/LY0JqKg8lJzMhNZXteXkum7tSpco0aRJnf33ddQ1ISkpyydxlKrgVFBQwZcoUJk2aZB/bt28f/v7+xMWdaUC/fv1Yt26dhyoUERERb7c9L49Fp06RabMBkGmzsejUKZeGtz/YbDaWL19G69ZtXDJfmQpuL7zwAt27d6d69er2scTERKpWrWp/HRYWhs1mIysrywMVioiIiLdbmZ1N4V/GCn8fd7XZs58nKCiQ3r37umS+MnNxwvfff8++ffsYNWqUW+YPDw92y7wXKzKyoqdLKFPUj5LUE0fqhyP1oyT1xFF57EdKihlf3/OvRf112x8rbX+VabNdcJ6L9eKLs0lIOMaMGXOwWEpGLrPZfNF/X2UmuG3fvp1Dhw7Rvn17AJKSkhg0aBADBgzgxIkT9vdlZGRgNpsJCQm5qPnT07Ox2QxXlnzRIiMrkpp62qM1lCXqR0nqiSP1w5H6UZJ64qi89sNms1FUdO4w5utrLrEt1Gw+Z3gLNZd87z/12msv88MPB3j++Rcwm33POa/NZivx92U2my642FRmDpUOHjyYLVu2sHHjRjZu3Eh0dDRvvfUW9913H/n5+ezYsQOAxYsX06lTJw9XKyIiIt6qW3Awfn8Z8/t93BV+/fUQCxfOJy0tlSFD7mXgwP48/rhrjiiWmRW38zGbzUyfPp2JEyditVqpVq0azz//vKfLEhERES/VLDAQOHNOW6bNRqjZTLfgYPv4pbr66lps2bLDJXP9VZkNbhs3brT/uUmTJqxcudKD1YiIiMjlpFlgoMuCWmkqM4dKRUREROTCFNxEREREvITTh0q/+uorVq9eTUZGBvPmzWPv3r1kZ2fTqlUrd9YnIiIiIr9zasVt4cKFTJo0iZo1a7J9+3YAAgICeOGFF9xanIiIiIj8yang9u677zJ//nwGDx6M2XzmI1dffTWHDx92a3EiIiIi8iengltOTg4xMTHAmSfeAxQVFeHn99e7oIiIiIiIuzh1jluzZs14/fXXeeCBB+xjCxYsoEWLFm4rTERERMRbPf74o5w4cQKz2URgYBAjR46mTp26lzyvU8HtiSeeYMiQISxZsoScnBw6duxIhQoVeO211y65ABEREZHSlrA9j4Mrs8nPtBEQauaabsFUa+a6+7qNHz+Z4N+fxLB58yaefXYKb7/9/iXP+7fBzWazcejQIT744AMOHjxIQkICMTExxMbG2s93ExEREfEWCdvz2LfoFLbCM6/zM23sW3QKwGXhLfisx2dlZ2djMrkmM/1tcDObzQwdOpTvv/+e2NhYYmNjXbJjEREREU84uDLbHtr+YCs8M+7KVbfnnnuKb7/9BoAZM150yZxOxb9mzZqxa9cul+xQRERExJPyM20XNf5PjR37JB99tJrBg4fyyiuuuYWaU+e4Va1alfvvv5/27dsTHR1tv7IUYMSIES4pRERERKQ0BISazxnSAkLdcwpYp063Mn36M5w8mUXlyiGXNJdTwc1qtXLzzTcDkJycfEk7FBEREfGka7oFO5zjBmD2OzPuCrm5uZw+fYoqVaIB2LLlSypVqkSlSpUveW6ngtuzzz57yTsSERERKQv+OI/NXVeV5ufn8eSTY8nPz8Ns9qFSpUpMmzbb4YjlP+X0s0p/++03Vq1aRUpKClFRUXTt2pWaNWtecgEiIiIipa1as0CXXohwtrCwcF5//R23zO3UwdyNGzfSq1cvDh8+TOXKlTl8+DC9e/fmf//7n1uKEhEREZGSnFpxmz17Nq+88gotW7a0j23bto2nnnqK9u3bu604EREREfmTUytuSUlJxMXFOYw1bdqUpKQktxQlIiIicjEMw/B0CRfln9brVHCrV68eb7/9tsPY/PnzqV+//j/aqYiIiIirmM0+FBcXebqMi1JcXITZ7HPRn3PqUOmkSZN44IEHWLBgATExMSQmJhIYGMi8efMueociIiIirhQYGMzp01mEhIS77NFS7mQYNk6fziQw8OJvP+JUcKtVqxZr1qxh165d9qtKGzZsiJ+f30XvUERERMSVgoMrk5mZSnLyccDxEKTZbMZmc+0TES6dCYslgODgi7+vm1PB7YcffiAkJMThPLfExEROnjxJvXr1LnqnIiIiIq5iMpkIC4s657bIyIqkpp4u5Yrcx6n1xNGjR1NU5HjsuLCwkNGjR7ulKBEREREpyangduLECWrUqOEwdsUVV5CQkOCWokRERESkJKeCW3R0NPv373cY279/P1FR516WFBERERHXc+oct4EDBzJ06FDuu+8+rrjiCo4ePcrbb7/NkCFD3F2fiIiIiPzOqeDWt29fKlasyNKlS0lKSiI6OprHHnuMTp06ubs+EREREfmd0w+Z79y5M507d3ZnLSIiIiJyAU6d47Zq1SoOHToEwOHDh7nzzjsZMGCAfUxERERE3M+p4DZnzhwqVz5zk7hp06bxf//3fzRv3pzJkye7tTgRERER+ZNTh0ozMjKIiIjAarXy3Xff8eKLL+Lr60vLli3dXZ+IiIiI/M6p4BYWFsaRI0c4ePAg//d//4fFYiEvL+8fP9n+XDIzMxkzZgxHjx7FYrFw5ZVXMmXKFMLCwti1axcTJkzAarVSrVo1nn/+ecLDw122bxERERFv4NSh0qFDh9KrVy/Gjx/PoEGDANi6datLH3dlMpm47777WL9+PStXrqRGjRrMmDEDm83G6NGjmTBhAuvXrycuLo4ZM2a4bL8iIiIi3sKp4NarVy+2bNnCF198wQ033ABAo0aNmDVrlssKCQkJoUWLFvbXjRo14sSJE+zbtw9/f3/7c1L79evHunXrXLZfEREREW/h9O1AAgMDHV6781ClzWZj0aJFxMfHk5iYSNWqVe3bwsLCsNlsZGVlERIS4rYaRERERMoap4NbaXrqqacICgrizjvv5LPPPnPJnOHhwS6Z51JFRlb0dAllivpRknriSP1wpH6UpJ44Uj9Kupx6UuaC27Rp0zhy5Ajz5s3DbDYTExPDiRMn7NszMjIwm80XvdqWnp6Nzea6iyn+icjIiqSmnvZoDWWJ+lGSeuJI/XCkfpSknjhSP0rytp6YzaYLLjY5dY5baZk1axb79u3j5ZdfxmKxANCgQQPy8/PZsWMHAIsXL9ajtkRERKRcKjMrbj///DOvvfYaNWvWpF+/fgBUr16dl19+menTpzNx4kSH24F4q8TEE8yc+Rz79u3FYrFw003xDB/+KL6+ZeavQkRERMqoC6aF1NRUHn/8cb7//nvq1KnDmDFjaNKkiX17kyZN2Llzp0sKqVOnDj/99NM5tzVp0oSVK1e6ZD+eNnPmc4SGhvHxx+vIzj7NyJEPsnz5Uvr06efp0kRERKSMu+Ch0qlTpxIVFcXChQvp1KkTDzzwgEOAcuUNeMuLxMQTxMffjL+/P+HhEbRocT2HD+uZryIiIvL3Lrji9u233/L555/j7+/PtddeS8uWLRk8eDB5eXn07dsXk8lUWnVeNvr0+TcbNnxK48ZxnD59im+++Yr77nvA02WJiIiIF7hgcCsuLqaoqAh/f38A6tWrx8KFC7nnnnvIyckplQIvN40aNeGTT5bTsWNbiouL6dy5K23a3OTpskRERMQLXPBQ6XXXXceWLVscxq688koWLlzIBx98QF5enluLuxz4FeZjSfwV3x93knPwR0Y9+hBt27bjs882s3r1Bk6fPsWrr77o6TJFRETEC1xwxW3EiBGcPHmyxHi1atV47733WLJkidsKuxz4FheQ/+nHZG/aAMDJwiKSkpO4/fZ/YbFYsFgsdOnSnTfeeIWhQ0d4uFoREREp6y644tawYUPatGlzzm1VqlRh2LBhbinqcuGTkWwPbQCV/XyJDvDnk/8upKioiNOnT7N27Spq1arjwSpFRETEW+jmYW5kyy15HuC4a2ryzrfbePfDD/HxMdOkSTOGD3/EA9WJiIiIt1FwcyNzeBQmiz9GgdU+Vq9uXeY9OIYC3wAPViYiIiLeSMHNjQoqhhP50Cgy33+bwqREAurWo3KfAeQ7GdqmTHmS7777lry8fMLCwrnjjrvo1q0niYkn6NOnO4GBgfb33nHH3QwceJ+7voqIiIiUAU4Ft7feeotBgwaVGJ8/fz733HOPy4u6XBiGgTW6JiEPj8NkzadCVAQZ2UVOf/7OOwcyduyTWCwWjhz5jYce+g916tSlcuXKAKxd+7kelSUiIlKOOPWQ+Zdffvmc46+++qpLi7lcFfgEYA0KweesFTJnXH11LSwWCwAm05l/EhKOu6NEERER8QIXXK75+uuvAbDZbHzzzTcOj7g6fvw4FSpUcG91wowZz7F27UqsVivXXFOXVq1u4OTJLABuv70bJpOJZs1aMHToCEJCQjxaq4iIiLiXybjAA0fj4+MBSExMJCYm5s8PmUxERkZy//330759e/dX6QLp6dnYbJ59tmpkZEVSU09f9OeKi4vZt28v33+/gzvvHEhBQQFHj/5G7drXcOrUSWbNmkZubi6zZr3khqrd55/243KmnjhSPxypHyWpJ47Uj5K8rSdms4nw8ODzbr/gitvGjRsBGDNmDNOnT3dtZXJOZvOZ57+eHTJ9fHxo2LARn366huXLl9KnTz/q1bsWgLCwcEaOHEOPHp3Izc0hKEiroCIiIpcrp85xOzu02Ww2h3/k/KZMeZIePTpyyy1t6dev1zmfNDF//hu0bh3Hjh3bCMhMwvbFGorWLME/6TA+RrHDe4uLi895jpvJVDLsiYiIyOXHqUsS9+/fz5QpU/jpp5+wWs/ck8wwDEwmEz/88INbC/Rmf70qdMSIIURHX0m9evWBMxcafP75BsLDI/DLziRl5kKM3/t7bN0qDre8iebd++Lv78+OHd+yYcN6Jk2ayv79+6hYMZjq1a/g9OlTzJkzg8aNmxIcfP6lVREREfF+TgW3sWPH0q5dO5555hkCAnTjWGddfXUt+5/PXBVqIiHhuD24zZw5jQceeIiZM6dRePyIPbQBmIAPP/wvz73zDjabQXR0NMOHP0rr1m357LN1vP76K2RmZlChQgXi4lowadLU0v56IiIiUsqcCm4JCQmMHDnSfkhOnHf2VaHXXnstrVrdAMDGjRuwWPxo1ao1MA0KHe/vVtnPj5k33UClh8ZSaHL8a+rQoRMdOnQqra8gIiIiZYRT57h16NCBLVu2uLuWy9KoUWN5993FXHttAw4dOsS//tWT6dOn8tprL3HPPYN54IF7SU5O4vH3F/HovoMcOJVt/2ylW26lyKwb7IqIiMgZTqUCq9XKsGHDaNq0KREREQ7bdLWpI5MJfMwmbMafFwvMmfM8V15Zk2uvrUdISCRLlnxA/frXUbPmVTz++ARGjhzG44+NpzDpGFNemMPS3t0J6dAF4+q6nP9mLSIiIlLeOBXcateuTe3atd1di9ez5J+m6MBucr7bRkZEFLO/3MqeH34kNzeXli1bERgYRVZW5u83NN5K+/Y34OPjg81m44kJ42jdug2nrQXY+t9PYUi4p7+OiIiIlDFOBbdhw4a5uw6v50sxeWuXk711MwBPL1+Jzc+PjxYsZNn6Dbz77lsUFRXyyCNjyM3NJT6+A0OHPsS6dWt488155Obmsm7darp160lFhTYRERE5B6dPoPrqq69YvXo1GRkZzJs3j71795KdnU2rVq3cWZ/X8DmVSfbXf54HmFpQiF9hEb3u7E+RzaCgwIrNZmP69GcwmUx8/fUWfvrpB4YOHYHZbGbgwEHUqHEFRUXOP4ReREREyhenLk5YuHAhkyZNombNmmzfvh2AgIAAXnjhBbcW51XOuuB2jbWY4oAAjuZbad2kCRUrBlO5cmVmzpxJcHBFzGYfiouLSU9P44knxtCwYWMCA4Po0KET7733Dj//fNBz30NERETKLKeC27vvvsv8+fMZPHgwZvOZj1x99dUcPnzYrcV5k6KKYQS3icf/yppUrXMNt4VUpILZzLotW0hNTaVp0+ZkZWWRnX2a4uIiioqKaN/+Fq65ph5ZWVnk5uacmaeoiBMnEjz8bURERKQscupQaU5Ojv0h83/cy62oqAg/Pz/3VeZlzMVFVGjeitazXqSgoIC/Pgzs8883sGHDegAqVKhAZGQUq1d/gr+/PwUFBSxYcIQVK5aSk5PLddc1KP0vICIiImWeUytuzZo14/XXX3cYW7BgAS1atHBLUd7GkneKnEVvkfz802AYnOs2xbbiP587mpOTw2+/nVmttFqtGIaBYdgIDq6IYdjw8fEppcpFRETEmzi14vbEE08wZMgQlixZQk5ODh07dqRChQq89tpr7q7PK9gO/Uje7p3c+vX3533P392Ozc/Pj8DAQCpUqEBCwnFCQ8NcW6SIiIh4PaeCW1RUFMuWLWPPnj2cOHGCmJgYYmNj7ee7lWc+PmasP/8EgL/ZjNX214OkziksLOTnnw8SEhJKrVp1XFmiiIiIXCacTl4mk4mGDRvSsWNHYmNjAbD9w5ByOSkuthFQ+0zQ+iDun5+bZrPZMAyDtm3bERgY6KryRERE5DLi1Irb/v37mTJlCj/99BNWqxUAwzAwmUz88MMPbi2wrLPYCvAJDycwthGnv9v+j+eJioomJSWJdetW06NHL+rUqevCKkVERMQVOnS40eG11WrltttuZ+TIMRQWFjJ58nh+/PEHkpISefHFeTRpEufS/TsV3MaOHUu7du145plnCAgIcGkBzjp8+DBjx44lKyuLkJAQpk2bRs2aNT1Sy9n8TqaS9MarVI7vwI+FwI59/2ielJQkAMLCwtm+/VsFNxERkTLos8822/+cm5tLjx4dadfuZvtYbGwj+vTpz4QJj7ll/04Ft4SEBEaOHGm/FYgnTJw4kf79+9OjRw8+/vhjJkyYwIIFCzxWD4CPj4nCzAxiRo+DwgKWvv72Jc+ZkZFB7do6x01ERKSs++KLjYSEhNGwYWPgzIWGffv2B8Bsds8dIpw6x61Dhw5s2bLl79/oJunp6Rw4cICuXbsC0LVrVw4cOEBGRobHagLwt1mxhEdSnJFBYXIKP/z22yXPeccdd9O8ectLL05ERETcau3aVXTq1KVUF7acWnGzWq0MGzaMpk2bEhER4bBt+vTpbinsbImJiVSpUsV+fzMfHx+ioqJITEwkLMxzt80wZ5+kIOEomas+pig1BYthkHcJ83Xp0p3/+79Y+vfvTXJyEtde24Dx4ycRHR3jsppFRETk0iUlJbJr107Gjn2yVPfrVHCrXbs2tWvXdnctbhUeHuzyOXOSD5O5cgVFaakANK5cga0nc/7RXHXr1mXcuDF06tSJp59+mvj4eObMmcNTTz3Bhx9+6Mqyy5TIyIqeLqHMUU8cqR+O1I+S1BNH6kdJruiJtTgXqy2XAJ9gLOYAlixZSNOmTWnYsN453282mwgJCXL534dTwW3YsGEu3enFiomJITk5meLiYnx8zjygPSUlxf4YLmekp2djs/3dbXAvTkB+nj20YTJxdWxjtm6++EPK4eHhDBhwLx9/vIaaNa8mLq41p04V8O9/38N7773Pjh17ufLKmi6tvSyIjKxIauppT5dRpqgnjtQPR+pHSeqJI/WjpEvtickE+f6JfJ31PsnWX6gecB3NK/+LZcuWc+edd593bpvNICsr96L3bTabLrjY5FRwA9i2bRsrVqwgJSWFqKgoevToQcuWpXMuVnh4OPXr12fVqlX06NGDVatWUb9+fY8eJgXwqRSCOSgIW24uFW+8ibt//YV/t2ps337fvp+5vUdP+tw/jJzcPAYNugMfH1/efHMBDz54P4cP/4q/vz/p6enMnTuH6tWrO1yYEBgYSLVq1Th8+NBlGdxERETKumLLKdamzSCv+BQAR/P3sH/PT6SlpRAff3OJ9xcUFGAYZxaKioqKsFqtWCwWl50H59TFCUuWLOHhhx8mMjKSDh06EBUVxaOPPlqqh/AmTZrEe++9R8eOHXnvvfeYPHlyqe37vMIjiOh/F5jN+IaGUXD8mH1TVmEht4RWZPPOnXS5tQO9e3clOTmZu+66l1WrPuGXX34GID8/Hx8fH7KyMtmzZzf5+VaHXQQHB5Obm1uqX0tERETOyDZS7aHtDzvW/8wN7VoQFFShxPv79+9N+/Y3kJqawiOPDKN9+xtISkp0WT1Orbi9+eabzJ8/n3r1/jyO27lzZ4YPH07fvn1dVsyF1KpViyVLlpTKvpyVY7Pgf11jqo6dQHFWlsM2E/Bd5ml+Sz+JYUBMeDj9u3ahe/t2vPre+w7v9fOzYBgGPj5m0tNTHfeRk0NQUJCbv4mIiIici8VU8mlG8Q/VpHfUWLCWfP/SpSvdWo9TwS0rK4tatWo5jF199dWcPHnSLUV5E2uRGWtoNQILCvG/8iqsRw4DUNnPj7l39CXk9v6kvf0qBYd/hV3fkpl0jAcGDycpKZHExBNUr34Fn366BqvVSlRUFXJy/ry4IS8vj4SE41x1Va3z7V5ERETcKKA4kv+reAt7T39qH4sLuQ1LUTiuPXPeOU4FtyZNmvDcc88xatQoAgMDyc3NZdasWTRu3PjvP1xO2CqHU6HF9QTUrU9hYgKWGlcScG0D8n46cCa0/a4wKZGnJ4znSK6V2bNfISgoiFGjxrJv3162bt3MihVL2bTpf7Rq1Zr589+gVq06Or9NRETEU4r8uM6/K1cENCbHlkFFcwQVbNUxipx+3LtLmYw/zqC7gJSUFEaOHMmuXbuoXLkyJ0+epHHjxsycOZMqVaqURp2XzB1Xlf6Vf/5pjNRETIYBFStTHBFN3uK3yf32a/t7UqwF3LNzPxY/Cz6+f95VefToceze/T1msw/fffctSUlJXHvtdYwfP4mYmKpurdtTdPVTSeqJI/XDkfpRknriSP0oydt64pKrSqOionj//fdJSkqyX1UaHR3tsiIvF9aAilDjrPu1FEPgdbEOwS3K38KWCeOwHjtKxTvupSCgkn3bzp078POz8MEHy0qzbBEREfESTq/znTp1im+//db+z6lTp/7+Q4K5Vj2CW7c9cyMYIKhBLJhMJO3dxfqPlpCbm0txcTHbtn3Nhg3riYtr5uGKRUREpKxyasXt66+/5qGHHuKqq66iatWqJCYmMmXKFObOnUurVq3cXaNXK/APJrhLD/wio8Bmw3roZ05+ugYT8NGGDUxbsBCbzSA6Oprhwx+ldeu2ni5ZREREyiingttTTz3FlClT6NKli31s7dq1TJ48mXXr1rmtuMtFgSWYoqwsTn/+mX2ssr8/r894BmvY5Xn+moiIiLieU4dKU1JS6Nixo8NYhw4dSEtLc0tRl5tiw0Rgu05UvqUzpoBA/KpVJ2r4aArD9PB4ERERcZ5TK249evTg/fff56677rKPLVq0iJ49e7qrrsuONbASEf0G4N/2FgwfC1Yfi6dLEhERES/jVHA7cOAAixcv5s0336RKlSokJyeTkZFBbGwsd9xxh/1977///gVmEZPZjNVy/kt8RURERC7EqeDWt2/fUnu0lYiIiIicm1PB7bbbbnN3HSIiIiLyN5wKbgA7duzgwIED5ObmOowPGTLE5UWJiIiISElO3w5k7dq1xMXF4e/vbx83/X5TWRERERFxP6eC28qVK1m5cqXXPJdURERE5HLk1H3coqOjsVh0+woRERERT3JqxW3q1Kk8+eST3HrrrURERDhsa9ZMz9YUERERKQ1OBbf9+/fz5Zdfsn37dgICAuzjJpOJTZs2uas2ERERETmLU8Ft9uzZzJs3j+uvv97d9YiIiIjIeTh1jltgYCBxcXHurkVERERELsCp4DZ8+HCeeeYZUlNTsdlsDv+IiIiISOlw6lDpuHHjAPjvf/9rHzMMA5PJxA8//OCeykRERETEgVPB7X//+5+76xARERGRv+FUcKtWrRoANpuNtLQ0IiIiMJudOsoqIiIiIi7iVPrKzs5mzJgxxMbG0qZNG2JjY3nsscc4ffq0u+sTERERkd85Fdyefvpp8vLyWLlyJXv27GHlypXk5eXx9NNPu7s+EREREfmdU4dKN2/ezIYNGwgMDATgqquu4tlnn6VDhw5uLU5ERERE/uTUipu/vz8ZGRkOY5mZmXp+qYiIiEgpcmrF7fbbb+fee+9l4MCBVK1alRMnTvDOO+/Qt29fd9cnIiIiIr9zKrg98MADREVFsWrVKlJSUoiKiuK+++7j9ttvd3d9IiIiIvI7p4KbyWTi9ttvV1ATERER8SCnryrduXOnw9jOnTuZOnWqS4qYPHkynTp1onv37vTr14+9e/fat6WlpXHvvffSsWNHunfvzu7du12yTxERERFv41RwW7VqFQ0aNHAYa9CgAatWrXJJEW3atGHlypV88skn/Oc//2HkyJH2bTNnziQuLo7169czYcIERo8ejWEYLtmviIiIiDdxKriZTKYSYam4uNhlD5lv164dfn5+ADRq1IikpCT73OvWraNfv34AxMXFYbFYHFbkRERERMoLp4JbXFwcc+bMsYcpm83G3LlziYuLc3lB77//PjfddBNms5nMzEwMwyAsLMy+PSYmhqSkJJfvV0RERKSsc+rihPHjx/Of//yH1q1bU7VqVRITE4mMjGTevHlO7eS2227jxIkT59y2detWfHx8AFi9ejUrV67k/fffd7J854WHB7t8zn8iMrKip0soU9SPktQTR+qHI/WjJPXEkfpR0uXUE6eCW3R0NMuXL2fPnj0kJiYSExNDbGys0w+aX758+d++57PPPmP27Nm88847REREABAaGgpARkaGfdUtMTGR6Ohop/Z7tvT0bGw2z54bFxlZkdRUPd/1D+pHSeqJI/XDkfpRknriSP0oydt6YjabLrjY5FzyAsxmM40aNaJz5840atTI6dDmjM8//5xnn32Wt956i+rVqzts69SpE4sXLwZgx44d5Ofnl7hQQkRERKQ8cGrFzd0ef/xx/Pz8GD58uH3snXfeITQ0lEcffZTRo0ezYsUK/P39mT59uktDo4iIiIi3KBPB7ZtvvjnvtsjISN55553SK0ZERESkjNLSlYiIiIiXUHATERER8RIKbiIiIiJeQsFNRERExEsouImIiIh4CQU3ERERES+h4CYiIiLiJRTcRERERLyEgpuIiIiIl1BwExEREfESCm4iIiIiXkLBTURERMRLKLiJiIiIeAkFNxEREREvoeAmIiIi4iUU3ERERES8hIKbiIiIiJdQcBMRERHxEgpuIiIiIl5CwU1ERETESyi4iYiIiHgJBTcRERERL6HgJiIiIuIlFNxEREREvISCm4iIiIiXUHATERER8RIKbiIiIiJeQsFNRERExEv4eroAcY1ly/7LmjWr+PXXX7j55o6MHz8JgH379vLmm6/y008/4uNjplGjpjz88GgiIiI8W7CIiIhcNK24XSYiIiK5++5B3Hprd4fx06dP0b17L5Yu/YSlS1cRFBTEM89M9lCVIiIicim04naZaNs2HoAffzxAamqKfbxVqxsc3te7978YNmxwqdYmIiIirlGmVty2bdtG/fr1ee+99+xjaWlp3HvvvXTs2JHu3buze/duD1bo/Xbv3slVV13t6TJERETkHygzwS07O5sZM2bQpk0bh/GZM2cSFxfH+vXrmTBhAqNHj8YwDA9V6d1++eVn5s9/kwcfHOHpUkREROQfKDPB7bnnnmPQoEGEhoY6jK9bt45+/foBEBcXh8ViYe/evZ4osezJN5N7zCAvAUwFF/6rPH78GKNGDWfEiEdp2LBxKRUoIiIirlQmznH74osvOH36NJ06dWLTpk328czMTAzDICwszD4WExNDUlISsbGxHqi07LCdMrN1biqnk4oACLvaQvPB4ed8b1JSIg8/PJSBAwfRqdOtpVmmiIiIuFCpBLfbbruNEydOnHPbunXrmDlzJvPnz3drDeHhwW6d31mRkRVdMs93n6XZQxtA2qE8kvZlExDgi5+fmUqVLPj4+JCens7IkUO5664BDBp0j0v27Uqu6sflRD1xpH44Uj9KUk8cqR8lXU49KZXgtnz58vNu27FjB6mpqfTp0wc4s8r2+eefk5WVxbBhwwDIyMiwr7olJiYSHR190TWkp2djs3n23LjIyIqkpp6+5Hl8zGaS9uc5jG1JWsyzj35gf/3JJ59wzz33YzKZOHbsGHPnzmXu3Ln27Z99tvmS67hUrurH5UQ9caR+OFI/SlJPHKkfJXlbT8xm0wUXmzx+qDQuLo6vv/7a/nrs2LE0aNCAO++8E4BOnTqxePFihg4dyo4dO8jPz6dBgwaeKrdMsBkGNZoFkX7Iah9rE3MHYyaNILSBT4n333uvbv8hIiJyOfB4cPs7jz76KKNHj2bFihX4+/szffp0zOYyc02FRxiGQXTjAGocCuLY9lwwQe2bKhJS2w+webo8ERERcZMyF9yee+45h9eRkZG88847nimmDDMF2Yi9szL1ulXCZDLhFwI2hTYREZHLWpkLbuI8m9mGbyiAocgmIiJSDpTvY44iIiIiXkTBTURERMRLKLiJiIiIeAkFNxEREREvUW4uTjCbTZ4uASg7dZQV6kdJ6okj9cOR+lGSeuJI/SjJm3ryd7WaDMPw7OMERERERMQpOlQqIiIi4iUU3ERERES8hIKbiIiIiJdQcBMRERHxEgpuIiIiIl5CwU1ERETESyi4iYiIiHgJBTcRERERL6HgJiIiIuIlFNxKweHDh/nXv/5Fx44d+de//sVvv/3m6ZLcbtq0acTHx1O3bl0OHjxoH79QLy7nPmVmZnL//ffTsWNHunXrxrBhw8jIyABg165ddO/enY4dO3LvvfeSnp5u/9yFtnm7oUOH0r17d3r27En//v354YcfgPL7M/KHl156yeH3prz+fADEx8fTqVMnevToQY8ePdi8eTNQvntitVqZOHEit9xyC926dePJJ58EyufvzfHjx+0/Gz169CA+Pp7mzZsDl3k/DHG7AQMGGCtWrDAMwzBWrFhhDBgwwMMVud/27duNEydOGO3atTN++ukn+/iFenE59ykzM9P45ptv7K+fe+454/HHHzeKi4uNm2++2di+fbthGIbx8ssvG2PHjjUMw7jgtsvBqVOn7H/+7LPPjJ49exqGUX5/RgzDMPbt22cMGjTI/ntTnn8+DMMo8e8Pw7jw9y4PPXnqqaeMqVOnGjabzTAMw0hNTTUMo3z/3vzh6aefNiZPnmwYxuXdDwU3N0tLSzOaNm1qFBUVGYZhGEVFRUbTpk2N9PR0D1dWOs7+F++FelHe+rRu3Trj7rvvNnbv3m3ceuut9vH09HSjUaNGhmEYF9x2uVm+fLlx2223leufEavVavTt29c4duyY/femvP98nCu4leeeZGdnG02bNjWys7Mdxsvz780frFar0aJFC2Pfvn2XfT98Pb3id7lLTEykSpUq+Pj4AODj40NUVBSJiYmEhYV5uLrSdaFeGIZRbvpks9lYtGgR8fHxJCYmUrVqVfu2sLAwbDYbWVlZF9wWEhLigcpdb/z48Xz11VcYhsGbb75Zrn9GXnjhBbp370716tXtY+X95wNg1KhRGIZB06ZNeeSRR8p1T44dO0ZISAgvvfQS27Zto0KFCowYMYKAgIBy+3vzh40bN1KlShWuu+469u3bd1n3Q+e4iZSyp556iqCgIO68805Pl+JxU6dOZdOmTYwcOZLp06d7uhyP+f7779m3bx/9+/f3dCllyvvvv88nn3zCsmXLMAyDKVOmeLokjyouLubYsWNce+21fPTRR4waNYqHHnqI3NxcT5fmccuWLaN3796eLqNUKLi5WUxMDMnJyRQXFwNnfvFSUlKIiYnxcGWl70K9KC99mjZtGkeOHGHOnDmYzWZiYmI4ceKEfXtGRgZms5mQkJALbrvc9OzZk23bthEdHV0uf0a2b9/OoUOHaN++PfHx8SQlJTFo0CCOHDlSrn8+/vi7tVgs9O/fn507d5br35mYmBh8fX3p2rUrAA0bNiQ0NJSAgIBy+Xvzh+TkZLZv3063bt2Ay/+/NQpubhYeHk79+vVZtWoVAKtWraJ+/fpesyTrShfqRXno06xZs9i3bx8vv/wyFosFgAYNGpCfn8+OHTsAWLx4MZ06dfrbbd4uJyeHxMRE++uNGzdSuXLlcvszMnjwYLZs2cLGjRvZuHEj0dHRvPXWW9x3333l8ucDIDc3l9OnTwNgGAZr1qyhfv365fZ3Bs4c+m3RogVfffUVcObqyPT0dGrWrFkuf2/+sHz5ctq2bUtoaChw+f+3xmQYhuHpIi53hw4dYuzYsZw6dYpKlSoxbdo0rr76ak+X5VZPP/00n376KWlpaYSGhhISEsLq1asv2IvLuU8///wzXbt2pWbNmgQEBABQvXp1Xn75ZXbu3MnEiROxWq1Uq1aN559/noiICIALbvNmaWlpDB06lLy8PMxmM5UrV+axxx7juuuuK7c/I2eLj49n3rx5XHPNNeXy5wPOnM/10EMPUVxcjM1mo1atWjzxxBNERUWV257Amb6MGzeOrKwsfH19efjhh2nbtm25/r3p2LEj48ePp02bNvaxy7kfCm4iIiIiXkKHSkVERES8hIKbiIiIiJdQcBMRERHxEgpuIiIiIl5CwU1ERETESyi4iYiIiHgJBTcREReLj49n69at591eUFDA8OHDiY+Pp27dumzbtq0UqxMRb6bgJiLiAU2aNGH69OlERkZ6uhT7439EpOxTcBMRt0hMTGTYsGG0bNmSFi1a2B8QbrPZeOWVV2jXrh2tWrVizJgx9kcbHT9+nLp167Js2TLatm1Ls2bNWLRoEXv27KFbt27ExcU5PGj8o48+ol+/fkyZMoWmTZvSqVMnvv76a/v25ORkhgwZQvPmzenQoQMffvihfdvcuXMZMWIEY8aMoXHjxtx6663s3bvX4bMPPfQQLVu2JD4+ngULFjj12dGjR3PixAmGDBlC48aNeeONN0r0xmKxMHDgQOLi4jCb//5fwx999BHt27encePGxMfH88knn9i3ffjhh3Tu3JnGjRvTpUsX9u/fD5y5O/yAAQOIi4vj1ltv5X//+5/9M2PHjmXixIncf//9NGrUiG3btl3w+4pIGWKIiLhYUVGR0a1bN2Pq1KlGTk6OkZ+fb2zfvt0wDMNYsmSJcfPNNxtHjx41srOzjQcffNAYNWqUYRiGcezYMeOaa64xnnzySSM/P9/YvHmz0aBBA+OBBx4w0tLSjKSkJKNly5bGtm3bDMMwjGXLlhn169c35s+fbxQUFBirV682mjRpYmRmZhqGYRj9+/c3Jk6caOTn5xsHDhwwWrRoYWzdutUwDMN48cUXjQYNGhibNm0yioqKjBkzZhh9+vQxDMMwiouLjdtuu82YO3euYbVajaNHjxrx8fHGl19++befNQzDaNeunfHVV1851asbb7zR+Oabb867PScnx2jcuLFx6NAhwzAMIzk52Th48KBhGIaxZs0ao3Xr1sbu3bsNm81m/Pbbb8bx48eNgoIC4+abbzZeffVVw2q1Glu3bjUaNWpkn+Oxxx4zmjRpYuzYscMoLi42cnNzL/h9RaTs0IqbiLjcnj17SElJYcyYMQQFBeHv709cXBwAK1euZODAgdSoUYMKFSrwyCOPsGbNGoqKiuyff/DBB/H396d169YEBQXRtWtXwsPDqVKlCnFxcRw4cMD+3rCwMO6++278/Pzo0qULV111FZs2bSIxMZGdO3cyatQo/P39qV+/Pn369OHjjz+2f7Zp06a0bdsWHx8fevTowY8//gjA3r17ycjIYNiwYVgsFmrUqEHfvn1Zs2bN337WHcxmMz///DP5+flERUVRp04dAJYuXcp9991HbGwsJpOJK6+8kmrVqrF7925yc3MZPHgwFouFVq1a0a5dO1avXm2fs3379jRt2hSz2czBgwf/9vuKSNng6+kCROTyk5iYSNWqVfH1LfmvmJSUFKpVq2Z/Xa1aNYqKikhPT7ePhYeH2//s7+9f4nVubq79dZUqVTCZTPbXVatWJSUlhZSUFCpXrkxwcLDDtn379tlfn/3w8YCAAKxWK0VFRSQkJJCSkmIPm3DmPLCzX5/vs+f6zpciKCiI2bNn8/bbbzN+/HiaNGnCY489Rq1atUhMTOSKK64o8ZmUlBSio6MdDsNWrVqV5ORk++uYmBj7n535viJSNii4iYjLxcTEkJiYeM4gExUVRUJCgv31iRMn8PX1JTw8nKSkpIveV3JyMoZh2MNbYmIi8fHxREVFcfLkSbKzs+3hLTExkSpVqjhVf/Xq1fn0008vuh53uPHGG7nxxhvJz89nzpw5PPnkk3zwwQfExMRw9OjREu+PiooiKSkJm81mD2+JiYnUrFnznPOXte8rIuenQ6Ui4nKxsbFERkYyc+ZMcnNzsVqtfPfddwB07dqVd999l2PHjpGTk8Ps2bPp3LnzP16pysjIYMGCBRQWFrJ27VoOHTpE27ZtiYmJoXHjxsyaNQur1cqPP/7I0qVL6d69u1P1V6hQgddff538/HyKi4s5ePAge/bscaqmiIgIjh07dsH3FBQUYLVaASgsLMRqtWIYRon3paWlsWHDBnJzc7FYLAQFBdnD2O23387bb7/Nvn37MAyDI0eOkJCQQGxsLAEBAbz55psUFhaybds2Nm7cSJcuXdzyfUWk9Ci4iYjL+fj4MG/ePI4cOUK7du1o06YNa9euBaB37950796dO++8k/bt22OxWHjyySf/8b5iY2M5cuQILVu2ZM6cObz44ouEhoYCMGvWLBISErjxxhsZNmwYDz30ENdff73T9f/444+0b9+eli1b8sQTT5Cdne1UTYMHD+bVV18lLi6Ot95665zv6dSpE7GxsSQnJzNo0CBiY2MdViL/YLPZeOedd7jxxhtp3rw527dvZ9KkSQB07tyZIUOG8Oijj9KkSRMefPBBTp48icViYd68eXz55Ze0bNmSyZMnM336dGrVquWW7ysipcdknOt/8UREvMBHH33EkiVLWLRokadLEREpFVpxExEREfESCm4iIiIiXkKHSkVERES8hFbcRERERLyEgpuIiIiIl1BwExEREfESCm4iIiIiXkLBTURERMRLKLiJiIiIeIn/B+OBWMVZiKI6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "category_group_dict = cluster_feature(matrix, 'item_cnt_month', 'item_category_id', 'date_block_num', n_components=2, n_clusters=4, aggfunc=\"mean\", exclude =[])\n",
    "matrix['category_cluster'] = matrix['item_category_id'].map(category_group_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shops are clustered by their summed sales of each item category. The principle component plots show that shops mainly differ in the magnitude of their sales, with shop 31 being an outlier due to the volume of its sales. Shops 12 and 55 are outliers on an orthogonal dimension because they sell different (online only) items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "papermill": {
     "duration": 3.477294,
     "end_time": "2021-04-28T18:13:18.77379",
     "exception": false,
     "start_time": "2021-04-28T18:13:15.296496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shop_group_dict = cluster_feature(matrix, 'item_cnt_month', 'shop_id', 'item_category_id', n_components=4, n_clusters=4, aggfunc=\"mean\", exclude=[36])\n",
    "shop_group_dict[36] = shop_group_dict[37]  # Shop36 added separately because it only has one month of data\n",
    "matrix['shop_cluster'] = matrix['shop_id'].map(shop_group_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "papermill": {
     "duration": 9.033337,
     "end_time": "2021-04-28T18:13:27.865241",
     "exception": false,
     "start_time": "2021-04-28T18:13:18.831904",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "matrix, oldcols = shrink_mem_new_cols(matrix, oldcols)  # Use this function periodically to downcast dtypes to save memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.058948,
     "end_time": "2021-04-28T18:13:27.984695",
     "exception": false,
     "start_time": "2021-04-28T18:13:27.925747",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Number of unique item features\n",
    "\n",
    "These features count the number of unique items sharing the same value of a grouping feature or set of features as the current item in the current month, e.g. number of new items in the same category.  \n",
    "\n",
    "This could considered to be a kind of data leakage feature, as the set of items in each month (and therefore the test set) is determined by whether each item recorded a sale or not in the month being predicted, which isn't known in advance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "papermill": {
     "duration": 1.661615,
     "end_time": "2021-04-28T18:14:25.413563",
     "exception": false,
     "start_time": "2021-04-28T18:14:23.751948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def uniques(matrix, groupers, name, limitation=None):\n",
    "    if limitation is not None:\n",
    "        s = (\n",
    "            matrix.query(limitation)\n",
    "            .groupby(groupers)\n",
    "            .item_id.nunique()\n",
    "            .rename(name)\n",
    "            .reset_index()\n",
    "        )\n",
    "    else:\n",
    "        s = matrix.groupby(groupers).item_id.nunique().rename(name).reset_index()\n",
    "    matrix = matrix.merge(s, on=groupers, how=\"left\")\n",
    "    matrix[name] = matrix[name].fillna(0)\n",
    "    return matrix\n",
    "\n",
    "\n",
    "matrix = uniques(matrix, [\"date_block_num\"], \"unique_items_month\")\n",
    "\n",
    "matrix = uniques(matrix, [\"date_block_num\", \"item_name_group\"], \"name_group_unique_month\")\n",
    "matrix = uniques(\n",
    "    matrix,\n",
    "    [\"date_block_num\", \"item_category_id\", \"item_name_group\"],\n",
    "    \"name_group_cat_unique_month\",\n",
    ")\n",
    "matrix = uniques(\n",
    "    matrix,\n",
    "    [\"date_block_num\", \"item_name_group\"],\n",
    "    \"name_group_new_unique_month\",\n",
    "    limitation=\"new_item==True\",\n",
    ")\n",
    "matrix = uniques(\n",
    "    matrix,\n",
    "    [\"date_block_num\", \"item_category_id\", \"item_name_group\"],\n",
    "    \"name_group_new_cat_unique_month\",\n",
    "    limitation=\"new_item==True\",\n",
    ")\n",
    "\n",
    "matrix = uniques(\n",
    "    matrix, [\"date_block_num\", \"artist_name_or_first_word\"], \"first_word_unique_month\"\n",
    ")\n",
    "matrix = uniques(\n",
    "    matrix,\n",
    "    [\"date_block_num\", \"item_category_id\", \"artist_name_or_first_word\"],\n",
    "    \"first_word_cat_unique_month\",\n",
    ")\n",
    "matrix = uniques(\n",
    "    matrix,\n",
    "    [\"date_block_num\", \"artist_name_or_first_word\"],\n",
    "    \"first_word_new_unique_month\",\n",
    "    limitation=\"new_item==True\",\n",
    ")\n",
    "matrix = uniques(\n",
    "    matrix,\n",
    "    [\"date_block_num\", \"item_category_id\", \"artist_name_or_first_word\"],\n",
    "    \"first_word_new_cat_unique_month\",\n",
    "    limitation=\"new_item==True\",\n",
    ")\n",
    "\n",
    "matrix = uniques(matrix, [\"date_block_num\", \"item_category_id\"], \"unique_items_cat\")\n",
    "matrix = uniques(\n",
    "    matrix,\n",
    "    [\"date_block_num\", \"item_category_id\"],\n",
    "    \"new_items_cat\",\n",
    "    limitation=\"new_item==True\",\n",
    ")\n",
    "matrix = uniques(matrix, [\"date_block_num\"], \"new_items_month\", limitation=\"new_item==True\")\n",
    "\n",
    "matrix[\"cat_items_proportion\"] = matrix[\"unique_items_cat\"] / matrix[\"unique_items_month\"]\n",
    "matrix[\"name_group_new_proportion_month\"] = (\n",
    "    matrix[\"name_group_new_unique_month\"] / matrix[\"name_group_unique_month\"]\n",
    ")\n",
    "\n",
    "matrix = matrix.drop(columns=[\"unique_items_month\", \"name_group_unique_month\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "papermill": {
     "duration": 5.877312,
     "end_time": "2021-04-28T18:14:31.349756",
     "exception": false,
     "start_time": "2021-04-28T18:14:25.472444",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "matrix, oldcols = shrink_mem_new_cols(matrix, oldcols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.058252,
     "end_time": "2021-04-28T18:14:31.467011",
     "exception": false,
     "start_time": "2021-04-28T18:14:31.408759",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Percentage change in an aggregate feature  \n",
    "This uses the pandas pct_change method to calculate the proportional change in mean sales count for a specific grouping for a specific time interval, e.g. increase / decrease in mean sales of an item between the last 2 months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "papermill": {
     "duration": 0.074182,
     "end_time": "2021-04-28T18:14:31.600743",
     "exception": false,
     "start_time": "2021-04-28T18:14:31.526561",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_pct_change(\n",
    "    matrix,\n",
    "    group_feats,\n",
    "    target=\"item_cnt_month\",\n",
    "    aggfunc=\"mean\",\n",
    "    periods=1,\n",
    "    lag=1,\n",
    "    clip_value=None,\n",
    "):\n",
    "    periods = list_if_not(periods, int)\n",
    "    group_feats = list_if_not(group_feats)\n",
    "    group_feats_full = [\"date_block_num\"] + group_feats\n",
    "    dat = matrix.pivot_table(\n",
    "        index=group_feats + [\"date_block_num\"],\n",
    "        values=target,\n",
    "        aggfunc=aggfunc,\n",
    "        fill_value=0,\n",
    "        dropna=False,\n",
    "    ).astype(\"float32\")\n",
    "    for g in group_feats:\n",
    "        firsts = matrix.groupby(g).date_block_num.min().rename(\"firsts\")\n",
    "        dat = dat.merge(firsts, left_on=g, right_index=True, how=\"left\")\n",
    "        dat.loc[dat.index.get_level_values(\"date_block_num\") < dat[\"firsts\"], target] = float(\n",
    "            \"nan\"\n",
    "        )\n",
    "        del dat[\"firsts\"]\n",
    "    for period in periods:\n",
    "        feat_name = \"_\".join(\n",
    "            group_feats + [target] + [aggfunc] + [\"delta\"] + [str(period)] + [f\"lag_{lag}\"]\n",
    "        )\n",
    "        print(f\"Adding feature {feat_name}\")\n",
    "        dat = (\n",
    "            dat.groupby(group_feats)[target]\n",
    "            .transform(lambda x: x.pct_change(periods=period, fill_method=\"pad\"))\n",
    "            .rename(feat_name)\n",
    "        )\n",
    "        if clip_value is not None:\n",
    "            dat = dat.clip(lower=-clip_value, upper=clip_value)\n",
    "    dat = dat.reset_index()\n",
    "    dat[\"date_block_num\"] += lag\n",
    "    matrix = matrix.merge(dat, on=[\"date_block_num\"] + group_feats, how=\"left\")\n",
    "    matrix[feat_name] = reduce_mem_usage(matrix[feat_name])\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "papermill": {
     "duration": 55.239396,
     "end_time": "2021-04-28T18:15:26.899005",
     "exception": false,
     "start_time": "2021-04-28T18:14:31.659609",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding feature item_id_item_cnt_month_mean_delta_1_lag_1\n",
      "Adding feature item_category_id_item_cnt_month_mean_delta_1_lag_1\n",
      "Adding feature item_name_group_item_cnt_month_mean_delta_1_lag_1\n",
      "Adding feature item_category_id_item_cnt_month_mean_delta_1_lag_12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = add_pct_change(matrix, [\"item_id\"], \"item_cnt_month\", clip_value=3)\n",
    "matrix = add_pct_change(matrix, [\"item_category_id\"], \"item_cnt_month\", clip_value=3)\n",
    "matrix = add_pct_change(matrix, [\"item_name_group\"], \"item_cnt_month\", clip_value=3)\n",
    "# Delta 1 feature lagged by 12 months, intended to capture seasonal trends\n",
    "matrix = add_pct_change(matrix, [\"item_category_id\"], \"item_cnt_month\", lag=12, clip_value=3,)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "papermill": {
     "duration": 1.450712,
     "end_time": "2021-04-28T18:15:28.412578",
     "exception": false,
     "start_time": "2021-04-28T18:15:26.961866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "matrix, oldcols = shrink_mem_new_cols(matrix, oldcols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.063575,
     "end_time": "2021-04-28T18:15:28.537486",
     "exception": false,
     "start_time": "2021-04-28T18:15:28.473911",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Windowed aggregates\n",
    "\n",
    "Features aggregated over a specific window to reduce noise. Available windows are expanding (i.e. all preceding timepoints), rolling (i.e. fixed number of equally weighted timepoints) and exponentially weighted mean.  \n",
    "\n",
    "\n",
    "A note about feature names: these are set automatically according to the pattern < grouping features > - < aggregated features > - < monthly aggregation function > - < window type > , where < window type > is either \"rolling - < window aggregation function > - win - < window length in months >\" for square rolling windows, \"expanding - < window aggregation function >\" for expanding windows, and \"ewm_hl - < decay rate in terms of half-life > for exponential weighted means, all connected by underscores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "papermill": {
     "duration": 0.452093,
     "end_time": "2021-04-28T18:15:29.05061",
     "exception": false,
     "start_time": "2021-04-28T18:15:28.598517",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shop_id = 16\n",
    "item_id = 482\n",
    "im = matrix.query(f\"shop_id=={shop_id} & item_id=={item_id}\")[['date_block_num', 'item_cnt_month']]\n",
    "im['moving average'] = im['item_cnt_month'].ewm(halflife=1).mean()\n",
    "im['expanding mean'] = im['item_cnt_month'].expanding().mean()\n",
    "im['rolling 12 month mean'] = im['item_cnt_month'].rolling(window=12, min_periods=1).mean()\n",
    "im = im.set_index('date_block_num')\n",
    "ax = im.plot(figsize=(12,5), marker='.', title='Time series averaging methods')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "papermill": {
     "duration": 0.088969,
     "end_time": "2021-04-28T18:15:29.204666",
     "exception": false,
     "start_time": "2021-04-28T18:15:29.115697",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_rolling_stats(\n",
    "    matrix,\n",
    "    features,\n",
    "    window=12,\n",
    "    kind=\"rolling\",\n",
    "    argfeat=\"item_cnt_month\",\n",
    "    aggfunc=\"mean\",\n",
    "    rolling_aggfunc=\"mean\",\n",
    "    dtype=\"float16\",\n",
    "    reshape_source=True,\n",
    "    lag_offset=0,\n",
    "):\n",
    "    def rolling_stat(\n",
    "        matrix,\n",
    "        source,\n",
    "        feats,\n",
    "        feat_name,\n",
    "        window=12,\n",
    "        argfeat=\"item_cnt_month\",\n",
    "        aggfunc=\"mean\",\n",
    "        dtype=dtype,\n",
    "        lag_offset=0,\n",
    "    ):\n",
    "        # Calculate a statistic on a windowed section of a source table,  grouping on specific features\n",
    "        store = []\n",
    "        for i in range(2 + lag_offset, 35 + lag_offset):\n",
    "            if len(feats) > 0:\n",
    "                mes = (\n",
    "                    source[source.date_block_num.isin(range(max([i - window, 0]), i))]\n",
    "                    .groupby(feats)[argfeat]\n",
    "                    .agg(aggfunc)\n",
    "                    .astype(dtype)\n",
    "                    .rename(feat_name)\n",
    "                    .reset_index()\n",
    "                )\n",
    "            else:\n",
    "                mes = {}\n",
    "                mes[feat_name] = (\n",
    "                    source.loc[\n",
    "                        source.date_block_num.isin(range(max([i - window, 0]), i)), argfeat\n",
    "                    ]\n",
    "                    .agg(aggfunc)\n",
    "                    .astype(dtype)\n",
    "                )\n",
    "                mes = pd.DataFrame(data=mes, index=[i])\n",
    "            mes[\"date_block_num\"] = i - lag_offset\n",
    "            store.append(mes)\n",
    "        store = pd.concat(store)\n",
    "        matrix = matrix.merge(store, on=feats + [\"date_block_num\"], how=\"left\")\n",
    "        return matrix\n",
    "\n",
    "    \"\"\" An issue when using windowed functions is that missing values from months when items recorded no sales are skipped rather than being correctly\n",
    "    treated as zeroes. Creating a pivot_table fills in the zeros.\"\"\"\n",
    "    if (reshape_source == True) or (kind == \"ewm\"):\n",
    "        source = matrix.pivot_table(\n",
    "            index=features + [\"date_block_num\"],\n",
    "            values=argfeat,\n",
    "            aggfunc=aggfunc,\n",
    "            fill_value=0,\n",
    "            dropna=False,\n",
    "        ).astype(dtype)\n",
    "        for g in features:\n",
    "            firsts = matrix.groupby(g).date_block_num.min().rename(\"firsts\")\n",
    "            source = source.merge(firsts, left_on=g, right_index=True, how=\"left\")\n",
    "            # Set values before the items first appearance to nan so they are ignored rather than being treated as zero sales.\n",
    "            source.loc[\n",
    "                source.index.get_level_values(\"date_block_num\") < source[\"firsts\"], argfeat\n",
    "            ] = float(\"nan\")\n",
    "            del source[\"firsts\"]\n",
    "        source = source.reset_index()\n",
    "    else:\n",
    "        source = matrix\n",
    "\n",
    "    if kind == \"rolling\":\n",
    "        feat_name = (\n",
    "            f\"{'_'.join(features)}_{argfeat}_{aggfunc}_rolling_{rolling_aggfunc}_win_{window}\"\n",
    "        )\n",
    "        print(f'Creating feature \"{feat_name}\"')\n",
    "        return rolling_stat(\n",
    "            matrix,\n",
    "            source,\n",
    "            features,\n",
    "            feat_name,\n",
    "            window=window,\n",
    "            argfeat=argfeat,\n",
    "            aggfunc=rolling_aggfunc,\n",
    "            dtype=dtype,\n",
    "            lag_offset=lag_offset,\n",
    "        )\n",
    "    elif kind == \"expanding\":\n",
    "        feat_name = f\"{'_'.join(features)}_{argfeat}_{aggfunc}_expanding_{rolling_aggfunc}\"\n",
    "        print(f'Creating feature \"{feat_name}\"')\n",
    "        return rolling_stat(\n",
    "            matrix,\n",
    "            source,\n",
    "            features,\n",
    "            feat_name,\n",
    "            window=100,\n",
    "            argfeat=argfeat,\n",
    "            aggfunc=aggfunc,\n",
    "            dtype=dtype,\n",
    "            lag_offset=lag_offset,\n",
    "        )\n",
    "    elif kind == \"ewm\":\n",
    "        feat_name = f\"{'_'.join(features)}_{argfeat}_{aggfunc}_ewm_hl_{window}\"\n",
    "        print(f'Creating feature \"{feat_name}\"')\n",
    "        source[feat_name] = (\n",
    "            source.groupby(features)[argfeat]\n",
    "            .ewm(halflife=window, min_periods=1)\n",
    "            .agg(rolling_aggfunc)\n",
    "            .to_numpy(dtype=dtype)\n",
    "        )\n",
    "        del source[argfeat]\n",
    "        #         source = source.reset_index()\n",
    "        source[\"date_block_num\"] += 1 - lag_offset\n",
    "        return matrix.merge(source, on=[\"date_block_num\"] + features, how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.063375,
     "end_time": "2021-04-28T18:15:29.331871",
     "exception": false,
     "start_time": "2021-04-28T18:15:29.268496",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Create rolling mean features. The combinations of grouping features and window types here were selected by generating a large number of features and then pruning them with the scikit-learn RFECV function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "papermill": {
     "duration": 1905.447107,
     "end_time": "2021-04-28T18:47:14.842926",
     "exception": false,
     "start_time": "2021-04-28T18:15:29.395819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating feature \"shop_id_artist_name_or_first_word_item_category_id_item_age_item_cnt_month_mean_rolling_mean_win_12\"\n",
      "Creating feature \"shop_id_artist_name_or_first_word_item_category_id_new_item_item_cnt_month_mean_expanding_mean\"\n",
      "Creating feature \"shop_id_artist_name_or_first_word_new_item_item_cnt_month_mean_expanding_mean\"\n",
      "Creating feature \"shop_id_category_cluster_item_cnt_month_mean_rolling_mean_win_12\"\n",
      "Creating feature \"shop_id_item_category_id_item_age_item_cnt_month_mean_expanding_mean\"\n",
      "Creating feature \"shop_id_item_category_id_item_age_item_cnt_month_mean_rolling_mean_win_12\"\n",
      "Creating feature \"shop_id_item_category_id_item_cnt_month_mean_ewm_hl_1\"\n",
      "Creating feature \"shop_id_item_category_id_new_item_item_cnt_month_mean_expanding_mean\"\n",
      "Creating feature \"shop_id_item_category_id_new_item_item_cnt_month_mean_rolling_mean_win_12\"\n",
      "Creating feature \"shop_id_item_cnt_month_mean_rolling_mean_win_12\"\n",
      "Creating feature \"shop_id_item_id_item_cnt_month_mean_ewm_hl_1\"\n",
      "Creating feature \"shop_id_item_id_item_cnt_month_mean_rolling_mean_win_12\"\n",
      "Creating feature \"shop_id_item_name_group_item_category_id_new_item_item_cnt_month_mean_rolling_mean_win_12\"\n",
      "Creating feature \"shop_id_item_name_group_new_item_item_cnt_month_mean_expanding_mean\"\n",
      "Creating feature \"shop_id_supercategory_id_new_item_item_cnt_month_mean_rolling_mean_win_12\"\n",
      "Creating feature \"shop_cluster_item_id_item_cnt_month_mean_ewm_hl_1\"\n",
      "Creating feature \"shop_cluster_item_category_id_item_age_item_cnt_month_mean_expanding_mean\"\n",
      "Creating feature \"shop_cluster_item_name_group_new_item_item_cnt_month_mean_rolling_mean_win_12\"\n",
      "Creating feature \"category_cluster_item_age_item_cnt_month_mean_expanding_mean\"\n",
      "Creating feature \"category_cluster_new_item_item_cnt_month_mean_expanding_mean\"\n",
      "Creating feature \"item_id_item_cnt_month_mean_rolling_mean_win_12\"\n",
      "Creating feature \"artist_name_or_first_word_item_cnt_month_mean_rolling_mean_win_12\"\n",
      "Creating feature \"artist_name_or_first_word_item_cnt_month_mean_ewm_hl_1\"\n",
      "Creating feature \"artist_name_or_first_word_item_age_item_cnt_month_mean_rolling_mean_win_12\"\n",
      "Creating feature \"artist_name_or_first_word_item_category_id_item_age_item_cnt_month_mean_rolling_mean_win_12\"\n",
      "Creating feature \"artist_name_or_first_word_new_item_item_cnt_month_mean_expanding_mean\"\n",
      "Creating feature \"item_category_id_item_age_item_cnt_month_mean_expanding_mean\"\n",
      "Creating feature \"item_category_id_item_cnt_month_mean_rolling_mean_win_12\"\n",
      "Creating feature \"item_category_id_item_cnt_month_mean_ewm_hl_1\"\n",
      "Creating feature \"item_category_id_new_item_item_cnt_month_mean_expanding_mean\"\n",
      "Creating feature \"item_name_group_item_age_item_cnt_month_mean_rolling_mean_win_12\"\n",
      "Creating feature \"item_name_group_item_cnt_month_mean_ewm_hl_1\"\n",
      "Creating feature \"item_name_group_item_cnt_month_mean_rolling_mean_win_12\"\n",
      "Creating feature \"platform_id_item_cnt_month_mean_rolling_mean_win_12\"\n",
      "Creating feature \"platform_id_item_cnt_month_mean_ewm_hl_1\"\n"
     ]
    }
   ],
   "source": [
    "matrix = add_rolling_stats(\n",
    "    matrix,\n",
    "    [\"shop_id\", \"artist_name_or_first_word\", \"item_category_id\", \"item_age\"],\n",
    "    window=12,\n",
    "    reshape_source=False,\n",
    ")\n",
    "matrix = add_rolling_stats(\n",
    "    matrix,\n",
    "    [\"shop_id\", \"artist_name_or_first_word\", \"item_category_id\", \"new_item\"],\n",
    "    kind=\"expanding\",\n",
    "    reshape_source=False,\n",
    ")\n",
    "matrix = add_rolling_stats(\n",
    "    matrix,\n",
    "    [\"shop_id\", \"artist_name_or_first_word\", \"new_item\"],\n",
    "    kind=\"expanding\",\n",
    "    reshape_source=False,\n",
    ")\n",
    "matrix = add_rolling_stats(matrix, [\"shop_id\", \"category_cluster\"], window=12)\n",
    "matrix = add_rolling_stats(\n",
    "    matrix,\n",
    "    [\"shop_id\", \"item_category_id\", \"item_age\"],\n",
    "    kind=\"expanding\",\n",
    "    reshape_source=False,\n",
    ")\n",
    "matrix = add_rolling_stats(\n",
    "    matrix, [\"shop_id\", \"item_category_id\", \"item_age\"], window=12, reshape_source=False\n",
    ")\n",
    "matrix = add_rolling_stats(matrix, [\"shop_id\", \"item_category_id\"], kind=\"ewm\", window=1)\n",
    "matrix = add_rolling_stats(\n",
    "    matrix,\n",
    "    [\"shop_id\", \"item_category_id\", \"new_item\"],\n",
    "    kind=\"expanding\",\n",
    "    reshape_source=False,\n",
    ")\n",
    "matrix = add_rolling_stats(\n",
    "    matrix, [\"shop_id\", \"item_category_id\", \"new_item\"], window=12, reshape_source=False\n",
    ")\n",
    "matrix = add_rolling_stats(matrix, [\"shop_id\"], window=12)\n",
    "matrix = add_rolling_stats(matrix, [\"shop_id\", \"item_id\"], kind=\"ewm\", window=1)\n",
    "matrix = add_rolling_stats(matrix, [\"shop_id\", \"item_id\"], window=12)\n",
    "matrix = add_rolling_stats(\n",
    "    matrix,\n",
    "    [\"shop_id\", \"item_name_group\", \"item_category_id\", \"new_item\"],\n",
    "    window=12,\n",
    "    reshape_source=False,\n",
    ")\n",
    "matrix = add_rolling_stats(\n",
    "    matrix, [\"shop_id\", \"item_name_group\", \"new_item\"], kind=\"expanding\", reshape_source=False\n",
    ")\n",
    "matrix = add_rolling_stats(\n",
    "    matrix, [\"shop_id\", \"supercategory_id\", \"new_item\"], window=12, reshape_source=False\n",
    ")\n",
    "\n",
    "matrix = add_rolling_stats(matrix, [\"shop_cluster\", \"item_id\"], kind=\"ewm\", window=1)\n",
    "matrix = add_rolling_stats(\n",
    "    matrix,\n",
    "    [\"shop_cluster\", \"item_category_id\", \"item_age\"],\n",
    "    kind=\"expanding\",\n",
    "    reshape_source=False,\n",
    ")\n",
    "matrix = add_rolling_stats(\n",
    "    matrix, [\"shop_cluster\", \"item_name_group\", \"new_item\"], window=12, reshape_source=False\n",
    ")\n",
    "\n",
    "matrix = add_rolling_stats(\n",
    "    matrix, [\"category_cluster\", \"item_age\"], kind=\"expanding\", reshape_source=False\n",
    ")\n",
    "matrix = add_rolling_stats(\n",
    "    matrix, [\"category_cluster\", \"new_item\"], kind=\"expanding\", reshape_source=False\n",
    ")\n",
    "\n",
    "matrix = add_rolling_stats(matrix, [\"item_id\"], window=12)\n",
    "\n",
    "matrix = add_rolling_stats(matrix, [\"artist_name_or_first_word\"], window=12)\n",
    "matrix = add_rolling_stats(matrix, [\"artist_name_or_first_word\"], kind=\"ewm\", window=1)\n",
    "matrix = add_rolling_stats(\n",
    "    matrix, [\"artist_name_or_first_word\", \"item_age\"], window=12, reshape_source=False\n",
    ")\n",
    "matrix = add_rolling_stats(\n",
    "    matrix,\n",
    "    [\"artist_name_or_first_word\", \"item_category_id\", \"item_age\"],\n",
    "    window=12,\n",
    "    reshape_source=False,\n",
    ")\n",
    "matrix = add_rolling_stats(\n",
    "    matrix, [\"artist_name_or_first_word\", \"new_item\"], kind=\"expanding\", reshape_source=False\n",
    ")\n",
    "\n",
    "matrix = add_rolling_stats(\n",
    "    matrix, [\"item_category_id\", \"item_age\"], kind=\"expanding\", reshape_source=False\n",
    ")\n",
    "matrix = add_rolling_stats(matrix, [\"item_category_id\"], window=12)\n",
    "matrix = add_rolling_stats(matrix, [\"item_category_id\"], kind=\"ewm\", window=1)\n",
    "matrix = add_rolling_stats(\n",
    "    matrix, [\"item_category_id\", \"new_item\"], kind=\"expanding\", reshape_source=False\n",
    ")\n",
    "\n",
    "matrix = add_rolling_stats(\n",
    "    matrix, [\"item_name_group\", \"item_age\"], window=12, reshape_source=False\n",
    ")\n",
    "matrix = add_rolling_stats(matrix, [\"item_name_group\"], kind=\"ewm\", window=1)\n",
    "matrix = add_rolling_stats(matrix, [\"item_name_group\"], window=12)\n",
    "\n",
    "matrix = add_rolling_stats(matrix, [\"platform_id\"], window=12)\n",
    "matrix = add_rolling_stats(matrix, [\"platform_id\"], kind=\"ewm\", window=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "papermill": {
     "duration": 17.789665,
     "end_time": "2021-04-28T18:47:32.707445",
     "exception": false,
     "start_time": "2021-04-28T18:47:14.91778",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved matrixcheckpoint\n",
      "Widnow aggregate features created\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "matrix, oldcols = shrink_mem_new_cols(matrix, oldcols)\n",
    "\n",
    "matrix.to_pickle(\"matrixcheckpoint1.pkl\")\n",
    "print(\"Saved matrixcheckpoint\")\n",
    "gc.collect()\n",
    "\n",
    "print(\"Widnow aggregate features created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.448793,
     "end_time": "2021-04-28T18:47:36.713076",
     "exception": false,
     "start_time": "2021-04-28T18:47:36.264283",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The following code block calculates windowed mean sales features with day resolution accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "papermill": {
     "duration": 92.446203,
     "end_time": "2021-04-28T18:49:09.252422",
     "exception": false,
     "start_time": "2021-04-28T18:47:36.806219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating feature \"shop_id_item_id_item_cnt_month_sum_rolling_sum_win_12\"\n",
      "Creating feature \"item_id_item_cnt_month_sum_expanding_sum\"\n"
     ]
    }
   ],
   "source": [
    "# Summed sales & accurate windowed mean sales per day features\n",
    "matrix = add_rolling_stats(\n",
    "    matrix,\n",
    "    [\"shop_id\", \"item_id\"],\n",
    "    aggfunc=\"sum\",\n",
    "    rolling_aggfunc=\"sum\",\n",
    "    kind=\"rolling\",\n",
    "    window=12,\n",
    "    reshape_source=False,\n",
    ")\n",
    "matrix = add_rolling_stats(\n",
    "    matrix,\n",
    "    [\"item_id\"],\n",
    "    aggfunc=\"sum\",\n",
    "    rolling_aggfunc=\"sum\",\n",
    "    kind=\"expanding\",\n",
    "    reshape_source=False,\n",
    ")\n",
    "matrix[\"1year\"] = 365\n",
    "matrix[\"item_id_day_mean_expanding\"] = matrix[\n",
    "    \"item_id_item_cnt_month_sum_expanding_sum\"\n",
    "] / matrix[[\"first_item_sale_days\"]].min(axis=1)\n",
    "matrix[\"shop_id_item_id_day_mean_win_12\"] = matrix[\n",
    "    \"shop_id_item_id_item_cnt_month_sum_rolling_sum_win_12\"\n",
    "] / matrix[[\"first_item_sale_days\", \"shop_open_days\", \"1year\"]].min(axis=1)\n",
    "matrix.loc[matrix.new_item == True, \"item_id_day_mean_expanding\",] = float(\"nan\")\n",
    "matrix = matrix.drop(columns=[\"1year\", \"item_id_item_cnt_month_sum_expanding_sum\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.217115,
     "end_time": "2021-04-28T18:49:09.640666",
     "exception": false,
     "start_time": "2021-04-28T18:49:09.423551",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Revenue features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "papermill": {
     "duration": 91.965703,
     "end_time": "2021-04-28T18:50:41.781069",
     "exception": false,
     "start_time": "2021-04-28T18:49:09.815366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating feature \"shop_id_item_name_group_item_revenue_month_mean_rolling_mean_win_12\"\n"
     ]
    }
   ],
   "source": [
    "matrix = add_rolling_stats(\n",
    "    matrix,\n",
    "    [\"shop_id\", \"item_name_group\"],\n",
    "    window=12,\n",
    "    argfeat=\"item_revenue_month\",\n",
    "    dtype=\"float32\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.090066,
     "end_time": "2021-04-28T18:50:41.952101",
     "exception": false,
     "start_time": "2021-04-28T18:50:41.862035",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Windowed mean unique item features and ratio of new items in category with mean over the previous year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "papermill": {
     "duration": 28.595028,
     "end_time": "2021-04-28T18:51:10.635694",
     "exception": false,
     "start_time": "2021-04-28T18:50:42.040666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating feature \"item_category_id_new_items_cat_mean_rolling_mean_win_12\"\n",
      "Creating feature \"item_name_group_name_group_new_unique_month_mean_rolling_mean_win_12\"\n"
     ]
    }
   ],
   "source": [
    "matrix = add_rolling_stats(\n",
    "    matrix,\n",
    "    [\"item_category_id\"],\n",
    "    argfeat=\"new_items_cat\",\n",
    "    window=12,\n",
    "    reshape_source=True,\n",
    "    lag_offset=1,\n",
    ")\n",
    "matrix = add_rolling_stats(\n",
    "    matrix,\n",
    "    [\"item_name_group\"],\n",
    "    argfeat=\"name_group_new_unique_month\",\n",
    "    window=12,\n",
    "    reshape_source=True,\n",
    "    lag_offset=1,\n",
    ")\n",
    "\n",
    "matrix[\"new_items_cat_1_12_ratio\"] = (\n",
    "    matrix[\"new_items_cat\"]\n",
    "    / matrix[\"item_category_id_new_items_cat_mean_rolling_mean_win_12\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "papermill": {
     "duration": 7.661105,
     "end_time": "2021-04-28T18:51:18.734463",
     "exception": false,
     "start_time": "2021-04-28T18:51:11.073358",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "matrix, oldcols = shrink_mem_new_cols(matrix, oldcols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.108926,
     "end_time": "2021-04-28T18:51:19.025566",
     "exception": false,
     "start_time": "2021-04-28T18:51:18.91664",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Lagged features and mean encodings  \n",
    "Values for the same shop-item combination from previous months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "papermill": {
     "duration": 0.091696,
     "end_time": "2021-04-28T18:51:19.215776",
     "exception": false,
     "start_time": "2021-04-28T18:51:19.12408",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def simple_lag_feature(matrix, lag_feature, lags):\n",
    "    for lag in lags:\n",
    "        newname = lag_feature + f\"_lag_{lag}\"\n",
    "        print(f\"Adding feature {newname}\")\n",
    "        targetseries = matrix.loc[:, [\"date_block_num\", \"item_id\", \"shop_id\"] + [lag_feature]]\n",
    "        targetseries[\"date_block_num\"] += lag\n",
    "        targetseries = targetseries.rename(columns={lag_feature: newname})\n",
    "        matrix = matrix.merge(\n",
    "            targetseries, on=[\"date_block_num\", \"item_id\", \"shop_id\"], how=\"left\"\n",
    "        )\n",
    "        matrix.loc[\n",
    "            (matrix.item_age >= lag) & (matrix.shop_age >= lag) & (matrix[newname].isna()),\n",
    "            newname,\n",
    "        ] = 0\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "papermill": {
     "duration": 120.906823,
     "end_time": "2021-04-28T18:53:20.206272",
     "exception": false,
     "start_time": "2021-04-28T18:51:19.299449",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding feature item_cnt_month_lag_1\n",
      "Adding feature item_cnt_month_lag_2\n",
      "Adding feature item_cnt_month_lag_3\n",
      "Adding feature item_cnt_month_lag_4\n",
      "Adding feature item_cnt_month_lag_5\n",
      "Adding feature item_cnt_month_lag_6\n",
      "Adding feature item_cnt_month_lag_12\n",
      "Adding feature item_cnt_day_avg_lag_1\n",
      "Adding feature item_cnt_day_avg_lag_2\n",
      "Adding feature item_cnt_day_avg_lag_3\n",
      "Adding feature item_cnt_day_avg_lag_4\n",
      "Adding feature item_cnt_day_avg_lag_5\n",
      "Adding feature item_cnt_day_avg_lag_6\n",
      "Adding feature item_cnt_day_avg_lag_12\n",
      "Adding feature item_revenue_month_lag_1\n",
      "Lag features created\n"
     ]
    }
   ],
   "source": [
    "matrix = simple_lag_feature(matrix, 'item_cnt_month', lags=[1, 2, 3])\n",
    "matrix = simple_lag_feature(matrix, 'item_cnt_day_avg', lags=[1, 2, 3])\n",
    "matrix = simple_lag_feature(matrix, 'item_revenue_month', lags=[1])\n",
    "gc.collect()\n",
    "print(\"Lag features created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.084107,
     "end_time": "2021-04-28T18:53:20.373538",
     "exception": false,
     "start_time": "2021-04-28T18:53:20.289431",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Mean encodings\n",
    "The mean or sum value of a target feature for each level of a categorical feature or combination of categorical features, lagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "papermill": {
     "duration": 0.093518,
     "end_time": "2021-04-28T18:53:20.548179",
     "exception": false,
     "start_time": "2021-04-28T18:53:20.454661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_apply_ME(\n",
    "    matrix, grouping_fields, lags=[1], target=\"item_cnt_day_avg\", aggfunc=\"mean\"\n",
    "):\n",
    "    grouping_fields = list_if_not(grouping_fields)\n",
    "    for lag in lags:\n",
    "        newname = \"_\".join(grouping_fields + [target] + [aggfunc] + [f\"lag_{lag}\"])\n",
    "        print(f\"Adding feature {newname}\")\n",
    "        me_series = (\n",
    "            matrix.groupby([\"date_block_num\"] + grouping_fields)[target]\n",
    "            .agg(aggfunc)\n",
    "            .rename(newname)\n",
    "            .reset_index()\n",
    "        )\n",
    "        me_series[\"date_block_num\"] += lag\n",
    "        matrix = matrix.merge(me_series, on=[\"date_block_num\"] + grouping_fields, how=\"left\")\n",
    "        del me_series\n",
    "        matrix[newname] = matrix[newname].fillna(0)\n",
    "        for g in grouping_fields:\n",
    "            firsts = matrix.groupby(g).date_block_num.min().rename(\"firsts\")\n",
    "            matrix = matrix.merge(firsts, left_on=g, right_index=True, how=\"left\")\n",
    "            matrix.loc[\n",
    "                matrix[\"date_block_num\"] < (matrix[\"firsts\"] + (lag)), newname\n",
    "            ] = float(\"nan\")\n",
    "            del matrix[\"firsts\"]\n",
    "        matrix[newname] = reduce_mem_usage(matrix[newname])\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "papermill": {
     "duration": 116.204762,
     "end_time": "2021-04-28T18:55:16.832993",
     "exception": false,
     "start_time": "2021-04-28T18:53:20.628231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding feature item_name_group_item_cnt_month_mean_lag_1\n",
      "Adding feature item_name_group_item_cnt_month_sum_lag_1\n",
      "Adding feature item_id_item_cnt_month_mean_lag_1\n",
      "Adding feature item_id_item_cnt_day_avg_mean_lag_1\n",
      "Adding feature platform_id_item_cnt_day_avg_mean_lag_1\n",
      "Adding feature item_name_group_item_cnt_day_avg_mean_lag_1\n",
      "Adding feature platform_id_item_cnt_month_mean_lag_1\n",
      "Adding feature supercategory_id_item_cnt_day_avg_mean_lag_1\n",
      "Adding feature item_category_id_new_item_item_cnt_month_mean_lag_1\n",
      "Adding feature shop_id_item_category_id_item_cnt_month_mean_lag_1\n",
      "Adding feature shop_cluster_item_id_item_cnt_month_mean_lag_1\n",
      "Adding feature shop_cluster_item_id_item_cnt_day_avg_mean_lag_1\n",
      "Adding feature city_code_item_id_item_cnt_day_avg_mean_lag_1\n",
      "Adding feature city_code_item_name_group_item_cnt_day_avg_mean_lag_1\n",
      "Adding feature shop_type_item_id_item_cnt_day_avg_mean_lag_1\n",
      "Adding feature shop_type_item_id_item_cnt_month_mean_lag_1\n"
     ]
    }
   ],
   "source": [
    "matrix = create_apply_ME(matrix, [\"item_name_group\"], target=\"item_cnt_month\")\n",
    "matrix = create_apply_ME(matrix, [\"item_name_group\"], target=\"item_cnt_month\", aggfunc=\"sum\")\n",
    "matrix = create_apply_ME(matrix, [\"item_id\"], target=\"item_cnt_month\")\n",
    "matrix = create_apply_ME(matrix, [\"item_id\"])\n",
    "matrix = create_apply_ME(matrix, [\"platform_id\"])\n",
    "matrix = create_apply_ME(matrix, [\"item_name_group\"])\n",
    "matrix = create_apply_ME(matrix, [\"platform_id\"], target=\"item_cnt_month\")\n",
    "matrix = create_apply_ME(matrix, [\"supercategory_id\"])\n",
    "matrix = create_apply_ME(matrix, [\"item_category_id\", \"new_item\"], target=\"item_cnt_month\")\n",
    "matrix = create_apply_ME(matrix, [\"shop_id\", \"item_category_id\"], target=\"item_cnt_month\")\n",
    "matrix = create_apply_ME(matrix, [\"shop_cluster\", \"item_id\"], target=\"item_cnt_month\")\n",
    "matrix = create_apply_ME(matrix, [\"shop_cluster\", \"item_id\"])\n",
    "matrix = create_apply_ME(matrix, [\"city_code\", \"item_id\"])\n",
    "matrix = create_apply_ME(matrix, [\"city_code\", \"item_name_group\"])\n",
    "matrix = create_apply_ME(matrix, [\"shop_type\", \"item_id\"])\n",
    "matrix = create_apply_ME(matrix, [\"shop_type\", \"item_id\"], target=\"item_cnt_month\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.085228,
     "end_time": "2021-04-28T18:55:17.004209",
     "exception": false,
     "start_time": "2021-04-28T18:55:16.918981",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Ratios between lag 1 sales and rolling 12 month means, to capture decreases from previous means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "papermill": {
     "duration": 0.12325,
     "end_time": "2021-04-28T18:55:17.213537",
     "exception": false,
     "start_time": "2021-04-28T18:55:17.090287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "matrix[\"item_id_item_cnt_1_12_ratio\"] = (\n",
    "    matrix[\"item_id_item_cnt_month_mean_lag_1\"]\n",
    "    / matrix[\"item_id_item_cnt_month_mean_rolling_mean_win_12\"]\n",
    ")\n",
    "matrix[\"shop_id_item_id_item_cnt_1_12_ratio\"] = (\n",
    "    matrix[\"item_cnt_day_avg_lag_1\"] / matrix[\"shop_id_item_id_day_mean_win_12\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "papermill": {
     "duration": 11.498338,
     "end_time": "2021-04-28T18:55:28.796406",
     "exception": false,
     "start_time": "2021-04-28T18:55:17.298068",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved matrixcheckpoint\n",
      "Mean encoding features created\n"
     ]
    }
   ],
   "source": [
    "matrix, oldcols = shrink_mem_new_cols(matrix, oldcols)\n",
    "matrix.to_pickle(\"matrixcheckpoint2.pkl\")\n",
    "print(\"Saved matrixcheckpoint\")\n",
    "gc.collect()\n",
    "print(\"Mean encoding features created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 2.295401,
     "end_time": "2021-04-28T18:55:46.830211",
     "exception": false,
     "start_time": "2021-04-28T18:55:44.53481",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Some columns that were used to generate other features can now be discarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "papermill": {
     "duration": 5.783446,
     "end_time": "2021-04-28T18:55:54.944188",
     "exception": false,
     "start_time": "2021-04-28T18:55:49.160742",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "surplus_columns = [\n",
    "    \"item_revenue_month\",\n",
    "    \"item_cnt_day_avg\",\n",
    "    \"item_name_group\",\n",
    "    \"artist_name_or_first_word\",\n",
    "    \"item_age\",\n",
    "    \"shop_open_days\",\n",
    "    \"shop_age\",\n",
    "    \"platform_id\",\n",
    "    \"supercategory_id\",\n",
    "    \"city_code\",\n",
    "    \"category_cluster\",\n",
    "    \"shop_cluster\",\n",
    "    \"shop_type\",\n",
    "    \"new_items_cat\",\n",
    "    \"shop_id_item_id_day_mean_win_12\",\n",
    "    \"item_id_item_cnt_month_mean_rolling_mean_win_12\",\n",
    "]\n",
    "matrix = matrix.drop(columns=surplus_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.084959,
     "end_time": "2021-04-28T18:55:55.115949",
     "exception": false,
     "start_time": "2021-04-28T18:55:55.03099",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Predictive words in item_name\n",
    "\n",
    "One-hot features are made for words in the item_name field that are predictive of item sales.  \n",
    "\n",
    "To select *k* word features from the 1000's of words found in item names, words are discarded if they are not in the names of a threshold number of items, or are not in the names of new items in the test or validation months. Remaining words are then selected by the scikit-learn SelectKBest function according to their correlation with the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "papermill": {
     "duration": 0.117744,
     "end_time": "2021-04-28T18:55:55.579227",
     "exception": false,
     "start_time": "2021-04-28T18:55:55.461483",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", module=\"sklearn\")\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "\n",
    "def name_token_feats(matrix, items, k=50, item_n_threshold=5, target_month_start=33):\n",
    "    def name_correction(st):\n",
    "        st = re.sub(r\"[^\\w\\s]\", \"\", st)\n",
    "        st = re.sub(r\"\\s{2,}\", \" \", st)\n",
    "        st = st.lower().strip()\n",
    "        return st\n",
    "\n",
    "    items[\"item_name_clean\"] = items[\"item_name\"].apply(name_correction)\n",
    "\n",
    "    def create_item_id_bow_matrix(items):\n",
    "        all_stopwords = stopwords.words(\"russian\")\n",
    "        all_stopwords = all_stopwords + stopwords.words(\"english\")\n",
    "\n",
    "        vectorizer = CountVectorizer(stop_words=all_stopwords)\n",
    "        X = vectorizer.fit_transform(items.loc[:, \"item_name_clean\"])\n",
    "        X = pd.DataFrame.sparse.from_spmatrix(X)\n",
    "        print(f\"{len(vectorizer.vocabulary_)} words found in all items\")\n",
    "        featuremap = {\n",
    "            col: \"word_\" + token\n",
    "            for col, token in zip(\n",
    "                range(len(vectorizer.vocabulary_)), vectorizer.get_feature_names()\n",
    "            )\n",
    "        }\n",
    "        X = X.rename(columns=featuremap)\n",
    "        return X\n",
    "\n",
    "    items_bow = create_item_id_bow_matrix(items)\n",
    "    items_bow = items_bow.clip(0, 1)  # Made the word counts binary\n",
    "    common_word_mask = items_bow.sum(axis=0) > item_n_threshold\n",
    "    target_items = matrix.query(\n",
    "        f\"date_block_num>={target_month_start} & new_item==True\"\n",
    "    ).item_id.unique()\n",
    "    target_item_mask = items_bow.loc[target_items, :].sum(axis=0) > 1\n",
    "    items_bow = items_bow.loc[:, common_word_mask & target_item_mask]\n",
    "    print(f\"{items_bow.shape[1]} words of interest\")\n",
    "    mxbow = matrix[[\"date_block_num\", \"item_id\", \"item_cnt_month\"]].query(\"date_block_num<34\")\n",
    "    mxbow = mxbow.merge(items_bow, left_on=\"item_id\", right_index=True, how=\"left\")\n",
    "    X = mxbow.drop(columns=[\"date_block_num\", \"item_id\", \"item_cnt_month\"])\n",
    "    y = mxbow[\"item_cnt_month\"].clip(0, 20)\n",
    "    selektor = SelectKBest(f_regression, k=k)\n",
    "    selektor.fit(X, y)\n",
    "    tokencols = X.columns[selektor.get_support()]\n",
    "    print(f\"{k} word features selected\")\n",
    "    return items_bow[tokencols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "papermill": {
     "duration": 1213.623185,
     "end_time": "2021-04-28T19:16:09.288159",
     "exception": false,
     "start_time": "2021-04-28T18:55:55.664974",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19134 words found in all items\n",
      "449 words of interest\n",
      "50 word features selected\n"
     ]
    }
   ],
   "source": [
    "items = pd.read_csv(\"items.csv.zip\")\n",
    "word_frame = name_token_feats(matrix, items, k=50, item_n_threshold=5)\n",
    "matrix = matrix.merge(word_frame, left_on='item_id', right_index=True, how='left')\n",
    "# LightGBM didn't seem to work with sparse features in this case, so we'll convert them to int\n",
    "sparsecols = [c for c in matrix.columns if pd.api.types.is_sparse(matrix[c].dtype)]\n",
    "matrix[sparsecols] = matrix[sparsecols].sparse.to_dense().astype('int8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final feature frame is saved and the notebook kernel is reset to free up memory for LightGBM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "papermill": {
     "duration": 8.028085,
     "end_time": "2021-04-28T19:16:22.397834",
     "exception": false,
     "start_time": "2021-04-28T19:16:14.369749",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All features generated, dataframe saved\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "matrix.to_pickle(\"checkpoint_final.pkl\")\n",
    "print(\"All features generated, dataframe saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.44176,
     "end_time": "2021-04-28T19:16:23.862813",
     "exception": false,
     "start_time": "2021-04-28T19:16:23.421053",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.08846,
     "end_time": "2021-04-28T19:16:24.040872",
     "exception": false,
     "start_time": "2021-04-28T19:16:23.952412",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "papermill": {
     "duration": 0.098249,
     "end_time": "2021-04-28T19:16:24.227277",
     "exception": false,
     "start_time": "2021-04-28T19:16:24.129028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "from tqdm.notebook import tqdm as tqdm_notebook\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature frame is loaded and the target is clipped to match the test items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = pd.read_pickle(\"checkpoint_final.pkl\")\n",
    "matrix['item_cnt_month'] = matrix['item_cnt_month'].clip(0,20)\n",
    "# drop first 2 months\n",
    "matrix = matrix[matrix.date_block_num >= 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [c for c in matrix.columns if c.endswith('lag_4') or c.endswith('lag_5') or c.endswith('lag_6') or c.endswith('lag_12')]\n",
    "matrix = matrix.drop(cols, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize the model with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-26 09:24:34,429]\u001b[0m A new study created in memory with name: no-name-aab13a04-f1e2-4061-aacc-021e4e10a88f\u001b[0m\n",
      "/home/alex/.local/lib/python3.8/site-packages/lightgbm/basic.py:1705: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['item_category_id', 'month', 'season']\n",
      "  _log_warning('categorical_feature in Dataset is overridden.\\n'\n",
      "\u001b[33m[W 2021-08-26 09:24:44,330]\u001b[0m Trial 0 failed because of the following error: LightGBMError('GPU Tree Learner was not enabled in this build.\\nPlease recompile with CMake option -DUSE_GPU=1')\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/alex/.local/lib/python3.8/site-packages/optuna/_optimize.py\", line 217, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"<ipython-input-6-39da7385a387>\", line 45, in objective\n",
      "    gbm = lgb.train(\n",
      "  File \"/home/alex/.local/lib/python3.8/site-packages/lightgbm/engine.py\", line 228, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/home/alex/.local/lib/python3.8/site-packages/lightgbm/basic.py\", line 2234, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/home/alex/.local/lib/python3.8/site-packages/lightgbm/basic.py\", line 110, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\u001b[0m\n"
     ]
    },
    {
     "ename": "LightGBMError",
     "evalue": "GPU Tree Learner was not enabled in this build.\nPlease recompile with CMake option -DUSE_GPU=1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLightGBMError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-39da7385a387>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpruner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpruners\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMedianPruner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_warmup_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"minimize\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/optuna/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    398\u001b[0m             )\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    401\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTrialState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFAIL\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc_err\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-39da7385a387>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m# Add a callback for pruning.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mpruning_callback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLightGBMPruningCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"auc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     gbm = lgb.train(\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0;31m# construct booster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m         \u001b[0mbooster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBooster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_train_data_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, train_set, model_file, model_str, silent)\u001b[0m\n\u001b[1;32m   2232\u001b[0m             \u001b[0mparams_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_dict_to_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2233\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2234\u001b[0;31m             _safe_call(_LIB.LGBM_BoosterCreate(\n\u001b[0m\u001b[1;32m   2235\u001b[0m                 \u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2236\u001b[0m                 \u001b[0mc_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_safe_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \"\"\"\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLGBM_GetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLightGBMError\u001b[0m: GPU Tree Learner was not enabled in this build.\nPlease recompile with CMake option -DUSE_GPU=1"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "cat_feats = ['item_category_id', 'month', 'season']\n",
    "\n",
    "last_block = 33\n",
    "dates = matrix['date_block_num']\n",
    "\n",
    "# drop target and some features that lead to overfitting\n",
    "cols_to_drop = ['item_cnt_month', 'new_item', 'shop_id', 'item_id']\n",
    "\n",
    "# split dataset on train and test sets for model training\n",
    "X_train = matrix.loc[dates <  last_block].drop(cols_to_drop, axis=1)\n",
    "X_val = matrix.loc[dates ==  last_block].drop(cols_to_drop, axis=1)\n",
    "X_test = matrix.loc[dates ==  34].drop(cols_to_drop, axis=1)\n",
    "\n",
    "y_train = matrix.loc[dates <  last_block, 'item_cnt_month']\n",
    "y_val = matrix.loc[dates ==  last_block, 'item_cnt_month']\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    dtrain = lgb.Dataset(X_train, label=y_train)\n",
    "    dvalid = lgb.Dataset(X_val, label=y_val)\n",
    "\n",
    "    param = {\n",
    "        \"objective\": \"mse\",\n",
    "        \"metric\": \"rmse\",\n",
    "        \"verbosity\": 1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"device\": \"gpu\",\n",
    "        \"gpu_platform_id\": 0,\n",
    "        \"gpu_device_id\": 0,\n",
    "        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n",
    "        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 1024),\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "    }\n",
    "\n",
    "    # Add a callback for pruning.\n",
    "    pruning_callback = optuna.integration.LightGBMPruningCallback(trial, \"auc\")\n",
    "    gbm = lgb.train(\n",
    "            param, \n",
    "            dtrain, \n",
    "            valid_sets=[dvalid], \n",
    "            verbose_eval=100,\n",
    "            categorical_feature=cat_feats,\n",
    "            callbacks=[pruning_callback]\n",
    "    )\n",
    "\n",
    "    preds = gbm.predict(valid_x)\n",
    "    accuracy = mean_squared_error(valid_y, preds, squared=False)\n",
    "    return accuracy\n",
    "\n",
    "study = optuna.create_study(pruner=optuna.pruners.MedianPruner(n_warmup_steps=10), direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-25 17:12:54,485]\u001b[0m A new study created in memory with name: no-name-fd1b473f-b78c-48a3-8132-fe2dc09b2a02\u001b[0m\n",
      "feature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]/home/alex/.local/lib/python3.8/site-packages/lightgbm/basic.py:1705: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['item_category_id', 'month']\n",
      "  _log_warning('categorical_feature in Dataset is overridden.\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 3.274649 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/.local/lib/python3.8/site-packages/lightgbm/basic.py:1433: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/home/alex/.local/lib/python3.8/site-packages/lightgbm/basic.py:1245: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.798105\tvalid_1's rmse: 0.733762\n",
      "[100]\tvalid_0's rmse: 0.762576\tvalid_1's rmse: 0.725243\n",
      "[150]\tvalid_0's rmse: 0.744603\tvalid_1's rmse: 0.722851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.722520:  14%|#4        | 1/7 [01:11<07:09, 71.66s/it]\u001b[32m[I 2021-08-25 17:14:06,152]\u001b[0m Trial 0 finished with value: 0.722520215172997 and parameters: {'feature_fraction': 0.6}. Best is trial 0 with value: 0.722520215172997.\u001b[0m\n",
      "feature_fraction, val_score: 0.722520:  14%|#4        | 1/7 [01:11<07:09, 71.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[132]\tvalid_0's rmse: 0.750048\tvalid_1's rmse: 0.72252\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 3.115005 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.796111\tvalid_1's rmse: 0.725757\n",
      "[100]\tvalid_0's rmse: 0.760568\tvalid_1's rmse: 0.718284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.716324:  29%|##8       | 2/7 [02:25<06:05, 73.13s/it]\u001b[32m[I 2021-08-25 17:15:20,301]\u001b[0m Trial 1 finished with value: 0.7163235603713447 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 1 with value: 0.7163235603713447.\u001b[0m\n",
      "feature_fraction, val_score: 0.716324:  29%|##8       | 2/7 [02:25<06:05, 73.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[150]\tvalid_0's rmse: 0.742507\tvalid_1's rmse: 0.717427\n",
      "Early stopping, best iteration is:\n",
      "[120]\tvalid_0's rmse: 0.752642\tvalid_1's rmse: 0.716324\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.746155 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.799719\tvalid_1's rmse: 0.737689\n",
      "[100]\tvalid_0's rmse: 0.764008\tvalid_1's rmse: 0.728674\n",
      "[150]\tvalid_0's rmse: 0.747203\tvalid_1's rmse: 0.726075\n",
      "[200]\tvalid_0's rmse: 0.732963\tvalid_1's rmse: 0.724687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.716324:  43%|####2     | 3/7 [04:40<06:45, 101.27s/it]\u001b[32m[I 2021-08-25 17:17:35,066]\u001b[0m Trial 2 finished with value: 0.7238064448766743 and parameters: {'feature_fraction': 0.5}. Best is trial 1 with value: 0.7163235603713447.\u001b[0m\n",
      "feature_fraction, val_score: 0.716324:  43%|####2     | 3/7 [04:40<06:45, 101.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[174]\tvalid_0's rmse: 0.740226\tvalid_1's rmse: 0.723806\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 2.920068 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.794801\tvalid_1's rmse: 0.737693\n",
      "[100]\tvalid_0's rmse: 0.758048\tvalid_1's rmse: 0.726255\n",
      "[150]\tvalid_0's rmse: 0.739488\tvalid_1's rmse: 0.721431\n",
      "[200]\tvalid_0's rmse: 0.727625\tvalid_1's rmse: 0.719407\n",
      "[250]\tvalid_0's rmse: 0.717665\tvalid_1's rmse: 0.716391\n",
      "[300]\tvalid_0's rmse: 0.708793\tvalid_1's rmse: 0.716608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.716119:  57%|#####7    | 4/7 [07:00<05:49, 116.62s/it]\u001b[32m[I 2021-08-25 17:19:55,218]\u001b[0m Trial 3 finished with value: 0.7161188597767694 and parameters: {'feature_fraction': 1.0}. Best is trial 3 with value: 0.7161188597767694.\u001b[0m\n",
      "feature_fraction, val_score: 0.716119:  57%|#####7    | 4/7 [07:00<05:49, 116.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[285]\tvalid_0's rmse: 0.711047\tvalid_1's rmse: 0.716119\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 2.955024 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.796388\tvalid_1's rmse: 0.732485\n",
      "[100]\tvalid_0's rmse: 0.759887\tvalid_1's rmse: 0.723478\n",
      "[150]\tvalid_0's rmse: 0.74259\tvalid_1's rmse: 0.716907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.716119:  71%|#######1  | 5/7 [08:25<03:30, 105.23s/it]\u001b[32m[I 2021-08-25 17:21:20,240]\u001b[0m Trial 4 finished with value: 0.7166522616216168 and parameters: {'feature_fraction': 0.7}. Best is trial 3 with value: 0.7161188597767694.\u001b[0m\n",
      "feature_fraction, val_score: 0.716119:  71%|#######1  | 5/7 [08:25<03:30, 105.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[159]\tvalid_0's rmse: 0.740447\tvalid_1's rmse: 0.716652\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.674447 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.799881\tvalid_1's rmse: 0.735611\n",
      "[100]\tvalid_0's rmse: 0.765337\tvalid_1's rmse: 0.724427\n",
      "[150]\tvalid_0's rmse: 0.746924\tvalid_1's rmse: 0.720455\n",
      "[200]\tvalid_0's rmse: 0.733742\tvalid_1's rmse: 0.719232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.716119:  86%|########5 | 6/7 [10:27<01:50, 110.87s/it]\u001b[32m[I 2021-08-25 17:23:22,081]\u001b[0m Trial 5 finished with value: 0.7179115779351035 and parameters: {'feature_fraction': 0.4}. Best is trial 3 with value: 0.7161188597767694.\u001b[0m\n",
      "feature_fraction, val_score: 0.716119:  86%|########5 | 6/7 [10:27<01:50, 110.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[186]\tvalid_0's rmse: 0.736706\tvalid_1's rmse: 0.717912\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 3.015042 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.795921\tvalid_1's rmse: 0.734002\n",
      "[100]\tvalid_0's rmse: 0.759654\tvalid_1's rmse: 0.721174\n",
      "[150]\tvalid_0's rmse: 0.742048\tvalid_1's rmse: 0.71559\n",
      "[200]\tvalid_0's rmse: 0.728548\tvalid_1's rmse: 0.714982\n",
      "[250]\tvalid_0's rmse: 0.718967\tvalid_1's rmse: 0.715582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.714232: 100%|##########| 7/7 [12:03<00:00, 105.92s/it]\u001b[32m[I 2021-08-25 17:24:57,788]\u001b[0m Trial 6 finished with value: 0.7142318176972299 and parameters: {'feature_fraction': 0.8}. Best is trial 6 with value: 0.7142318176972299.\u001b[0m\n",
      "feature_fraction, val_score: 0.714232: 100%|##########| 7/7 [12:03<00:00, 103.33s/it]\n",
      "num_leaves, val_score: 0.714232:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[223]\tvalid_0's rmse: 0.723885\tvalid_1's rmse: 0.714232\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 2.994559 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.748124\tvalid_1's rmse: 0.717818\n",
      "[100]\tvalid_0's rmse: 0.711551\tvalid_1's rmse: 0.711098\n",
      "[150]\tvalid_0's rmse: 0.6929\tvalid_1's rmse: 0.711705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.710559:   5%|5         | 1/20 [01:30<28:46, 90.86s/it]\u001b[32m[I 2021-08-25 17:26:28,657]\u001b[0m Trial 7 finished with value: 0.710558518648866 and parameters: {'num_leaves': 84}. Best is trial 7 with value: 0.710558518648866.\u001b[0m\n",
      "num_leaves, val_score: 0.710559:   5%|5         | 1/20 [01:30<28:46, 90.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[138]\tvalid_0's rmse: 0.696804\tvalid_1's rmse: 0.710559\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 3.062821 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.852535\tvalid_1's rmse: 0.763521\n",
      "[100]\tvalid_0's rmse: 0.820121\tvalid_1's rmse: 0.747898\n",
      "[150]\tvalid_0's rmse: 0.800342\tvalid_1's rmse: 0.737416\n",
      "[200]\tvalid_0's rmse: 0.7871\tvalid_1's rmse: 0.732563\n",
      "[250]\tvalid_0's rmse: 0.776744\tvalid_1's rmse: 0.728288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.710559:  10%|#         | 2/20 [03:05<27:50, 92.81s/it]\u001b[32m[I 2021-08-25 17:28:02,829]\u001b[0m Trial 8 finished with value: 0.7282876715404706 and parameters: {'num_leaves': 10}. Best is trial 7 with value: 0.710558518648866.\u001b[0m\n",
      "num_leaves, val_score: 0.710559:  10%|#         | 2/20 [03:05<27:50, 92.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[250]\tvalid_0's rmse: 0.776744\tvalid_1's rmse: 0.728288\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 3.065311 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.71337\tvalid_1's rmse: 0.7254\n",
      "[100]\tvalid_0's rmse: 0.673713\tvalid_1's rmse: 0.722388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.710559:  15%|#5        | 3/20 [04:33<25:45, 90.90s/it]\u001b[32m[I 2021-08-25 17:29:31,457]\u001b[0m Trial 9 finished with value: 0.7223768230962235 and parameters: {'num_leaves': 182}. Best is trial 7 with value: 0.710558518648866.\u001b[0m\n",
      "num_leaves, val_score: 0.710559:  15%|#5        | 3/20 [04:33<25:45, 90.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[101]\tvalid_0's rmse: 0.67332\tvalid_1's rmse: 0.722377\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 3.003604 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.784262\tvalid_1's rmse: 0.735115\n",
      "[100]\tvalid_0's rmse: 0.748006\tvalid_1's rmse: 0.725774\n",
      "[150]\tvalid_0's rmse: 0.730137\tvalid_1's rmse: 0.7244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.710559:  20%|##        | 4/20 [05:51<22:53, 85.87s/it]\u001b[32m[I 2021-08-25 17:30:49,610]\u001b[0m Trial 10 finished with value: 0.722932658302141 and parameters: {'num_leaves': 40}. Best is trial 7 with value: 0.710558518648866.\u001b[0m\n",
      "num_leaves, val_score: 0.710559:  20%|##        | 4/20 [05:51<22:53, 85.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[132]\tvalid_0's rmse: 0.735414\tvalid_1's rmse: 0.722933\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.994319 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.73102\tvalid_1's rmse: 0.717309\n",
      "[100]\tvalid_0's rmse: 0.692654\tvalid_1's rmse: 0.711639\n",
      "[150]\tvalid_0's rmse: 0.670791\tvalid_1's rmse: 0.710064\n",
      "[200]\tvalid_0's rmse: 0.65636\tvalid_1's rmse: 0.711101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.709652:  25%|##5       | 5/20 [07:41<23:38, 94.56s/it]\u001b[32m[I 2021-08-25 17:32:39,568]\u001b[0m Trial 11 finished with value: 0.7096522746609923 and parameters: {'num_leaves': 128}. Best is trial 11 with value: 0.7096522746609923.\u001b[0m\n",
      "num_leaves, val_score: 0.709652:  25%|##5       | 5/20 [07:41<23:38, 94.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[173]\tvalid_0's rmse: 0.66376\tvalid_1's rmse: 0.709652\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 3.194726 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.814817\tvalid_1's rmse: 0.747666\n",
      "[100]\tvalid_0's rmse: 0.77755\tvalid_1's rmse: 0.733827\n",
      "[150]\tvalid_0's rmse: 0.760294\tvalid_1's rmse: 0.727531\n",
      "[200]\tvalid_0's rmse: 0.746889\tvalid_1's rmse: 0.722392\n",
      "[250]\tvalid_0's rmse: 0.736855\tvalid_1's rmse: 0.721547\n",
      "[300]\tvalid_0's rmse: 0.728371\tvalid_1's rmse: 0.720363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.709652:  30%|###       | 6/20 [09:41<24:01, 102.99s/it]\u001b[32m[I 2021-08-25 17:34:38,920]\u001b[0m Trial 12 finished with value: 0.720193591901334 and parameters: {'num_leaves': 22}. Best is trial 11 with value: 0.7096522746609923.\u001b[0m\n",
      "num_leaves, val_score: 0.709652:  30%|###       | 6/20 [09:41<24:01, 102.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[308]\tvalid_0's rmse: 0.727334\tvalid_1's rmse: 0.720194\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 3.208650 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.703843\tvalid_1's rmse: 0.719278\n",
      "[100]\tvalid_0's rmse: 0.664076\tvalid_1's rmse: 0.716783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.709652:  35%|###5      | 7/20 [11:22<22:10, 102.33s/it]\u001b[32m[I 2021-08-25 17:36:19,902]\u001b[0m Trial 13 finished with value: 0.7167662575831205 and parameters: {'num_leaves': 231}. Best is trial 11 with value: 0.7096522746609923.\u001b[0m\n",
      "num_leaves, val_score: 0.709652:  35%|###5      | 7/20 [11:22<22:10, 102.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[105]\tvalid_0's rmse: 0.66118\tvalid_1's rmse: 0.716766\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 3.137951 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.699042\tvalid_1's rmse: 0.716314\n",
      "[100]\tvalid_0's rmse: 0.658019\tvalid_1's rmse: 0.71484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.709652:  40%|####      | 8/20 [12:48<19:26, 97.24s/it] \u001b[32m[I 2021-08-25 17:37:46,249]\u001b[0m Trial 14 finished with value: 0.7141513234158461 and parameters: {'num_leaves': 255}. Best is trial 11 with value: 0.7096522746609923.\u001b[0m\n",
      "num_leaves, val_score: 0.709652:  40%|####      | 8/20 [12:48<19:26, 97.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[76]\tvalid_0's rmse: 0.6734\tvalid_1's rmse: 0.714151\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 3.291388 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.724539\tvalid_1's rmse: 0.724136\n",
      "[100]\tvalid_0's rmse: 0.687102\tvalid_1's rmse: 0.720592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.709652:  45%|####5     | 9/20 [14:09<16:54, 92.22s/it]\u001b[32m[I 2021-08-25 17:39:07,416]\u001b[0m Trial 15 finished with value: 0.7192932837206024 and parameters: {'num_leaves': 145}. Best is trial 11 with value: 0.7096522746609923.\u001b[0m\n",
      "num_leaves, val_score: 0.709652:  45%|####5     | 9/20 [14:09<16:54, 92.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's rmse: 0.696936\tvalid_1's rmse: 0.719293\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.983197 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.700595\tvalid_1's rmse: 0.719603\n",
      "[100]\tvalid_0's rmse: 0.658527\tvalid_1's rmse: 0.714751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.709652:  50%|#####     | 10/20 [15:39<15:15, 91.55s/it]\u001b[32m[I 2021-08-25 17:40:37,480]\u001b[0m Trial 16 finished with value: 0.7146319961043768 and parameters: {'num_leaves': 249}. Best is trial 11 with value: 0.7096522746609923.\u001b[0m\n",
      "num_leaves, val_score: 0.709652:  50%|#####     | 10/20 [15:39<15:15, 91.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[101]\tvalid_0's rmse: 0.658013\tvalid_1's rmse: 0.714632\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 3.106688 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.738277\tvalid_1's rmse: 0.721079\n",
      "[100]\tvalid_0's rmse: 0.699945\tvalid_1's rmse: 0.714501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.709652:  55%|#####5    | 11/20 [17:02<13:20, 88.93s/it]\u001b[32m[I 2021-08-25 17:42:00,481]\u001b[0m Trial 17 finished with value: 0.7142705177289697 and parameters: {'num_leaves': 108}. Best is trial 11 with value: 0.7096522746609923.\u001b[0m\n",
      "num_leaves, val_score: 0.709652:  55%|#####5    | 11/20 [17:02<13:20, 88.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[104]\tvalid_0's rmse: 0.698109\tvalid_1's rmse: 0.714271\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 3.102720 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.747881\tvalid_1's rmse: 0.72099\n",
      "[100]\tvalid_0's rmse: 0.710258\tvalid_1's rmse: 0.71387\n",
      "[150]\tvalid_0's rmse: 0.691541\tvalid_1's rmse: 0.712459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.709652:  60%|######    | 12/20 [18:37<12:05, 90.65s/it]\u001b[32m[I 2021-08-25 17:43:35,054]\u001b[0m Trial 18 finished with value: 0.7120915655859414 and parameters: {'num_leaves': 87}. Best is trial 11 with value: 0.7096522746609923.\u001b[0m\n",
      "num_leaves, val_score: 0.709652:  60%|######    | 12/20 [18:37<12:05, 90.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[161]\tvalid_0's rmse: 0.688463\tvalid_1's rmse: 0.712092\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 3.153225 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.758188\tvalid_1's rmse: 0.730883\n",
      "[100]\tvalid_0's rmse: 0.721735\tvalid_1's rmse: 0.721113\n",
      "[150]\tvalid_0's rmse: 0.70328\tvalid_1's rmse: 0.717346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.709652:  65%|######5   | 13/20 [20:04<10:27, 89.64s/it]\u001b[32m[I 2021-08-25 17:45:02,371]\u001b[0m Trial 19 finished with value: 0.716174740979489 and parameters: {'num_leaves': 69}. Best is trial 11 with value: 0.7096522746609923.\u001b[0m\n",
      "num_leaves, val_score: 0.709652:  65%|######5   | 13/20 [20:04<10:27, 89.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[133]\tvalid_0's rmse: 0.708223\tvalid_1's rmse: 0.716175\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 3.196620 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.72424\tvalid_1's rmse: 0.721036\n",
      "[100]\tvalid_0's rmse: 0.685451\tvalid_1's rmse: 0.720596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.709652:  70%|#######   | 14/20 [21:24<08:40, 86.75s/it]\u001b[32m[I 2021-08-25 17:46:22,443]\u001b[0m Trial 20 finished with value: 0.7192549914525761 and parameters: {'num_leaves': 148}. Best is trial 11 with value: 0.7096522746609923.\u001b[0m\n",
      "num_leaves, val_score: 0.709652:  70%|#######   | 14/20 [21:24<08:40, 86.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[72]\tvalid_0's rmse: 0.703904\tvalid_1's rmse: 0.719255\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 3.432206 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.715434\tvalid_1's rmse: 0.727119\n",
      "[100]\tvalid_0's rmse: 0.67551\tvalid_1's rmse: 0.724651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.709652:  75%|#######5  | 15/20 [22:46<07:06, 85.25s/it]\u001b[32m[I 2021-08-25 17:47:44,205]\u001b[0m Trial 21 finished with value: 0.7236178947484965 and parameters: {'num_leaves': 180}. Best is trial 11 with value: 0.7096522746609923.\u001b[0m\n",
      "num_leaves, val_score: 0.709652:  75%|#######5  | 15/20 [22:46<07:06, 85.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[75]\tvalid_0's rmse: 0.691768\tvalid_1's rmse: 0.723618\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 3.403087 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.757582\tvalid_1's rmse: 0.72497\n",
      "[100]\tvalid_0's rmse: 0.720158\tvalid_1's rmse: 0.721677\n",
      "[150]\tvalid_0's rmse: 0.701651\tvalid_1's rmse: 0.719639\n",
      "[200]\tvalid_0's rmse: 0.687685\tvalid_1's rmse: 0.717651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.709652:  80%|########  | 16/20 [24:34<06:08, 92.15s/it]\u001b[32m[I 2021-08-25 17:49:32,377]\u001b[0m Trial 22 finished with value: 0.7176508276846515 and parameters: {'num_leaves': 71}. Best is trial 11 with value: 0.7096522746609923.\u001b[0m\n",
      "num_leaves, val_score: 0.709652:  80%|########  | 16/20 [24:34<06:08, 92.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[200]\tvalid_0's rmse: 0.687685\tvalid_1's rmse: 0.717651\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.904007 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.734122\tvalid_1's rmse: 0.719626\n",
      "[100]\tvalid_0's rmse: 0.696342\tvalid_1's rmse: 0.713522\n",
      "[150]\tvalid_0's rmse: 0.675689\tvalid_1's rmse: 0.713276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.709652:  85%|########5 | 17/20 [26:03<04:33, 91.09s/it]\u001b[32m[I 2021-08-25 17:51:01,009]\u001b[0m Trial 23 finished with value: 0.7118321640360593 and parameters: {'num_leaves': 117}. Best is trial 11 with value: 0.7096522746609923.\u001b[0m\n",
      "num_leaves, val_score: 0.709652:  85%|########5 | 17/20 [26:03<04:33, 91.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[123]\tvalid_0's rmse: 0.685639\tvalid_1's rmse: 0.711832\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 3.353752 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.716675\tvalid_1's rmse: 0.718054\n",
      "[100]\tvalid_0's rmse: 0.677263\tvalid_1's rmse: 0.715214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.709652:  90%|######### | 18/20 [27:33<03:01, 90.79s/it]\u001b[32m[I 2021-08-25 17:52:31,104]\u001b[0m Trial 24 finished with value: 0.7135809462738913 and parameters: {'num_leaves': 174}. Best is trial 11 with value: 0.7096522746609923.\u001b[0m\n",
      "num_leaves, val_score: 0.709652:  90%|######### | 18/20 [27:33<03:01, 90.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[86]\tvalid_0's rmse: 0.685401\tvalid_1's rmse: 0.713581\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 3.348612 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.743837\tvalid_1's rmse: 0.719345\n",
      "[100]\tvalid_0's rmse: 0.705792\tvalid_1's rmse: 0.714276\n",
      "[150]\tvalid_0's rmse: 0.687077\tvalid_1's rmse: 0.714377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.709652:  95%|#########5| 19/20 [29:12<01:33, 93.31s/it]\u001b[32m[I 2021-08-25 17:54:10,282]\u001b[0m Trial 25 finished with value: 0.7133864035183225 and parameters: {'num_leaves': 95}. Best is trial 11 with value: 0.7096522746609923.\u001b[0m\n",
      "num_leaves, val_score: 0.709652:  95%|#########5| 19/20 [29:12<01:33, 93.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[144]\tvalid_0's rmse: 0.689141\tvalid_1's rmse: 0.713386\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 3.231930 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.772729\tvalid_1's rmse: 0.727225\n",
      "[100]\tvalid_0's rmse: 0.735783\tvalid_1's rmse: 0.721816\n",
      "[150]\tvalid_0's rmse: 0.717112\tvalid_1's rmse: 0.719302\n",
      "[200]\tvalid_0's rmse: 0.702888\tvalid_1's rmse: 0.720123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.709652: 100%|##########| 20/20 [30:49<00:00, 94.29s/it]\u001b[32m[I 2021-08-25 17:55:46,871]\u001b[0m Trial 26 finished with value: 0.7189653376077784 and parameters: {'num_leaves': 52}. Best is trial 11 with value: 0.7096522746609923.\u001b[0m\n",
      "num_leaves, val_score: 0.709652: 100%|##########| 20/20 [30:49<00:00, 92.45s/it]\n",
      "bagging, val_score: 0.709652:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[175]\tvalid_0's rmse: 0.709222\tvalid_1's rmse: 0.718965\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 3.274048 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.730219\tvalid_1's rmse: 0.722864\n",
      "[100]\tvalid_0's rmse: 0.692402\tvalid_1's rmse: 0.721831\n",
      "[150]\tvalid_0's rmse: 0.671987\tvalid_1's rmse: 0.719568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.709652:  10%|#         | 1/10 [01:54<17:10, 114.54s/it]\u001b[32m[I 2021-08-25 17:57:41,435]\u001b[0m Trial 27 finished with value: 0.7195218696572744 and parameters: {'bagging_fraction': 0.9205856273228078, 'bagging_freq': 6}. Best is trial 27 with value: 0.7195218696572744.\u001b[0m\n",
      "bagging, val_score: 0.709652:  10%|#         | 1/10 [01:54<17:10, 114.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[152]\tvalid_0's rmse: 0.671447\tvalid_1's rmse: 0.719522\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 3.285411 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.731288\tvalid_1's rmse: 0.720922\n",
      "[100]\tvalid_0's rmse: 0.693528\tvalid_1's rmse: 0.715386\n",
      "[150]\tvalid_0's rmse: 0.674625\tvalid_1's rmse: 0.713665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.709652:  20%|##        | 2/10 [03:37<14:21, 107.71s/it]\u001b[32m[I 2021-08-25 17:59:24,347]\u001b[0m Trial 28 finished with value: 0.7130372380688206 and parameters: {'bagging_fraction': 0.8407674900565802, 'bagging_freq': 4}. Best is trial 28 with value: 0.7130372380688206.\u001b[0m\n",
      "bagging, val_score: 0.709652:  20%|##        | 2/10 [03:37<14:21, 107.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[121]\tvalid_0's rmse: 0.684851\tvalid_1's rmse: 0.713037\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 3.046250 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.731426\tvalid_1's rmse: 0.721585\n",
      "[100]\tvalid_0's rmse: 0.695181\tvalid_1's rmse: 0.719991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.709652:  30%|###       | 3/10 [04:55<11:00, 94.38s/it] \u001b[32m[I 2021-08-25 18:00:42,855]\u001b[0m Trial 29 finished with value: 0.7185267942249658 and parameters: {'bagging_fraction': 0.6796682973519622, 'bagging_freq': 1}. Best is trial 28 with value: 0.7130372380688206.\u001b[0m\n",
      "bagging, val_score: 0.709652:  30%|###       | 3/10 [04:55<11:00, 94.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[93]\tvalid_0's rmse: 0.698695\tvalid_1's rmse: 0.718527\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 3.108075 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.734257\tvalid_1's rmse: 0.722991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.709652:  40%|####      | 4/10 [05:59<08:12, 82.09s/it]\u001b[32m[I 2021-08-25 18:01:46,106]\u001b[0m Trial 30 finished with value: 0.7187641410976188 and parameters: {'bagging_fraction': 0.4347718698595812, 'bagging_freq': 3}. Best is trial 28 with value: 0.7130372380688206.\u001b[0m\n",
      "bagging, val_score: 0.709652:  40%|####      | 4/10 [05:59<08:12, 82.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[69]\tvalid_0's rmse: 0.716662\tvalid_1's rmse: 0.718764\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.963156 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.730333\tvalid_1's rmse: 0.719175\n",
      "[100]\tvalid_0's rmse: 0.69367\tvalid_1's rmse: 0.713594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.709652:  50%|#####     | 5/10 [07:32<07:10, 86.01s/it]\u001b[32m[I 2021-08-25 18:03:19,082]\u001b[0m Trial 31 finished with value: 0.7130699156566925 and parameters: {'bagging_fraction': 0.9088058948750567, 'bagging_freq': 6}. Best is trial 28 with value: 0.7130372380688206.\u001b[0m\n",
      "bagging, val_score: 0.709652:  50%|#####     | 5/10 [07:32<07:10, 86.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[97]\tvalid_0's rmse: 0.695444\tvalid_1's rmse: 0.71307\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 2.962379 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.735698\tvalid_1's rmse: 0.710797\n",
      "[100]\tvalid_0's rmse: 0.701927\tvalid_1's rmse: 0.709201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.708682:  60%|######    | 6/10 [08:40<05:20, 80.05s/it]\u001b[32m[I 2021-08-25 18:04:27,557]\u001b[0m Trial 32 finished with value: 0.7086815467702015 and parameters: {'bagging_fraction': 0.40869025100946105, 'bagging_freq': 5}. Best is trial 32 with value: 0.7086815467702015.\u001b[0m\n",
      "bagging, val_score: 0.708682:  60%|######    | 6/10 [08:40<05:20, 80.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[92]\tvalid_0's rmse: 0.704917\tvalid_1's rmse: 0.708682\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 3.392708 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.731249\tvalid_1's rmse: 0.718349\n",
      "[100]\tvalid_0's rmse: 0.695223\tvalid_1's rmse: 0.712149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.708682:  70%|#######   | 7/10 [10:00<03:59, 79.86s/it]\u001b[32m[I 2021-08-25 18:05:47,028]\u001b[0m Trial 33 finished with value: 0.7115364538265829 and parameters: {'bagging_fraction': 0.6520228216945252, 'bagging_freq': 7}. Best is trial 32 with value: 0.7086815467702015.\u001b[0m\n",
      "bagging, val_score: 0.708682:  70%|#######   | 7/10 [10:00<03:59, 79.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[104]\tvalid_0's rmse: 0.693428\tvalid_1's rmse: 0.711536\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 2.978397 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.730533\tvalid_1's rmse: 0.71724\n",
      "[100]\tvalid_0's rmse: 0.69156\tvalid_1's rmse: 0.710971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.708682:  80%|########  | 8/10 [11:36<02:50, 85.13s/it]\u001b[32m[I 2021-08-25 18:07:23,460]\u001b[0m Trial 34 finished with value: 0.7107806691630049 and parameters: {'bagging_fraction': 0.97981333926486, 'bagging_freq': 5}. Best is trial 32 with value: 0.7086815467702015.\u001b[0m\n",
      "bagging, val_score: 0.708682:  80%|########  | 8/10 [11:36<02:50, 85.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[99]\tvalid_0's rmse: 0.692237\tvalid_1's rmse: 0.710781\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 6.011327 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.733917\tvalid_1's rmse: 0.722752\n",
      "[100]\tvalid_0's rmse: 0.699937\tvalid_1's rmse: 0.723378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.708682:  90%|######### | 9/10 [12:52<01:22, 82.41s/it]\u001b[32m[I 2021-08-25 18:08:39,867]\u001b[0m Trial 35 finished with value: 0.7207484755761326 and parameters: {'bagging_fraction': 0.42907026303540236, 'bagging_freq': 1}. Best is trial 32 with value: 0.7086815467702015.\u001b[0m\n",
      "bagging, val_score: 0.708682:  90%|######### | 9/10 [12:52<01:22, 82.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[77]\tvalid_0's rmse: 0.71328\tvalid_1's rmse: 0.720748\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 3.015167 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.730727\tvalid_1's rmse: 0.714377\n",
      "[100]\tvalid_0's rmse: 0.691871\tvalid_1's rmse: 0.712128\n",
      "[150]\tvalid_0's rmse: 0.671156\tvalid_1's rmse: 0.711658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.708682: 100%|##########| 10/10 [14:49<00:00, 92.92s/it]\u001b[32m[I 2021-08-25 18:10:36,313]\u001b[0m Trial 36 finished with value: 0.7116122481245297 and parameters: {'bagging_fraction': 0.9948789277151555, 'bagging_freq': 5}. Best is trial 32 with value: 0.7086815467702015.\u001b[0m\n",
      "bagging, val_score: 0.708682: 100%|##########| 10/10 [14:49<00:00, 88.94s/it]\n",
      "feature_fraction_stage2, val_score: 0.708682:   0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[148]\tvalid_0's rmse: 0.671702\tvalid_1's rmse: 0.711612\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 2.932574 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.734775\tvalid_1's rmse: 0.719966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.708682:  17%|#6        | 1/6 [00:56<04:43, 56.65s/it]\u001b[32m[I 2021-08-25 18:11:32,989]\u001b[0m Trial 37 finished with value: 0.7181979338370629 and parameters: {'feature_fraction': 0.88}. Best is trial 37 with value: 0.7181979338370629.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.708682:  17%|#6        | 1/6 [00:56<04:43, 56.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[68]\tvalid_0's rmse: 0.719197\tvalid_1's rmse: 0.718198\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 3.020768 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.734111\tvalid_1's rmse: 0.711414\n",
      "[100]\tvalid_0's rmse: 0.700266\tvalid_1's rmse: 0.709241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.708682:  33%|###3      | 2/6 [01:56<03:53, 58.32s/it]\u001b[32m[I 2021-08-25 18:12:32,468]\u001b[0m Trial 38 finished with value: 0.708772244083244 and parameters: {'feature_fraction': 0.8160000000000001}. Best is trial 38 with value: 0.708772244083244.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.708682:  33%|###3      | 2/6 [01:56<03:53, 58.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[71]\tvalid_0's rmse: 0.714851\tvalid_1's rmse: 0.708772\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 3.035022 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.735195\tvalid_1's rmse: 0.718824\n",
      "[100]\tvalid_0's rmse: 0.701172\tvalid_1's rmse: 0.715586\n",
      "[150]\tvalid_0's rmse: 0.683804\tvalid_1's rmse: 0.713817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.708682:  50%|#####     | 3/6 [03:21<03:32, 70.78s/it]\u001b[32m[I 2021-08-25 18:13:58,066]\u001b[0m Trial 39 finished with value: 0.7136573989034395 and parameters: {'feature_fraction': 0.8480000000000001}. Best is trial 38 with value: 0.708772244083244.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.708682:  50%|#####     | 3/6 [03:21<03:32, 70.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[153]\tvalid_0's rmse: 0.682815\tvalid_1's rmse: 0.713657\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 2.997061 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.734872\tvalid_1's rmse: 0.715919\n",
      "[100]\tvalid_0's rmse: 0.701544\tvalid_1's rmse: 0.71366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.708682:  67%|######6   | 4/6 [04:24<02:14, 67.48s/it]\u001b[32m[I 2021-08-25 18:15:00,476]\u001b[0m Trial 40 finished with value: 0.7128769257154954 and parameters: {'feature_fraction': 0.784}. Best is trial 38 with value: 0.708772244083244.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.708682:  67%|######6   | 4/6 [04:24<02:14, 67.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[81]\tvalid_0's rmse: 0.710582\tvalid_1's rmse: 0.712877\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 3.232862 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.736564\tvalid_1's rmse: 0.718987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.708682:  83%|########3 | 5/6 [05:18<01:02, 62.65s/it]\u001b[32m[I 2021-08-25 18:15:54,566]\u001b[0m Trial 41 finished with value: 0.7176068406835338 and parameters: {'feature_fraction': 0.7200000000000001}. Best is trial 38 with value: 0.708772244083244.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.708682:  83%|########3 | 5/6 [05:18<01:02, 62.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[57]\tvalid_0's rmse: 0.729309\tvalid_1's rmse: 0.717607\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 2.953833 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.736099\tvalid_1's rmse: 0.716676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.708682: 100%|##########| 6/6 [06:14<00:00, 60.31s/it]\u001b[32m[I 2021-08-25 18:16:50,333]\u001b[0m Trial 42 finished with value: 0.7155677180768026 and parameters: {'feature_fraction': 0.7520000000000001}. Best is trial 38 with value: 0.708772244083244.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.708682: 100%|##########| 6/6 [06:14<00:00, 62.34s/it]\n",
      "regularization_factors, val_score: 0.708682:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[61]\tvalid_0's rmse: 0.725307\tvalid_1's rmse: 0.715568\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 2.977141 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.73645\tvalid_1's rmse: 0.71326\n",
      "[100]\tvalid_0's rmse: 0.700957\tvalid_1's rmse: 0.708647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.707381:   5%|5         | 1/20 [01:02<19:44, 62.33s/it]\u001b[32m[I 2021-08-25 18:17:52,681]\u001b[0m Trial 43 finished with value: 0.7073808732898264 and parameters: {'lambda_l1': 0.235956260325282, 'lambda_l2': 0.054223997116497724}. Best is trial 43 with value: 0.7073808732898264.\u001b[0m\n",
      "regularization_factors, val_score: 0.707381:   5%|5         | 1/20 [01:02<19:44, 62.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[84]\tvalid_0's rmse: 0.708238\tvalid_1's rmse: 0.707381\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 4.521144 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.735698\tvalid_1's rmse: 0.710743\n",
      "[100]\tvalid_0's rmse: 0.701927\tvalid_1's rmse: 0.70912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.707381:  10%|#         | 2/20 [02:11<19:50, 66.16s/it]\u001b[32m[I 2021-08-25 18:19:01,528]\u001b[0m Trial 44 finished with value: 0.7085856556695573 and parameters: {'lambda_l1': 2.0019408202008066e-06, 'lambda_l2': 8.5574307764448e-05}. Best is trial 43 with value: 0.7073808732898264.\u001b[0m\n",
      "regularization_factors, val_score: 0.707381:  10%|#         | 2/20 [02:11<19:50, 66.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[92]\tvalid_0's rmse: 0.704917\tvalid_1's rmse: 0.708586\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 3.108880 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.735698\tvalid_1's rmse: 0.710743\n",
      "[100]\tvalid_0's rmse: 0.702006\tvalid_1's rmse: 0.708767\n",
      "[150]\tvalid_0's rmse: 0.683905\tvalid_1's rmse: 0.709092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.707381:  15%|#5        | 3/20 [03:31<20:31, 72.43s/it]\u001b[32m[I 2021-08-25 18:20:21,418]\u001b[0m Trial 45 finished with value: 0.7077087121239402 and parameters: {'lambda_l1': 3.642911442812504e-08, 'lambda_l2': 7.973799650215828e-05}. Best is trial 43 with value: 0.7073808732898264.\u001b[0m\n",
      "regularization_factors, val_score: 0.707381:  15%|#5        | 3/20 [03:31<20:31, 72.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[137]\tvalid_0's rmse: 0.688226\tvalid_1's rmse: 0.707709\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 3.012635 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.735702\tvalid_1's rmse: 0.709568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.707381:  20%|##        | 4/20 [04:29<17:52, 67.02s/it]\u001b[32m[I 2021-08-25 18:21:20,129]\u001b[0m Trial 46 finished with value: 0.7074797678540277 and parameters: {'lambda_l1': 0.0018348869369216715, 'lambda_l2': 0.00016469668606209812}. Best is trial 43 with value: 0.7073808732898264.\u001b[0m\n",
      "regularization_factors, val_score: 0.707381:  20%|##        | 4/20 [04:29<17:52, 67.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[69]\tvalid_0's rmse: 0.718283\tvalid_1's rmse: 0.70748\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 3.094857 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.735598\tvalid_1's rmse: 0.71231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.707381:  25%|##5       | 5/20 [05:29<16:05, 64.39s/it]\u001b[32m[I 2021-08-25 18:22:19,869]\u001b[0m Trial 47 finished with value: 0.7102480094104204 and parameters: {'lambda_l1': 2.2310911568065094e-06, 'lambda_l2': 0.8691219034557326}. Best is trial 43 with value: 0.7073808732898264.\u001b[0m\n",
      "regularization_factors, val_score: 0.707381:  25%|##5       | 5/20 [05:29<16:05, 64.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[58]\tvalid_0's rmse: 0.727598\tvalid_1's rmse: 0.710248\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 5.536983 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.735698\tvalid_1's rmse: 0.710743\n",
      "[100]\tvalid_0's rmse: 0.701927\tvalid_1's rmse: 0.70912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.707381:  30%|###       | 6/20 [06:39<15:28, 66.32s/it]\u001b[32m[I 2021-08-25 18:23:29,940]\u001b[0m Trial 48 finished with value: 0.7085858175215911 and parameters: {'lambda_l1': 1.105133294713026e-08, 'lambda_l2': 3.858592978962724e-08}. Best is trial 43 with value: 0.7073808732898264.\u001b[0m\n",
      "regularization_factors, val_score: 0.707381:  30%|###       | 6/20 [06:39<15:28, 66.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[92]\tvalid_0's rmse: 0.704916\tvalid_1's rmse: 0.708586\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 3.209169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.735488\tvalid_1's rmse: 0.710833\n",
      "[100]\tvalid_0's rmse: 0.701156\tvalid_1's rmse: 0.709206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.707381:  35%|###5      | 7/20 [07:40<13:57, 64.43s/it]\u001b[32m[I 2021-08-25 18:24:30,460]\u001b[0m Trial 49 finished with value: 0.7085976293100035 and parameters: {'lambda_l1': 1.0785781278164679e-07, 'lambda_l2': 0.0010235883793118337}. Best is trial 43 with value: 0.7073808732898264.\u001b[0m\n",
      "regularization_factors, val_score: 0.707381:  35%|###5      | 7/20 [07:40<13:57, 64.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[73]\tvalid_0's rmse: 0.714854\tvalid_1's rmse: 0.708598\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 3.154771 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.734731\tvalid_1's rmse: 0.714601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.707381:  40%|####      | 8/20 [08:36<12:21, 61.83s/it]\u001b[32m[I 2021-08-25 18:25:26,744]\u001b[0m Trial 50 finished with value: 0.7111448514881974 and parameters: {'lambda_l1': 0.3879535973513488, 'lambda_l2': 0.0007422944509523808}. Best is trial 43 with value: 0.7073808732898264.\u001b[0m\n",
      "regularization_factors, val_score: 0.707381:  40%|####      | 8/20 [08:36<12:21, 61.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[67]\tvalid_0's rmse: 0.719032\tvalid_1's rmse: 0.711145\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 3.181908 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.735599\tvalid_1's rmse: 0.718756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.707381:  45%|####5     | 9/20 [09:35<11:10, 60.93s/it]\u001b[32m[I 2021-08-25 18:26:25,678]\u001b[0m Trial 51 finished with value: 0.7172606075829633 and parameters: {'lambda_l1': 0.044078035160026036, 'lambda_l2': 7.5681332971707555e-06}. Best is trial 43 with value: 0.7073808732898264.\u001b[0m\n",
      "regularization_factors, val_score: 0.707381:  45%|####5     | 9/20 [09:35<11:10, 60.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's rmse: 0.726236\tvalid_1's rmse: 0.717261\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 4.935911 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.734925\tvalid_1's rmse: 0.714191\n",
      "[100]\tvalid_0's rmse: 0.70173\tvalid_1's rmse: 0.71326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.707381:  50%|#####     | 10/20 [10:38<10:15, 61.58s/it]\u001b[32m[I 2021-08-25 18:27:28,715]\u001b[0m Trial 52 finished with value: 0.7120850159758836 and parameters: {'lambda_l1': 3.6473344416664596e-07, 'lambda_l2': 0.13271209128187667}. Best is trial 43 with value: 0.7073808732898264.\u001b[0m\n",
      "regularization_factors, val_score: 0.707381:  50%|#####     | 10/20 [10:38<10:15, 61.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[74]\tvalid_0's rmse: 0.714525\tvalid_1's rmse: 0.712085\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 3.167788 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.739202\tvalid_1's rmse: 0.715958\n",
      "[100]\tvalid_0's rmse: 0.705895\tvalid_1's rmse: 0.713751\n",
      "[150]\tvalid_0's rmse: 0.688983\tvalid_1's rmse: 0.712736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.707381:  55%|#####5    | 11/20 [11:58<10:06, 67.39s/it]\u001b[32m[I 2021-08-25 18:28:49,270]\u001b[0m Trial 53 finished with value: 0.7119867614695787 and parameters: {'lambda_l1': 9.568009009587781, 'lambda_l2': 7.191665253234682}. Best is trial 43 with value: 0.7073808732898264.\u001b[0m\n",
      "regularization_factors, val_score: 0.707381:  55%|#####5    | 11/20 [11:58<10:06, 67.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[142]\tvalid_0's rmse: 0.69201\tvalid_1's rmse: 0.711987\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 3.037318 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.73423\tvalid_1's rmse: 0.71063\n",
      "[100]\tvalid_0's rmse: 0.700198\tvalid_1's rmse: 0.708185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.707381:  60%|######    | 12/20 [13:12<09:13, 69.15s/it]\u001b[32m[I 2021-08-25 18:30:02,463]\u001b[0m Trial 54 finished with value: 0.7077093787017471 and parameters: {'lambda_l1': 0.0005768050220019755, 'lambda_l2': 0.05534235563608736}. Best is trial 43 with value: 0.7073808732898264.\u001b[0m\n",
      "regularization_factors, val_score: 0.707381:  60%|######    | 12/20 [13:12<09:13, 69.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[110]\tvalid_0's rmse: 0.696657\tvalid_1's rmse: 0.707709\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 3.356313 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.734772\tvalid_1's rmse: 0.713926\n",
      "[100]\tvalid_0's rmse: 0.700785\tvalid_1's rmse: 0.711684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.707381:  65%|######5   | 13/20 [14:23<08:08, 69.84s/it]\u001b[32m[I 2021-08-25 18:31:13,870]\u001b[0m Trial 55 finished with value: 0.7096152581535069 and parameters: {'lambda_l1': 0.0014422631254618406, 'lambda_l2': 0.014703368742291788}. Best is trial 43 with value: 0.7073808732898264.\u001b[0m\n",
      "regularization_factors, val_score: 0.707381:  65%|######5   | 13/20 [14:23<08:08, 69.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[117]\tvalid_0's rmse: 0.693949\tvalid_1's rmse: 0.709615\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 3.034493 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.734964\tvalid_1's rmse: 0.712848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.707381:  70%|#######   | 14/20 [15:22<06:38, 66.47s/it]\u001b[32m[I 2021-08-25 18:32:12,581]\u001b[0m Trial 56 finished with value: 0.7111221135804475 and parameters: {'lambda_l1': 0.023686346988538522, 'lambda_l2': 7.611364246329617e-07}. Best is trial 43 with value: 0.7073808732898264.\u001b[0m\n",
      "regularization_factors, val_score: 0.707381:  70%|#######   | 14/20 [15:22<06:38, 66.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[61]\tvalid_0's rmse: 0.723691\tvalid_1's rmse: 0.711122\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 3.057940 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.736725\tvalid_1's rmse: 0.716657\n",
      "[100]\tvalid_0's rmse: 0.701919\tvalid_1's rmse: 0.715846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.707381:  75%|#######5  | 15/20 [16:21<05:22, 64.44s/it]\u001b[32m[I 2021-08-25 18:33:12,315]\u001b[0m Trial 57 finished with value: 0.7154280953245861 and parameters: {'lambda_l1': 6.9821103071904, 'lambda_l2': 0.003910096574880415}. Best is trial 43 with value: 0.7073808732898264.\u001b[0m\n",
      "regularization_factors, val_score: 0.707381:  75%|#######5  | 15/20 [16:21<05:22, 64.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[71]\tvalid_0's rmse: 0.717548\tvalid_1's rmse: 0.715428\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 3.205224 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.736379\tvalid_1's rmse: 0.715049\n",
      "[100]\tvalid_0's rmse: 0.70272\tvalid_1's rmse: 0.711715\n",
      "[150]\tvalid_0's rmse: 0.685053\tvalid_1's rmse: 0.710343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.707381:  80%|########  | 16/20 [17:42<04:36, 69.24s/it]\u001b[32m[I 2021-08-25 18:34:32,695]\u001b[0m Trial 58 finished with value: 0.7097491933558918 and parameters: {'lambda_l1': 3.5925738276506246e-05, 'lambda_l2': 1.968098190594997}. Best is trial 43 with value: 0.7073808732898264.\u001b[0m\n",
      "regularization_factors, val_score: 0.707381:  80%|########  | 16/20 [17:42<04:36, 69.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[146]\tvalid_0's rmse: 0.686623\tvalid_1's rmse: 0.709749\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 3.081642 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.73482\tvalid_1's rmse: 0.710261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.707381:  85%|########5 | 17/20 [18:37<03:14, 65.00s/it]\u001b[32m[I 2021-08-25 18:35:27,822]\u001b[0m Trial 59 finished with value: 0.709512254854421 and parameters: {'lambda_l1': 0.43712610823013365, 'lambda_l2': 8.137654581827758e-07}. Best is trial 43 with value: 0.7073808732898264.\u001b[0m\n",
      "regularization_factors, val_score: 0.707381:  85%|########5 | 17/20 [18:37<03:14, 65.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[56]\tvalid_0's rmse: 0.729289\tvalid_1's rmse: 0.709512\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 3.126965 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.734627\tvalid_1's rmse: 0.719345\n",
      "[100]\tvalid_0's rmse: 0.701252\tvalid_1's rmse: 0.717087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.707381:  90%|######### | 18/20 [19:37<02:06, 63.39s/it]\u001b[32m[I 2021-08-25 18:36:27,485]\u001b[0m Trial 60 finished with value: 0.7159794333388341 and parameters: {'lambda_l1': 0.00519758761619444, 'lambda_l2': 0.18598948386256536}. Best is trial 43 with value: 0.7073808732898264.\u001b[0m\n",
      "regularization_factors, val_score: 0.707381:  90%|######### | 18/20 [19:37<02:06, 63.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[75]\tvalid_0's rmse: 0.713266\tvalid_1's rmse: 0.715979\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 3.132877 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.735698\tvalid_1's rmse: 0.710743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.707381:  95%|#########5| 19/20 [20:36<01:02, 62.10s/it]\u001b[32m[I 2021-08-25 18:37:26,560]\u001b[0m Trial 61 finished with value: 0.7094434798823342 and parameters: {'lambda_l1': 3.36506409403049e-05, 'lambda_l2': 2.8042155753267865e-05}. Best is trial 43 with value: 0.7073808732898264.\u001b[0m\n",
      "regularization_factors, val_score: 0.707381:  95%|#########5| 19/20 [20:36<01:02, 62.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[69]\tvalid_0's rmse: 0.719075\tvalid_1's rmse: 0.709443\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 3.134081 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.735644\tvalid_1's rmse: 0.709432\n",
      "[100]\tvalid_0's rmse: 0.70098\tvalid_1's rmse: 0.709839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.707381: 100%|##########| 20/20 [21:38<00:00, 62.12s/it]\u001b[32m[I 2021-08-25 18:38:28,740]\u001b[0m Trial 62 finished with value: 0.707856043568756 and parameters: {'lambda_l1': 0.5711377676112944, 'lambda_l2': 0.0067986557908690706}. Best is trial 43 with value: 0.7073808732898264.\u001b[0m\n",
      "regularization_factors, val_score: 0.707381: 100%|##########| 20/20 [21:38<00:00, 64.92s/it]\n",
      "min_data_in_leaf, val_score: 0.707381:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[80]\tvalid_0's rmse: 0.710644\tvalid_1's rmse: 0.707856\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 3.104776 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.737516\tvalid_1's rmse: 0.71047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.707381:  20%|##        | 1/5 [00:57<03:49, 57.44s/it]\u001b[32m[I 2021-08-25 18:39:26,192]\u001b[0m Trial 63 finished with value: 0.7096674206175176 and parameters: {'min_child_samples': 50}. Best is trial 63 with value: 0.7096674206175176.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.707381:  20%|##        | 1/5 [00:57<03:49, 57.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[58]\tvalid_0's rmse: 0.729723\tvalid_1's rmse: 0.709667\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 4.056495 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.744335\tvalid_1's rmse: 0.725671\n",
      "[100]\tvalid_0's rmse: 0.711773\tvalid_1's rmse: 0.721355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.707381:  40%|####      | 2/5 [02:13<03:24, 68.28s/it]\u001b[32m[I 2021-08-25 18:40:42,061]\u001b[0m Trial 64 finished with value: 0.7210887637456413 and parameters: {'min_child_samples': 100}. Best is trial 63 with value: 0.7096674206175176.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.707381:  40%|####      | 2/5 [02:13<03:24, 68.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[111]\tvalid_0's rmse: 0.707543\tvalid_1's rmse: 0.721089\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 5.789898 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.734669\tvalid_1's rmse: 0.716705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.707381:  60%|######    | 3/5 [03:15<02:10, 65.38s/it]\u001b[32m[I 2021-08-25 18:41:43,992]\u001b[0m Trial 65 finished with value: 0.7149719068531575 and parameters: {'min_child_samples': 10}. Best is trial 63 with value: 0.7096674206175176.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.707381:  60%|######    | 3/5 [03:15<02:10, 65.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 0.700127\tvalid_1's rmse: 0.715679\n",
      "Early stopping, best iteration is:\n",
      "[70]\tvalid_0's rmse: 0.716305\tvalid_1's rmse: 0.714972\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 3.134434 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.733449\tvalid_1's rmse: 0.713573\n",
      "[100]\tvalid_0's rmse: 0.698124\tvalid_1's rmse: 0.712469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.707381:  80%|########  | 4/5 [04:17<01:04, 64.26s/it]\u001b[32m[I 2021-08-25 18:42:46,535]\u001b[0m Trial 66 finished with value: 0.7110524904150468 and parameters: {'min_child_samples': 5}. Best is trial 63 with value: 0.7096674206175176.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.707381:  80%|########  | 4/5 [04:17<01:04, 64.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[82]\tvalid_0's rmse: 0.707451\tvalid_1's rmse: 0.711052\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 3.137552 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19476\n",
      "[LightGBM] [Info] Number of data points in the train set: 7876915, number of used features: 142\n",
      "[LightGBM] [Info] Start training from score 0.310162\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\tvalid_0's rmse: 0.736645\tvalid_1's rmse: 0.712647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.707381: 100%|##########| 5/5 [05:18<00:00, 62.96s/it]\u001b[32m[I 2021-08-25 18:43:47,181]\u001b[0m Trial 67 finished with value: 0.711765147451623 and parameters: {'min_child_samples': 25}. Best is trial 63 with value: 0.7096674206175176.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.707381: 100%|##########| 5/5 [05:18<00:00, 63.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[69]\tvalid_0's rmse: 0.719063\tvalid_1's rmse: 0.711765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import optuna.integration.lightgbm as lgb\n",
    "\n",
    "params = {\n",
    "    'objective': 'mse',\n",
    "    'metric': 'rmse',\n",
    "    'verbose': 1,\n",
    "    'device': 'gpu',\n",
    "    'gpu_platform_id': 0,\n",
    "    'gpu_device_id': 0\n",
    "}\n",
    "cat_feats = ['item_category_id', 'month']\n",
    "\n",
    "last_block = 33\n",
    "dates = matrix['date_block_num']\n",
    "\n",
    "# drop target and some features that lead to overfitting\n",
    "cols_to_drop = ['item_cnt_month', 'new_item', 'shop_id', 'item_id']\n",
    "\n",
    "# split dataset on train and test sets for model training\n",
    "X_train = matrix.loc[dates <  last_block].drop(cols_to_drop, axis=1)\n",
    "X_val = matrix.loc[dates ==  last_block].drop(cols_to_drop, axis=1)\n",
    "X_test = matrix.loc[dates ==  34].drop(cols_to_drop, axis=1)\n",
    "\n",
    "y_train = matrix.loc[dates <  last_block, 'item_cnt_month']\n",
    "y_val = matrix.loc[dates ==  last_block, 'item_cnt_month']\n",
    "\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_eval = lgb.Dataset(X_val, y_val, reference=lgb_train)\n",
    "\n",
    "study = optuna.create_study()\n",
    "\n",
    "gbm = lgb.train(\n",
    "        params,\n",
    "        lgb_train,\n",
    "        num_boost_round=8000,\n",
    "        study = study,\n",
    "        valid_sets=(lgb_train, lgb_eval), \n",
    "#         valid_sets=lgb_train,\n",
    "        categorical_feature = cat_feats,\n",
    "        verbose_eval=50, \n",
    "        early_stopping_rounds = 30,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_bagging_fraction</th>\n",
       "      <th>params_bagging_freq</th>\n",
       "      <th>params_feature_fraction</th>\n",
       "      <th>params_lambda_l1</th>\n",
       "      <th>params_lambda_l2</th>\n",
       "      <th>params_min_child_samples</th>\n",
       "      <th>params_num_leaves</th>\n",
       "      <th>system_attrs_grid_id</th>\n",
       "      <th>system_attrs_lightgbm_tuner:average_iteration_time</th>\n",
       "      <th>system_attrs_lightgbm_tuner:elapsed_secs</th>\n",
       "      <th>system_attrs_lightgbm_tuner:lgbm_params</th>\n",
       "      <th>system_attrs_lightgbm_tuner:step_name</th>\n",
       "      <th>system_attrs_search_space</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.722520</td>\n",
       "      <td>2021-08-25 17:12:54.487311</td>\n",
       "      <td>2021-08-25 17:14:06.152527</td>\n",
       "      <td>0 days 00:01:11.665216</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.542839</td>\n",
       "      <td>71.654730</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>feature_fraction</td>\n",
       "      <td>{'feature_fraction': [0.4, 0.5, 0.6, 0.7, 0.8,...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.716324</td>\n",
       "      <td>2021-08-25 17:14:06.153348</td>\n",
       "      <td>2021-08-25 17:15:20.301700</td>\n",
       "      <td>0 days 00:01:14.148352</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.617863</td>\n",
       "      <td>74.143594</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>feature_fraction</td>\n",
       "      <td>{'feature_fraction': [0.4, 0.5, 0.6, 0.7, 0.8,...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.723806</td>\n",
       "      <td>2021-08-25 17:15:20.302637</td>\n",
       "      <td>2021-08-25 17:17:35.066228</td>\n",
       "      <td>0 days 00:02:14.763591</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.774488</td>\n",
       "      <td>134.760955</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>feature_fraction</td>\n",
       "      <td>{'feature_fraction': [0.4, 0.5, 0.6, 0.7, 0.8,...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.716119</td>\n",
       "      <td>2021-08-25 17:17:35.067031</td>\n",
       "      <td>2021-08-25 17:19:55.218210</td>\n",
       "      <td>0 days 00:02:20.151179</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.491705</td>\n",
       "      <td>140.135919</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>feature_fraction</td>\n",
       "      <td>{'feature_fraction': [0.4, 0.5, 0.6, 0.7, 0.8,...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.716652</td>\n",
       "      <td>2021-08-25 17:19:55.219017</td>\n",
       "      <td>2021-08-25 17:21:20.240540</td>\n",
       "      <td>0 days 00:01:25.021523</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.534659</td>\n",
       "      <td>85.010712</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>feature_fraction</td>\n",
       "      <td>{'feature_fraction': [0.4, 0.5, 0.6, 0.7, 0.8,...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.717912</td>\n",
       "      <td>2021-08-25 17:21:20.241248</td>\n",
       "      <td>2021-08-25 17:23:22.081017</td>\n",
       "      <td>0 days 00:02:01.839769</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.654963</td>\n",
       "      <td>121.823104</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>feature_fraction</td>\n",
       "      <td>{'feature_fraction': [0.4, 0.5, 0.6, 0.7, 0.8,...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.714232</td>\n",
       "      <td>2021-08-25 17:23:22.081870</td>\n",
       "      <td>2021-08-25 17:24:57.788086</td>\n",
       "      <td>0 days 00:01:35.706216</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.429128</td>\n",
       "      <td>95.695437</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>feature_fraction</td>\n",
       "      <td>{'feature_fraction': [0.4, 0.5, 0.6, 0.7, 0.8,...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.710559</td>\n",
       "      <td>2021-08-25 17:24:57.790696</td>\n",
       "      <td>2021-08-25 17:26:28.657642</td>\n",
       "      <td>0 days 00:01:30.866946</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.658395</td>\n",
       "      <td>90.858442</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>num_leaves</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.728288</td>\n",
       "      <td>2021-08-25 17:26:28.658620</td>\n",
       "      <td>2021-08-25 17:28:02.829495</td>\n",
       "      <td>0 days 00:01:34.170875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.376631</td>\n",
       "      <td>94.157679</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>num_leaves</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.722377</td>\n",
       "      <td>2021-08-25 17:28:02.830192</td>\n",
       "      <td>2021-08-25 17:29:31.456878</td>\n",
       "      <td>0 days 00:01:28.626686</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>182.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.877365</td>\n",
       "      <td>88.613841</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>num_leaves</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.722933</td>\n",
       "      <td>2021-08-25 17:29:31.457721</td>\n",
       "      <td>2021-08-25 17:30:49.609970</td>\n",
       "      <td>0 days 00:01:18.152249</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.591980</td>\n",
       "      <td>78.141294</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>num_leaves</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.709652</td>\n",
       "      <td>2021-08-25 17:30:49.610758</td>\n",
       "      <td>2021-08-25 17:32:39.568482</td>\n",
       "      <td>0 days 00:01:49.957724</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>128.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.635539</td>\n",
       "      <td>109.948234</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>num_leaves</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.720194</td>\n",
       "      <td>2021-08-25 17:32:39.569204</td>\n",
       "      <td>2021-08-25 17:34:38.920613</td>\n",
       "      <td>0 days 00:01:59.351409</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.387475</td>\n",
       "      <td>119.342433</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>num_leaves</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.716766</td>\n",
       "      <td>2021-08-25 17:34:38.921587</td>\n",
       "      <td>2021-08-25 17:36:19.901956</td>\n",
       "      <td>0 days 00:01:40.980369</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>231.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.961633</td>\n",
       "      <td>100.971512</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>num_leaves</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.714151</td>\n",
       "      <td>2021-08-25 17:36:19.902697</td>\n",
       "      <td>2021-08-25 17:37:46.249675</td>\n",
       "      <td>0 days 00:01:26.346978</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>255.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.136000</td>\n",
       "      <td>86.335987</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>num_leaves</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.719293</td>\n",
       "      <td>2021-08-25 17:37:46.250681</td>\n",
       "      <td>2021-08-25 17:39:07.415887</td>\n",
       "      <td>0 days 00:01:21.165206</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>145.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.977786</td>\n",
       "      <td>81.156205</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>num_leaves</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.714632</td>\n",
       "      <td>2021-08-25 17:39:07.416871</td>\n",
       "      <td>2021-08-25 17:40:37.480324</td>\n",
       "      <td>0 days 00:01:30.063453</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>249.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.891657</td>\n",
       "      <td>90.057328</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>num_leaves</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.714271</td>\n",
       "      <td>2021-08-25 17:40:37.481229</td>\n",
       "      <td>2021-08-25 17:42:00.481341</td>\n",
       "      <td>0 days 00:01:23.000112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>108.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.797963</td>\n",
       "      <td>82.988151</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>num_leaves</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.712092</td>\n",
       "      <td>2021-08-25 17:42:00.482140</td>\n",
       "      <td>2021-08-25 17:43:35.053938</td>\n",
       "      <td>0 days 00:01:34.571798</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.587324</td>\n",
       "      <td>94.559108</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>num_leaves</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.716175</td>\n",
       "      <td>2021-08-25 17:43:35.054760</td>\n",
       "      <td>2021-08-25 17:45:02.371082</td>\n",
       "      <td>0 days 00:01:27.316322</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656429</td>\n",
       "      <td>87.305004</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>num_leaves</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0.719255</td>\n",
       "      <td>2021-08-25 17:45:02.372049</td>\n",
       "      <td>2021-08-25 17:46:22.443238</td>\n",
       "      <td>0 days 00:01:20.071189</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>148.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.111886</td>\n",
       "      <td>80.055824</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>num_leaves</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0.723618</td>\n",
       "      <td>2021-08-25 17:46:22.444243</td>\n",
       "      <td>2021-08-25 17:47:44.205001</td>\n",
       "      <td>0 days 00:01:21.760758</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>180.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.089989</td>\n",
       "      <td>81.749196</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>num_leaves</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0.717651</td>\n",
       "      <td>2021-08-25 17:47:44.205873</td>\n",
       "      <td>2021-08-25 17:49:32.377198</td>\n",
       "      <td>0 days 00:01:48.171325</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.540790</td>\n",
       "      <td>108.157914</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>num_leaves</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0.711832</td>\n",
       "      <td>2021-08-25 17:49:32.378055</td>\n",
       "      <td>2021-08-25 17:51:01.009332</td>\n",
       "      <td>0 days 00:01:28.631277</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>117.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.720495</td>\n",
       "      <td>88.620888</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>num_leaves</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>0.713581</td>\n",
       "      <td>2021-08-25 17:51:01.010371</td>\n",
       "      <td>2021-08-25 17:52:31.104005</td>\n",
       "      <td>0 days 00:01:30.093634</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>174.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.047458</td>\n",
       "      <td>90.081375</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>num_leaves</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0.713386</td>\n",
       "      <td>2021-08-25 17:52:31.104978</td>\n",
       "      <td>2021-08-25 17:54:10.282222</td>\n",
       "      <td>0 days 00:01:39.177244</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.688645</td>\n",
       "      <td>99.164855</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>num_leaves</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>0.718965</td>\n",
       "      <td>2021-08-25 17:54:10.283050</td>\n",
       "      <td>2021-08-25 17:55:46.871615</td>\n",
       "      <td>0 days 00:01:36.588565</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.551856</td>\n",
       "      <td>96.574873</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>num_leaves</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>0.719522</td>\n",
       "      <td>2021-08-25 17:55:46.874800</td>\n",
       "      <td>2021-08-25 17:57:41.435035</td>\n",
       "      <td>0 days 00:01:54.560235</td>\n",
       "      <td>0.920586</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.753506</td>\n",
       "      <td>114.532971</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>bagging</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0.713037</td>\n",
       "      <td>2021-08-25 17:57:41.435847</td>\n",
       "      <td>2021-08-25 17:59:24.347228</td>\n",
       "      <td>0 days 00:01:42.911381</td>\n",
       "      <td>0.840767</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.850437</td>\n",
       "      <td>102.902828</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>bagging</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>0.718527</td>\n",
       "      <td>2021-08-25 17:59:24.348140</td>\n",
       "      <td>2021-08-25 18:00:42.855523</td>\n",
       "      <td>0 days 00:01:18.507383</td>\n",
       "      <td>0.679668</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.844130</td>\n",
       "      <td>78.504086</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>bagging</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>0.718764</td>\n",
       "      <td>2021-08-25 18:00:42.856320</td>\n",
       "      <td>2021-08-25 18:01:46.105941</td>\n",
       "      <td>0 days 00:01:03.249621</td>\n",
       "      <td>0.434772</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.916619</td>\n",
       "      <td>63.246688</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>bagging</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>0.713070</td>\n",
       "      <td>2021-08-25 18:01:46.108088</td>\n",
       "      <td>2021-08-25 18:03:19.081938</td>\n",
       "      <td>0 days 00:01:32.973850</td>\n",
       "      <td>0.908806</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.958413</td>\n",
       "      <td>92.966079</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>bagging</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>0.708682</td>\n",
       "      <td>2021-08-25 18:03:19.082879</td>\n",
       "      <td>2021-08-25 18:04:27.557391</td>\n",
       "      <td>0 days 00:01:08.474512</td>\n",
       "      <td>0.408690</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.744086</td>\n",
       "      <td>68.455954</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>bagging</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>0.711536</td>\n",
       "      <td>2021-08-25 18:04:27.558287</td>\n",
       "      <td>2021-08-25 18:05:47.028061</td>\n",
       "      <td>0 days 00:01:19.469774</td>\n",
       "      <td>0.652023</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.764105</td>\n",
       "      <td>79.466893</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>bagging</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>0.710781</td>\n",
       "      <td>2021-08-25 18:05:47.028922</td>\n",
       "      <td>2021-08-25 18:07:23.460678</td>\n",
       "      <td>0 days 00:01:36.431756</td>\n",
       "      <td>0.979813</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.973903</td>\n",
       "      <td>96.416374</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>bagging</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>0.720748</td>\n",
       "      <td>2021-08-25 18:07:23.461541</td>\n",
       "      <td>2021-08-25 18:08:39.866827</td>\n",
       "      <td>0 days 00:01:16.405286</td>\n",
       "      <td>0.429070</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.992108</td>\n",
       "      <td>76.392290</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>bagging</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>0.711612</td>\n",
       "      <td>2021-08-25 18:08:39.867913</td>\n",
       "      <td>2021-08-25 18:10:36.313304</td>\n",
       "      <td>0 days 00:01:56.445391</td>\n",
       "      <td>0.994879</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.786774</td>\n",
       "      <td>116.442538</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>bagging</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>0.718198</td>\n",
       "      <td>2021-08-25 18:10:36.317953</td>\n",
       "      <td>2021-08-25 18:11:32.989556</td>\n",
       "      <td>0 days 00:00:56.671603</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.880</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.833013</td>\n",
       "      <td>56.644893</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>feature_fraction_stage2</td>\n",
       "      <td>{'feature_fraction': [0.7200000000000001, 0.75...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>0.708772</td>\n",
       "      <td>2021-08-25 18:11:32.990483</td>\n",
       "      <td>2021-08-25 18:12:32.468036</td>\n",
       "      <td>0 days 00:00:59.477553</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.816</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.837467</td>\n",
       "      <td>59.460146</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>feature_fraction_stage2</td>\n",
       "      <td>{'feature_fraction': [0.7200000000000001, 0.75...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>0.713657</td>\n",
       "      <td>2021-08-25 18:12:32.469133</td>\n",
       "      <td>2021-08-25 18:13:58.066593</td>\n",
       "      <td>0 days 00:01:25.597460</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.848</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.559365</td>\n",
       "      <td>85.582839</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>feature_fraction_stage2</td>\n",
       "      <td>{'feature_fraction': [0.7200000000000001, 0.75...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>0.712877</td>\n",
       "      <td>2021-08-25 18:13:58.067545</td>\n",
       "      <td>2021-08-25 18:15:00.476591</td>\n",
       "      <td>0 days 00:01:02.409046</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.784</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.770432</td>\n",
       "      <td>62.404973</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>feature_fraction_stage2</td>\n",
       "      <td>{'feature_fraction': [0.7200000000000001, 0.75...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>0.717607</td>\n",
       "      <td>2021-08-25 18:15:00.477533</td>\n",
       "      <td>2021-08-25 18:15:54.565933</td>\n",
       "      <td>0 days 00:00:54.088400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.720</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.948876</td>\n",
       "      <td>54.085920</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>feature_fraction_stage2</td>\n",
       "      <td>{'feature_fraction': [0.7200000000000001, 0.75...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>0.715568</td>\n",
       "      <td>2021-08-25 18:15:54.566751</td>\n",
       "      <td>2021-08-25 18:16:50.332717</td>\n",
       "      <td>0 days 00:00:55.765966</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.752</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.914150</td>\n",
       "      <td>55.763153</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>feature_fraction_stage2</td>\n",
       "      <td>{'feature_fraction': [0.7200000000000001, 0.75...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>0.707381</td>\n",
       "      <td>2021-08-25 18:16:50.337707</td>\n",
       "      <td>2021-08-25 18:17:52.681070</td>\n",
       "      <td>0 days 00:01:02.343363</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.359563e-01</td>\n",
       "      <td>5.422400e-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.741982</td>\n",
       "      <td>62.326452</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>regularization_factors</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>0.708586</td>\n",
       "      <td>2021-08-25 18:17:52.682001</td>\n",
       "      <td>2021-08-25 18:19:01.528375</td>\n",
       "      <td>0 days 00:01:08.846374</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.001941e-06</td>\n",
       "      <td>8.557431e-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.748137</td>\n",
       "      <td>68.828604</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>regularization_factors</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>0.707709</td>\n",
       "      <td>2021-08-25 18:19:01.529329</td>\n",
       "      <td>2021-08-25 18:20:21.418086</td>\n",
       "      <td>0 days 00:01:19.888757</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.642911e-08</td>\n",
       "      <td>7.973800e-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.583057</td>\n",
       "      <td>79.878837</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>regularization_factors</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>0.707480</td>\n",
       "      <td>2021-08-25 18:20:21.418959</td>\n",
       "      <td>2021-08-25 18:21:20.129669</td>\n",
       "      <td>0 days 00:00:58.710710</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.834887e-03</td>\n",
       "      <td>1.646967e-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.850741</td>\n",
       "      <td>58.701117</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>regularization_factors</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>0.710248</td>\n",
       "      <td>2021-08-25 18:21:20.130650</td>\n",
       "      <td>2021-08-25 18:22:19.868845</td>\n",
       "      <td>0 days 00:00:59.738195</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.231091e-06</td>\n",
       "      <td>8.691219e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.029774</td>\n",
       "      <td>59.726886</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>regularization_factors</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>0.708586</td>\n",
       "      <td>2021-08-25 18:22:19.870215</td>\n",
       "      <td>2021-08-25 18:23:29.940327</td>\n",
       "      <td>0 days 00:01:10.070112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.105133e-08</td>\n",
       "      <td>3.858593e-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761501</td>\n",
       "      <td>70.058116</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>regularization_factors</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>0.708598</td>\n",
       "      <td>2021-08-25 18:23:29.941159</td>\n",
       "      <td>2021-08-25 18:24:30.460053</td>\n",
       "      <td>0 days 00:01:00.518894</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.078578e-07</td>\n",
       "      <td>1.023588e-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.828889</td>\n",
       "      <td>60.508918</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>regularization_factors</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50</td>\n",
       "      <td>0.711145</td>\n",
       "      <td>2021-08-25 18:24:30.460951</td>\n",
       "      <td>2021-08-25 18:25:26.744155</td>\n",
       "      <td>0 days 00:00:56.283204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.879536e-01</td>\n",
       "      <td>7.422945e-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.839806</td>\n",
       "      <td>56.267018</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>regularization_factors</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>51</td>\n",
       "      <td>0.717261</td>\n",
       "      <td>2021-08-25 18:25:26.745032</td>\n",
       "      <td>2021-08-25 18:26:25.678246</td>\n",
       "      <td>0 days 00:00:58.933214</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.407804e-02</td>\n",
       "      <td>7.568133e-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.998553</td>\n",
       "      <td>58.914634</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>regularization_factors</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>52</td>\n",
       "      <td>0.712085</td>\n",
       "      <td>2021-08-25 18:26:25.679082</td>\n",
       "      <td>2021-08-25 18:27:28.715200</td>\n",
       "      <td>0 days 00:01:03.036118</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.647334e-07</td>\n",
       "      <td>1.327121e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.851571</td>\n",
       "      <td>63.016257</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>regularization_factors</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>53</td>\n",
       "      <td>0.711987</td>\n",
       "      <td>2021-08-25 18:27:28.716039</td>\n",
       "      <td>2021-08-25 18:28:49.270659</td>\n",
       "      <td>0 days 00:01:20.554620</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.568009e+00</td>\n",
       "      <td>7.191665e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.567192</td>\n",
       "      <td>80.541294</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>regularization_factors</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>54</td>\n",
       "      <td>0.707709</td>\n",
       "      <td>2021-08-25 18:28:49.271554</td>\n",
       "      <td>2021-08-25 18:30:02.462917</td>\n",
       "      <td>0 days 00:01:13.191363</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.768050e-04</td>\n",
       "      <td>5.534236e-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.665252</td>\n",
       "      <td>73.177722</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>regularization_factors</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>55</td>\n",
       "      <td>0.709615</td>\n",
       "      <td>2021-08-25 18:30:02.463824</td>\n",
       "      <td>2021-08-25 18:31:13.870719</td>\n",
       "      <td>0 days 00:01:11.406895</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.442263e-03</td>\n",
       "      <td>1.470337e-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.610200</td>\n",
       "      <td>71.393346</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>regularization_factors</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>56</td>\n",
       "      <td>0.711122</td>\n",
       "      <td>2021-08-25 18:31:13.871513</td>\n",
       "      <td>2021-08-25 18:32:12.581554</td>\n",
       "      <td>0 days 00:00:58.710041</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.368635e-02</td>\n",
       "      <td>7.611364e-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.962160</td>\n",
       "      <td>58.691790</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>regularization_factors</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>57</td>\n",
       "      <td>0.715428</td>\n",
       "      <td>2021-08-25 18:32:12.582640</td>\n",
       "      <td>2021-08-25 18:33:12.315306</td>\n",
       "      <td>0 days 00:00:59.732666</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.982110e+00</td>\n",
       "      <td>3.910097e-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.841097</td>\n",
       "      <td>59.717869</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>regularization_factors</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>58</td>\n",
       "      <td>0.709749</td>\n",
       "      <td>2021-08-25 18:33:12.316200</td>\n",
       "      <td>2021-08-25 18:34:32.694899</td>\n",
       "      <td>0 days 00:01:20.378699</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.592574e-05</td>\n",
       "      <td>1.968098e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550432</td>\n",
       "      <td>80.363129</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>regularization_factors</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>59</td>\n",
       "      <td>0.709512</td>\n",
       "      <td>2021-08-25 18:34:32.695754</td>\n",
       "      <td>2021-08-25 18:35:27.822213</td>\n",
       "      <td>0 days 00:00:55.126459</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.371261e-01</td>\n",
       "      <td>8.137655e-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.984089</td>\n",
       "      <td>55.108969</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>regularization_factors</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>60</td>\n",
       "      <td>0.715979</td>\n",
       "      <td>2021-08-25 18:35:27.823271</td>\n",
       "      <td>2021-08-25 18:36:27.485032</td>\n",
       "      <td>0 days 00:00:59.661761</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.197588e-03</td>\n",
       "      <td>1.859895e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.795280</td>\n",
       "      <td>59.646016</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>regularization_factors</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>61</td>\n",
       "      <td>0.709443</td>\n",
       "      <td>2021-08-25 18:36:27.485896</td>\n",
       "      <td>2021-08-25 18:37:26.560396</td>\n",
       "      <td>0 days 00:00:59.074500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.365064e-05</td>\n",
       "      <td>2.804216e-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.855889</td>\n",
       "      <td>59.056315</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>regularization_factors</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>62</td>\n",
       "      <td>0.707856</td>\n",
       "      <td>2021-08-25 18:37:26.561179</td>\n",
       "      <td>2021-08-25 18:38:28.740617</td>\n",
       "      <td>0 days 00:01:02.179438</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.711378e-01</td>\n",
       "      <td>6.798656e-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.777018</td>\n",
       "      <td>62.161449</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>regularization_factors</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>63</td>\n",
       "      <td>0.709667</td>\n",
       "      <td>2021-08-25 18:38:28.745276</td>\n",
       "      <td>2021-08-25 18:39:26.191914</td>\n",
       "      <td>0 days 00:00:57.446638</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.990301</td>\n",
       "      <td>57.437471</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>min_data_in_leaf</td>\n",
       "      <td>{'min_child_samples': [5, 10, 25, 50, 100]}</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>64</td>\n",
       "      <td>0.721089</td>\n",
       "      <td>2021-08-25 18:39:26.192882</td>\n",
       "      <td>2021-08-25 18:40:42.061688</td>\n",
       "      <td>0 days 00:01:15.868806</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.683397</td>\n",
       "      <td>75.857064</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>min_data_in_leaf</td>\n",
       "      <td>{'min_child_samples': [5, 10, 25, 50, 100]}</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>65</td>\n",
       "      <td>0.714972</td>\n",
       "      <td>2021-08-25 18:40:42.062408</td>\n",
       "      <td>2021-08-25 18:41:43.992632</td>\n",
       "      <td>0 days 00:01:01.930224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.884540</td>\n",
       "      <td>61.917783</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>min_data_in_leaf</td>\n",
       "      <td>{'min_child_samples': [5, 10, 25, 50, 100]}</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>66</td>\n",
       "      <td>0.711052</td>\n",
       "      <td>2021-08-25 18:41:43.993531</td>\n",
       "      <td>2021-08-25 18:42:46.535504</td>\n",
       "      <td>0 days 00:01:02.541973</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.762576</td>\n",
       "      <td>62.531250</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>min_data_in_leaf</td>\n",
       "      <td>{'min_child_samples': [5, 10, 25, 50, 100]}</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>67</td>\n",
       "      <td>0.711765</td>\n",
       "      <td>2021-08-25 18:42:46.536315</td>\n",
       "      <td>2021-08-25 18:43:47.180808</td>\n",
       "      <td>0 days 00:01:00.644493</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.878870</td>\n",
       "      <td>60.642050</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>min_data_in_leaf</td>\n",
       "      <td>{'min_child_samples': [5, 10, 25, 50, 100]}</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    number     value             datetime_start          datetime_complete  \\\n",
       "0        0  0.722520 2021-08-25 17:12:54.487311 2021-08-25 17:14:06.152527   \n",
       "1        1  0.716324 2021-08-25 17:14:06.153348 2021-08-25 17:15:20.301700   \n",
       "2        2  0.723806 2021-08-25 17:15:20.302637 2021-08-25 17:17:35.066228   \n",
       "3        3  0.716119 2021-08-25 17:17:35.067031 2021-08-25 17:19:55.218210   \n",
       "4        4  0.716652 2021-08-25 17:19:55.219017 2021-08-25 17:21:20.240540   \n",
       "5        5  0.717912 2021-08-25 17:21:20.241248 2021-08-25 17:23:22.081017   \n",
       "6        6  0.714232 2021-08-25 17:23:22.081870 2021-08-25 17:24:57.788086   \n",
       "7        7  0.710559 2021-08-25 17:24:57.790696 2021-08-25 17:26:28.657642   \n",
       "8        8  0.728288 2021-08-25 17:26:28.658620 2021-08-25 17:28:02.829495   \n",
       "9        9  0.722377 2021-08-25 17:28:02.830192 2021-08-25 17:29:31.456878   \n",
       "10      10  0.722933 2021-08-25 17:29:31.457721 2021-08-25 17:30:49.609970   \n",
       "11      11  0.709652 2021-08-25 17:30:49.610758 2021-08-25 17:32:39.568482   \n",
       "12      12  0.720194 2021-08-25 17:32:39.569204 2021-08-25 17:34:38.920613   \n",
       "13      13  0.716766 2021-08-25 17:34:38.921587 2021-08-25 17:36:19.901956   \n",
       "14      14  0.714151 2021-08-25 17:36:19.902697 2021-08-25 17:37:46.249675   \n",
       "15      15  0.719293 2021-08-25 17:37:46.250681 2021-08-25 17:39:07.415887   \n",
       "16      16  0.714632 2021-08-25 17:39:07.416871 2021-08-25 17:40:37.480324   \n",
       "17      17  0.714271 2021-08-25 17:40:37.481229 2021-08-25 17:42:00.481341   \n",
       "18      18  0.712092 2021-08-25 17:42:00.482140 2021-08-25 17:43:35.053938   \n",
       "19      19  0.716175 2021-08-25 17:43:35.054760 2021-08-25 17:45:02.371082   \n",
       "20      20  0.719255 2021-08-25 17:45:02.372049 2021-08-25 17:46:22.443238   \n",
       "21      21  0.723618 2021-08-25 17:46:22.444243 2021-08-25 17:47:44.205001   \n",
       "22      22  0.717651 2021-08-25 17:47:44.205873 2021-08-25 17:49:32.377198   \n",
       "23      23  0.711832 2021-08-25 17:49:32.378055 2021-08-25 17:51:01.009332   \n",
       "24      24  0.713581 2021-08-25 17:51:01.010371 2021-08-25 17:52:31.104005   \n",
       "25      25  0.713386 2021-08-25 17:52:31.104978 2021-08-25 17:54:10.282222   \n",
       "26      26  0.718965 2021-08-25 17:54:10.283050 2021-08-25 17:55:46.871615   \n",
       "27      27  0.719522 2021-08-25 17:55:46.874800 2021-08-25 17:57:41.435035   \n",
       "28      28  0.713037 2021-08-25 17:57:41.435847 2021-08-25 17:59:24.347228   \n",
       "29      29  0.718527 2021-08-25 17:59:24.348140 2021-08-25 18:00:42.855523   \n",
       "30      30  0.718764 2021-08-25 18:00:42.856320 2021-08-25 18:01:46.105941   \n",
       "31      31  0.713070 2021-08-25 18:01:46.108088 2021-08-25 18:03:19.081938   \n",
       "32      32  0.708682 2021-08-25 18:03:19.082879 2021-08-25 18:04:27.557391   \n",
       "33      33  0.711536 2021-08-25 18:04:27.558287 2021-08-25 18:05:47.028061   \n",
       "34      34  0.710781 2021-08-25 18:05:47.028922 2021-08-25 18:07:23.460678   \n",
       "35      35  0.720748 2021-08-25 18:07:23.461541 2021-08-25 18:08:39.866827   \n",
       "36      36  0.711612 2021-08-25 18:08:39.867913 2021-08-25 18:10:36.313304   \n",
       "37      37  0.718198 2021-08-25 18:10:36.317953 2021-08-25 18:11:32.989556   \n",
       "38      38  0.708772 2021-08-25 18:11:32.990483 2021-08-25 18:12:32.468036   \n",
       "39      39  0.713657 2021-08-25 18:12:32.469133 2021-08-25 18:13:58.066593   \n",
       "40      40  0.712877 2021-08-25 18:13:58.067545 2021-08-25 18:15:00.476591   \n",
       "41      41  0.717607 2021-08-25 18:15:00.477533 2021-08-25 18:15:54.565933   \n",
       "42      42  0.715568 2021-08-25 18:15:54.566751 2021-08-25 18:16:50.332717   \n",
       "43      43  0.707381 2021-08-25 18:16:50.337707 2021-08-25 18:17:52.681070   \n",
       "44      44  0.708586 2021-08-25 18:17:52.682001 2021-08-25 18:19:01.528375   \n",
       "45      45  0.707709 2021-08-25 18:19:01.529329 2021-08-25 18:20:21.418086   \n",
       "46      46  0.707480 2021-08-25 18:20:21.418959 2021-08-25 18:21:20.129669   \n",
       "47      47  0.710248 2021-08-25 18:21:20.130650 2021-08-25 18:22:19.868845   \n",
       "48      48  0.708586 2021-08-25 18:22:19.870215 2021-08-25 18:23:29.940327   \n",
       "49      49  0.708598 2021-08-25 18:23:29.941159 2021-08-25 18:24:30.460053   \n",
       "50      50  0.711145 2021-08-25 18:24:30.460951 2021-08-25 18:25:26.744155   \n",
       "51      51  0.717261 2021-08-25 18:25:26.745032 2021-08-25 18:26:25.678246   \n",
       "52      52  0.712085 2021-08-25 18:26:25.679082 2021-08-25 18:27:28.715200   \n",
       "53      53  0.711987 2021-08-25 18:27:28.716039 2021-08-25 18:28:49.270659   \n",
       "54      54  0.707709 2021-08-25 18:28:49.271554 2021-08-25 18:30:02.462917   \n",
       "55      55  0.709615 2021-08-25 18:30:02.463824 2021-08-25 18:31:13.870719   \n",
       "56      56  0.711122 2021-08-25 18:31:13.871513 2021-08-25 18:32:12.581554   \n",
       "57      57  0.715428 2021-08-25 18:32:12.582640 2021-08-25 18:33:12.315306   \n",
       "58      58  0.709749 2021-08-25 18:33:12.316200 2021-08-25 18:34:32.694899   \n",
       "59      59  0.709512 2021-08-25 18:34:32.695754 2021-08-25 18:35:27.822213   \n",
       "60      60  0.715979 2021-08-25 18:35:27.823271 2021-08-25 18:36:27.485032   \n",
       "61      61  0.709443 2021-08-25 18:36:27.485896 2021-08-25 18:37:26.560396   \n",
       "62      62  0.707856 2021-08-25 18:37:26.561179 2021-08-25 18:38:28.740617   \n",
       "63      63  0.709667 2021-08-25 18:38:28.745276 2021-08-25 18:39:26.191914   \n",
       "64      64  0.721089 2021-08-25 18:39:26.192882 2021-08-25 18:40:42.061688   \n",
       "65      65  0.714972 2021-08-25 18:40:42.062408 2021-08-25 18:41:43.992632   \n",
       "66      66  0.711052 2021-08-25 18:41:43.993531 2021-08-25 18:42:46.535504   \n",
       "67      67  0.711765 2021-08-25 18:42:46.536315 2021-08-25 18:43:47.180808   \n",
       "\n",
       "                 duration  params_bagging_fraction  params_bagging_freq  \\\n",
       "0  0 days 00:01:11.665216                      NaN                  NaN   \n",
       "1  0 days 00:01:14.148352                      NaN                  NaN   \n",
       "2  0 days 00:02:14.763591                      NaN                  NaN   \n",
       "3  0 days 00:02:20.151179                      NaN                  NaN   \n",
       "4  0 days 00:01:25.021523                      NaN                  NaN   \n",
       "5  0 days 00:02:01.839769                      NaN                  NaN   \n",
       "6  0 days 00:01:35.706216                      NaN                  NaN   \n",
       "7  0 days 00:01:30.866946                      NaN                  NaN   \n",
       "8  0 days 00:01:34.170875                      NaN                  NaN   \n",
       "9  0 days 00:01:28.626686                      NaN                  NaN   \n",
       "10 0 days 00:01:18.152249                      NaN                  NaN   \n",
       "11 0 days 00:01:49.957724                      NaN                  NaN   \n",
       "12 0 days 00:01:59.351409                      NaN                  NaN   \n",
       "13 0 days 00:01:40.980369                      NaN                  NaN   \n",
       "14 0 days 00:01:26.346978                      NaN                  NaN   \n",
       "15 0 days 00:01:21.165206                      NaN                  NaN   \n",
       "16 0 days 00:01:30.063453                      NaN                  NaN   \n",
       "17 0 days 00:01:23.000112                      NaN                  NaN   \n",
       "18 0 days 00:01:34.571798                      NaN                  NaN   \n",
       "19 0 days 00:01:27.316322                      NaN                  NaN   \n",
       "20 0 days 00:01:20.071189                      NaN                  NaN   \n",
       "21 0 days 00:01:21.760758                      NaN                  NaN   \n",
       "22 0 days 00:01:48.171325                      NaN                  NaN   \n",
       "23 0 days 00:01:28.631277                      NaN                  NaN   \n",
       "24 0 days 00:01:30.093634                      NaN                  NaN   \n",
       "25 0 days 00:01:39.177244                      NaN                  NaN   \n",
       "26 0 days 00:01:36.588565                      NaN                  NaN   \n",
       "27 0 days 00:01:54.560235                 0.920586                  6.0   \n",
       "28 0 days 00:01:42.911381                 0.840767                  4.0   \n",
       "29 0 days 00:01:18.507383                 0.679668                  1.0   \n",
       "30 0 days 00:01:03.249621                 0.434772                  3.0   \n",
       "31 0 days 00:01:32.973850                 0.908806                  6.0   \n",
       "32 0 days 00:01:08.474512                 0.408690                  5.0   \n",
       "33 0 days 00:01:19.469774                 0.652023                  7.0   \n",
       "34 0 days 00:01:36.431756                 0.979813                  5.0   \n",
       "35 0 days 00:01:16.405286                 0.429070                  1.0   \n",
       "36 0 days 00:01:56.445391                 0.994879                  5.0   \n",
       "37 0 days 00:00:56.671603                      NaN                  NaN   \n",
       "38 0 days 00:00:59.477553                      NaN                  NaN   \n",
       "39 0 days 00:01:25.597460                      NaN                  NaN   \n",
       "40 0 days 00:01:02.409046                      NaN                  NaN   \n",
       "41 0 days 00:00:54.088400                      NaN                  NaN   \n",
       "42 0 days 00:00:55.765966                      NaN                  NaN   \n",
       "43 0 days 00:01:02.343363                      NaN                  NaN   \n",
       "44 0 days 00:01:08.846374                      NaN                  NaN   \n",
       "45 0 days 00:01:19.888757                      NaN                  NaN   \n",
       "46 0 days 00:00:58.710710                      NaN                  NaN   \n",
       "47 0 days 00:00:59.738195                      NaN                  NaN   \n",
       "48 0 days 00:01:10.070112                      NaN                  NaN   \n",
       "49 0 days 00:01:00.518894                      NaN                  NaN   \n",
       "50 0 days 00:00:56.283204                      NaN                  NaN   \n",
       "51 0 days 00:00:58.933214                      NaN                  NaN   \n",
       "52 0 days 00:01:03.036118                      NaN                  NaN   \n",
       "53 0 days 00:01:20.554620                      NaN                  NaN   \n",
       "54 0 days 00:01:13.191363                      NaN                  NaN   \n",
       "55 0 days 00:01:11.406895                      NaN                  NaN   \n",
       "56 0 days 00:00:58.710041                      NaN                  NaN   \n",
       "57 0 days 00:00:59.732666                      NaN                  NaN   \n",
       "58 0 days 00:01:20.378699                      NaN                  NaN   \n",
       "59 0 days 00:00:55.126459                      NaN                  NaN   \n",
       "60 0 days 00:00:59.661761                      NaN                  NaN   \n",
       "61 0 days 00:00:59.074500                      NaN                  NaN   \n",
       "62 0 days 00:01:02.179438                      NaN                  NaN   \n",
       "63 0 days 00:00:57.446638                      NaN                  NaN   \n",
       "64 0 days 00:01:15.868806                      NaN                  NaN   \n",
       "65 0 days 00:01:01.930224                      NaN                  NaN   \n",
       "66 0 days 00:01:02.541973                      NaN                  NaN   \n",
       "67 0 days 00:01:00.644493                      NaN                  NaN   \n",
       "\n",
       "    params_feature_fraction  params_lambda_l1  params_lambda_l2  \\\n",
       "0                     0.600               NaN               NaN   \n",
       "1                     0.900               NaN               NaN   \n",
       "2                     0.500               NaN               NaN   \n",
       "3                     1.000               NaN               NaN   \n",
       "4                     0.700               NaN               NaN   \n",
       "5                     0.400               NaN               NaN   \n",
       "6                     0.800               NaN               NaN   \n",
       "7                       NaN               NaN               NaN   \n",
       "8                       NaN               NaN               NaN   \n",
       "9                       NaN               NaN               NaN   \n",
       "10                      NaN               NaN               NaN   \n",
       "11                      NaN               NaN               NaN   \n",
       "12                      NaN               NaN               NaN   \n",
       "13                      NaN               NaN               NaN   \n",
       "14                      NaN               NaN               NaN   \n",
       "15                      NaN               NaN               NaN   \n",
       "16                      NaN               NaN               NaN   \n",
       "17                      NaN               NaN               NaN   \n",
       "18                      NaN               NaN               NaN   \n",
       "19                      NaN               NaN               NaN   \n",
       "20                      NaN               NaN               NaN   \n",
       "21                      NaN               NaN               NaN   \n",
       "22                      NaN               NaN               NaN   \n",
       "23                      NaN               NaN               NaN   \n",
       "24                      NaN               NaN               NaN   \n",
       "25                      NaN               NaN               NaN   \n",
       "26                      NaN               NaN               NaN   \n",
       "27                      NaN               NaN               NaN   \n",
       "28                      NaN               NaN               NaN   \n",
       "29                      NaN               NaN               NaN   \n",
       "30                      NaN               NaN               NaN   \n",
       "31                      NaN               NaN               NaN   \n",
       "32                      NaN               NaN               NaN   \n",
       "33                      NaN               NaN               NaN   \n",
       "34                      NaN               NaN               NaN   \n",
       "35                      NaN               NaN               NaN   \n",
       "36                      NaN               NaN               NaN   \n",
       "37                    0.880               NaN               NaN   \n",
       "38                    0.816               NaN               NaN   \n",
       "39                    0.848               NaN               NaN   \n",
       "40                    0.784               NaN               NaN   \n",
       "41                    0.720               NaN               NaN   \n",
       "42                    0.752               NaN               NaN   \n",
       "43                      NaN      2.359563e-01      5.422400e-02   \n",
       "44                      NaN      2.001941e-06      8.557431e-05   \n",
       "45                      NaN      3.642911e-08      7.973800e-05   \n",
       "46                      NaN      1.834887e-03      1.646967e-04   \n",
       "47                      NaN      2.231091e-06      8.691219e-01   \n",
       "48                      NaN      1.105133e-08      3.858593e-08   \n",
       "49                      NaN      1.078578e-07      1.023588e-03   \n",
       "50                      NaN      3.879536e-01      7.422945e-04   \n",
       "51                      NaN      4.407804e-02      7.568133e-06   \n",
       "52                      NaN      3.647334e-07      1.327121e-01   \n",
       "53                      NaN      9.568009e+00      7.191665e+00   \n",
       "54                      NaN      5.768050e-04      5.534236e-02   \n",
       "55                      NaN      1.442263e-03      1.470337e-02   \n",
       "56                      NaN      2.368635e-02      7.611364e-07   \n",
       "57                      NaN      6.982110e+00      3.910097e-03   \n",
       "58                      NaN      3.592574e-05      1.968098e+00   \n",
       "59                      NaN      4.371261e-01      8.137655e-07   \n",
       "60                      NaN      5.197588e-03      1.859895e-01   \n",
       "61                      NaN      3.365064e-05      2.804216e-05   \n",
       "62                      NaN      5.711378e-01      6.798656e-03   \n",
       "63                      NaN               NaN               NaN   \n",
       "64                      NaN               NaN               NaN   \n",
       "65                      NaN               NaN               NaN   \n",
       "66                      NaN               NaN               NaN   \n",
       "67                      NaN               NaN               NaN   \n",
       "\n",
       "    params_min_child_samples  params_num_leaves  system_attrs_grid_id  \\\n",
       "0                        NaN                NaN                   2.0   \n",
       "1                        NaN                NaN                   5.0   \n",
       "2                        NaN                NaN                   1.0   \n",
       "3                        NaN                NaN                   6.0   \n",
       "4                        NaN                NaN                   3.0   \n",
       "5                        NaN                NaN                   0.0   \n",
       "6                        NaN                NaN                   4.0   \n",
       "7                        NaN               84.0                   NaN   \n",
       "8                        NaN               10.0                   NaN   \n",
       "9                        NaN              182.0                   NaN   \n",
       "10                       NaN               40.0                   NaN   \n",
       "11                       NaN              128.0                   NaN   \n",
       "12                       NaN               22.0                   NaN   \n",
       "13                       NaN              231.0                   NaN   \n",
       "14                       NaN              255.0                   NaN   \n",
       "15                       NaN              145.0                   NaN   \n",
       "16                       NaN              249.0                   NaN   \n",
       "17                       NaN              108.0                   NaN   \n",
       "18                       NaN               87.0                   NaN   \n",
       "19                       NaN               69.0                   NaN   \n",
       "20                       NaN              148.0                   NaN   \n",
       "21                       NaN              180.0                   NaN   \n",
       "22                       NaN               71.0                   NaN   \n",
       "23                       NaN              117.0                   NaN   \n",
       "24                       NaN              174.0                   NaN   \n",
       "25                       NaN               95.0                   NaN   \n",
       "26                       NaN               52.0                   NaN   \n",
       "27                       NaN                NaN                   NaN   \n",
       "28                       NaN                NaN                   NaN   \n",
       "29                       NaN                NaN                   NaN   \n",
       "30                       NaN                NaN                   NaN   \n",
       "31                       NaN                NaN                   NaN   \n",
       "32                       NaN                NaN                   NaN   \n",
       "33                       NaN                NaN                   NaN   \n",
       "34                       NaN                NaN                   NaN   \n",
       "35                       NaN                NaN                   NaN   \n",
       "36                       NaN                NaN                   NaN   \n",
       "37                       NaN                NaN                   5.0   \n",
       "38                       NaN                NaN                   3.0   \n",
       "39                       NaN                NaN                   4.0   \n",
       "40                       NaN                NaN                   2.0   \n",
       "41                       NaN                NaN                   0.0   \n",
       "42                       NaN                NaN                   1.0   \n",
       "43                       NaN                NaN                   NaN   \n",
       "44                       NaN                NaN                   NaN   \n",
       "45                       NaN                NaN                   NaN   \n",
       "46                       NaN                NaN                   NaN   \n",
       "47                       NaN                NaN                   NaN   \n",
       "48                       NaN                NaN                   NaN   \n",
       "49                       NaN                NaN                   NaN   \n",
       "50                       NaN                NaN                   NaN   \n",
       "51                       NaN                NaN                   NaN   \n",
       "52                       NaN                NaN                   NaN   \n",
       "53                       NaN                NaN                   NaN   \n",
       "54                       NaN                NaN                   NaN   \n",
       "55                       NaN                NaN                   NaN   \n",
       "56                       NaN                NaN                   NaN   \n",
       "57                       NaN                NaN                   NaN   \n",
       "58                       NaN                NaN                   NaN   \n",
       "59                       NaN                NaN                   NaN   \n",
       "60                       NaN                NaN                   NaN   \n",
       "61                       NaN                NaN                   NaN   \n",
       "62                       NaN                NaN                   NaN   \n",
       "63                      50.0                NaN                   3.0   \n",
       "64                     100.0                NaN                   4.0   \n",
       "65                      10.0                NaN                   1.0   \n",
       "66                       5.0                NaN                   0.0   \n",
       "67                      25.0                NaN                   2.0   \n",
       "\n",
       "    system_attrs_lightgbm_tuner:average_iteration_time  \\\n",
       "0                                            0.542839    \n",
       "1                                            0.617863    \n",
       "2                                            0.774488    \n",
       "3                                            0.491705    \n",
       "4                                            0.534659    \n",
       "5                                            0.654963    \n",
       "6                                            0.429128    \n",
       "7                                            0.658395    \n",
       "8                                            0.376631    \n",
       "9                                            0.877365    \n",
       "10                                           0.591980    \n",
       "11                                           0.635539    \n",
       "12                                           0.387475    \n",
       "13                                           0.961633    \n",
       "14                                           1.136000    \n",
       "15                                           0.977786    \n",
       "16                                           0.891657    \n",
       "17                                           0.797963    \n",
       "18                                           0.587324    \n",
       "19                                           0.656429    \n",
       "20                                           1.111886    \n",
       "21                                           1.089989    \n",
       "22                                           0.540790    \n",
       "23                                           0.720495    \n",
       "24                                           1.047458    \n",
       "25                                           0.688645    \n",
       "26                                           0.551856    \n",
       "27                                           0.753506    \n",
       "28                                           0.850437    \n",
       "29                                           0.844130    \n",
       "30                                           0.916619    \n",
       "31                                           0.958413    \n",
       "32                                           0.744086    \n",
       "33                                           0.764105    \n",
       "34                                           0.973903    \n",
       "35                                           0.992108    \n",
       "36                                           0.786774    \n",
       "37                                           0.833013    \n",
       "38                                           0.837467    \n",
       "39                                           0.559365    \n",
       "40                                           0.770432    \n",
       "41                                           0.948876    \n",
       "42                                           0.914150    \n",
       "43                                           0.741982    \n",
       "44                                           0.748137    \n",
       "45                                           0.583057    \n",
       "46                                           0.850741    \n",
       "47                                           1.029774    \n",
       "48                                           0.761501    \n",
       "49                                           0.828889    \n",
       "50                                           0.839806    \n",
       "51                                           0.998553    \n",
       "52                                           0.851571    \n",
       "53                                           0.567192    \n",
       "54                                           0.665252    \n",
       "55                                           0.610200    \n",
       "56                                           0.962160    \n",
       "57                                           0.841097    \n",
       "58                                           0.550432    \n",
       "59                                           0.984089    \n",
       "60                                           0.795280    \n",
       "61                                           0.855889    \n",
       "62                                           0.777018    \n",
       "63                                           0.990301    \n",
       "64                                           0.683397    \n",
       "65                                           0.884540    \n",
       "66                                           0.762576    \n",
       "67                                           0.878870    \n",
       "\n",
       "    system_attrs_lightgbm_tuner:elapsed_secs  \\\n",
       "0                                  71.654730   \n",
       "1                                  74.143594   \n",
       "2                                 134.760955   \n",
       "3                                 140.135919   \n",
       "4                                  85.010712   \n",
       "5                                 121.823104   \n",
       "6                                  95.695437   \n",
       "7                                  90.858442   \n",
       "8                                  94.157679   \n",
       "9                                  88.613841   \n",
       "10                                 78.141294   \n",
       "11                                109.948234   \n",
       "12                                119.342433   \n",
       "13                                100.971512   \n",
       "14                                 86.335987   \n",
       "15                                 81.156205   \n",
       "16                                 90.057328   \n",
       "17                                 82.988151   \n",
       "18                                 94.559108   \n",
       "19                                 87.305004   \n",
       "20                                 80.055824   \n",
       "21                                 81.749196   \n",
       "22                                108.157914   \n",
       "23                                 88.620888   \n",
       "24                                 90.081375   \n",
       "25                                 99.164855   \n",
       "26                                 96.574873   \n",
       "27                                114.532971   \n",
       "28                                102.902828   \n",
       "29                                 78.504086   \n",
       "30                                 63.246688   \n",
       "31                                 92.966079   \n",
       "32                                 68.455954   \n",
       "33                                 79.466893   \n",
       "34                                 96.416374   \n",
       "35                                 76.392290   \n",
       "36                                116.442538   \n",
       "37                                 56.644893   \n",
       "38                                 59.460146   \n",
       "39                                 85.582839   \n",
       "40                                 62.404973   \n",
       "41                                 54.085920   \n",
       "42                                 55.763153   \n",
       "43                                 62.326452   \n",
       "44                                 68.828604   \n",
       "45                                 79.878837   \n",
       "46                                 58.701117   \n",
       "47                                 59.726886   \n",
       "48                                 70.058116   \n",
       "49                                 60.508918   \n",
       "50                                 56.267018   \n",
       "51                                 58.914634   \n",
       "52                                 63.016257   \n",
       "53                                 80.541294   \n",
       "54                                 73.177722   \n",
       "55                                 71.393346   \n",
       "56                                 58.691790   \n",
       "57                                 59.717869   \n",
       "58                                 80.363129   \n",
       "59                                 55.108969   \n",
       "60                                 59.646016   \n",
       "61                                 59.056315   \n",
       "62                                 62.161449   \n",
       "63                                 57.437471   \n",
       "64                                 75.857064   \n",
       "65                                 61.917783   \n",
       "66                                 62.531250   \n",
       "67                                 60.642050   \n",
       "\n",
       "              system_attrs_lightgbm_tuner:lgbm_params  \\\n",
       "0   {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "1   {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "2   {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "3   {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "4   {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "5   {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "6   {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "7   {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "8   {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "9   {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "10  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "11  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "12  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "13  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "14  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "15  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "16  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "17  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "18  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "19  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "20  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "21  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "22  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "23  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "24  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "25  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "26  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "27  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "28  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "29  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "30  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "31  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "32  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "33  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "34  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "35  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "36  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "37  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "38  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "39  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "40  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "41  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "42  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "43  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "44  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "45  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "46  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "47  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "48  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "49  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "50  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "51  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "52  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "53  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "54  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "55  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "56  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "57  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "58  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "59  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "60  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "61  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "62  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "63  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "64  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "65  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "66  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "67  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "\n",
       "   system_attrs_lightgbm_tuner:step_name  \\\n",
       "0                       feature_fraction   \n",
       "1                       feature_fraction   \n",
       "2                       feature_fraction   \n",
       "3                       feature_fraction   \n",
       "4                       feature_fraction   \n",
       "5                       feature_fraction   \n",
       "6                       feature_fraction   \n",
       "7                             num_leaves   \n",
       "8                             num_leaves   \n",
       "9                             num_leaves   \n",
       "10                            num_leaves   \n",
       "11                            num_leaves   \n",
       "12                            num_leaves   \n",
       "13                            num_leaves   \n",
       "14                            num_leaves   \n",
       "15                            num_leaves   \n",
       "16                            num_leaves   \n",
       "17                            num_leaves   \n",
       "18                            num_leaves   \n",
       "19                            num_leaves   \n",
       "20                            num_leaves   \n",
       "21                            num_leaves   \n",
       "22                            num_leaves   \n",
       "23                            num_leaves   \n",
       "24                            num_leaves   \n",
       "25                            num_leaves   \n",
       "26                            num_leaves   \n",
       "27                               bagging   \n",
       "28                               bagging   \n",
       "29                               bagging   \n",
       "30                               bagging   \n",
       "31                               bagging   \n",
       "32                               bagging   \n",
       "33                               bagging   \n",
       "34                               bagging   \n",
       "35                               bagging   \n",
       "36                               bagging   \n",
       "37               feature_fraction_stage2   \n",
       "38               feature_fraction_stage2   \n",
       "39               feature_fraction_stage2   \n",
       "40               feature_fraction_stage2   \n",
       "41               feature_fraction_stage2   \n",
       "42               feature_fraction_stage2   \n",
       "43                regularization_factors   \n",
       "44                regularization_factors   \n",
       "45                regularization_factors   \n",
       "46                regularization_factors   \n",
       "47                regularization_factors   \n",
       "48                regularization_factors   \n",
       "49                regularization_factors   \n",
       "50                regularization_factors   \n",
       "51                regularization_factors   \n",
       "52                regularization_factors   \n",
       "53                regularization_factors   \n",
       "54                regularization_factors   \n",
       "55                regularization_factors   \n",
       "56                regularization_factors   \n",
       "57                regularization_factors   \n",
       "58                regularization_factors   \n",
       "59                regularization_factors   \n",
       "60                regularization_factors   \n",
       "61                regularization_factors   \n",
       "62                regularization_factors   \n",
       "63                      min_data_in_leaf   \n",
       "64                      min_data_in_leaf   \n",
       "65                      min_data_in_leaf   \n",
       "66                      min_data_in_leaf   \n",
       "67                      min_data_in_leaf   \n",
       "\n",
       "                            system_attrs_search_space     state  \n",
       "0   {'feature_fraction': [0.4, 0.5, 0.6, 0.7, 0.8,...  COMPLETE  \n",
       "1   {'feature_fraction': [0.4, 0.5, 0.6, 0.7, 0.8,...  COMPLETE  \n",
       "2   {'feature_fraction': [0.4, 0.5, 0.6, 0.7, 0.8,...  COMPLETE  \n",
       "3   {'feature_fraction': [0.4, 0.5, 0.6, 0.7, 0.8,...  COMPLETE  \n",
       "4   {'feature_fraction': [0.4, 0.5, 0.6, 0.7, 0.8,...  COMPLETE  \n",
       "5   {'feature_fraction': [0.4, 0.5, 0.6, 0.7, 0.8,...  COMPLETE  \n",
       "6   {'feature_fraction': [0.4, 0.5, 0.6, 0.7, 0.8,...  COMPLETE  \n",
       "7                                                 NaN  COMPLETE  \n",
       "8                                                 NaN  COMPLETE  \n",
       "9                                                 NaN  COMPLETE  \n",
       "10                                                NaN  COMPLETE  \n",
       "11                                                NaN  COMPLETE  \n",
       "12                                                NaN  COMPLETE  \n",
       "13                                                NaN  COMPLETE  \n",
       "14                                                NaN  COMPLETE  \n",
       "15                                                NaN  COMPLETE  \n",
       "16                                                NaN  COMPLETE  \n",
       "17                                                NaN  COMPLETE  \n",
       "18                                                NaN  COMPLETE  \n",
       "19                                                NaN  COMPLETE  \n",
       "20                                                NaN  COMPLETE  \n",
       "21                                                NaN  COMPLETE  \n",
       "22                                                NaN  COMPLETE  \n",
       "23                                                NaN  COMPLETE  \n",
       "24                                                NaN  COMPLETE  \n",
       "25                                                NaN  COMPLETE  \n",
       "26                                                NaN  COMPLETE  \n",
       "27                                                NaN  COMPLETE  \n",
       "28                                                NaN  COMPLETE  \n",
       "29                                                NaN  COMPLETE  \n",
       "30                                                NaN  COMPLETE  \n",
       "31                                                NaN  COMPLETE  \n",
       "32                                                NaN  COMPLETE  \n",
       "33                                                NaN  COMPLETE  \n",
       "34                                                NaN  COMPLETE  \n",
       "35                                                NaN  COMPLETE  \n",
       "36                                                NaN  COMPLETE  \n",
       "37  {'feature_fraction': [0.7200000000000001, 0.75...  COMPLETE  \n",
       "38  {'feature_fraction': [0.7200000000000001, 0.75...  COMPLETE  \n",
       "39  {'feature_fraction': [0.7200000000000001, 0.75...  COMPLETE  \n",
       "40  {'feature_fraction': [0.7200000000000001, 0.75...  COMPLETE  \n",
       "41  {'feature_fraction': [0.7200000000000001, 0.75...  COMPLETE  \n",
       "42  {'feature_fraction': [0.7200000000000001, 0.75...  COMPLETE  \n",
       "43                                                NaN  COMPLETE  \n",
       "44                                                NaN  COMPLETE  \n",
       "45                                                NaN  COMPLETE  \n",
       "46                                                NaN  COMPLETE  \n",
       "47                                                NaN  COMPLETE  \n",
       "48                                                NaN  COMPLETE  \n",
       "49                                                NaN  COMPLETE  \n",
       "50                                                NaN  COMPLETE  \n",
       "51                                                NaN  COMPLETE  \n",
       "52                                                NaN  COMPLETE  \n",
       "53                                                NaN  COMPLETE  \n",
       "54                                                NaN  COMPLETE  \n",
       "55                                                NaN  COMPLETE  \n",
       "56                                                NaN  COMPLETE  \n",
       "57                                                NaN  COMPLETE  \n",
       "58                                                NaN  COMPLETE  \n",
       "59                                                NaN  COMPLETE  \n",
       "60                                                NaN  COMPLETE  \n",
       "61                                                NaN  COMPLETE  \n",
       "62                                                NaN  COMPLETE  \n",
       "63        {'min_child_samples': [5, 10, 25, 50, 100]}  COMPLETE  \n",
       "64        {'min_child_samples': [5, 10, 25, 50, 100]}  COMPLETE  \n",
       "65        {'min_child_samples': [5, 10, 25, 50, 100]}  COMPLETE  \n",
       "66        {'min_child_samples': [5, 10, 25, 50, 100]}  COMPLETE  \n",
       "67        {'min_child_samples': [5, 10, 25, 50, 100]}  COMPLETE  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.trials_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_bagging_fraction</th>\n",
       "      <th>params_bagging_freq</th>\n",
       "      <th>params_feature_fraction</th>\n",
       "      <th>params_lambda_l1</th>\n",
       "      <th>params_lambda_l2</th>\n",
       "      <th>params_min_child_samples</th>\n",
       "      <th>params_num_leaves</th>\n",
       "      <th>system_attrs_grid_id</th>\n",
       "      <th>system_attrs_lightgbm_tuner:average_iteration_time</th>\n",
       "      <th>system_attrs_lightgbm_tuner:elapsed_secs</th>\n",
       "      <th>system_attrs_lightgbm_tuner:lgbm_params</th>\n",
       "      <th>system_attrs_lightgbm_tuner:step_name</th>\n",
       "      <th>system_attrs_search_space</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>0.707381</td>\n",
       "      <td>2021-08-25 18:16:50.337707</td>\n",
       "      <td>2021-08-25 18:17:52.681070</td>\n",
       "      <td>0 days 00:01:02.343363</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.359563e-01</td>\n",
       "      <td>5.422400e-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.741982</td>\n",
       "      <td>62.326452</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>regularization_factors</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>0.707480</td>\n",
       "      <td>2021-08-25 18:20:21.418959</td>\n",
       "      <td>2021-08-25 18:21:20.129669</td>\n",
       "      <td>0 days 00:00:58.710710</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.834887e-03</td>\n",
       "      <td>1.646967e-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.850741</td>\n",
       "      <td>58.701117</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>regularization_factors</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>0.707709</td>\n",
       "      <td>2021-08-25 18:19:01.529329</td>\n",
       "      <td>2021-08-25 18:20:21.418086</td>\n",
       "      <td>0 days 00:01:19.888757</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.642911e-08</td>\n",
       "      <td>7.973800e-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.583057</td>\n",
       "      <td>79.878837</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>regularization_factors</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>54</td>\n",
       "      <td>0.707709</td>\n",
       "      <td>2021-08-25 18:28:49.271554</td>\n",
       "      <td>2021-08-25 18:30:02.462917</td>\n",
       "      <td>0 days 00:01:13.191363</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.768050e-04</td>\n",
       "      <td>5.534236e-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.665252</td>\n",
       "      <td>73.177722</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>regularization_factors</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>62</td>\n",
       "      <td>0.707856</td>\n",
       "      <td>2021-08-25 18:37:26.561179</td>\n",
       "      <td>2021-08-25 18:38:28.740617</td>\n",
       "      <td>0 days 00:01:02.179438</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.711378e-01</td>\n",
       "      <td>6.798656e-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.777018</td>\n",
       "      <td>62.161449</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>regularization_factors</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>0.708586</td>\n",
       "      <td>2021-08-25 18:17:52.682001</td>\n",
       "      <td>2021-08-25 18:19:01.528375</td>\n",
       "      <td>0 days 00:01:08.846374</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.001941e-06</td>\n",
       "      <td>8.557431e-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.748137</td>\n",
       "      <td>68.828604</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>regularization_factors</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>0.708586</td>\n",
       "      <td>2021-08-25 18:22:19.870215</td>\n",
       "      <td>2021-08-25 18:23:29.940327</td>\n",
       "      <td>0 days 00:01:10.070112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.105133e-08</td>\n",
       "      <td>3.858593e-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761501</td>\n",
       "      <td>70.058116</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>regularization_factors</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>0.708598</td>\n",
       "      <td>2021-08-25 18:23:29.941159</td>\n",
       "      <td>2021-08-25 18:24:30.460053</td>\n",
       "      <td>0 days 00:01:00.518894</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.078578e-07</td>\n",
       "      <td>1.023588e-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.828889</td>\n",
       "      <td>60.508918</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>regularization_factors</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>0.708682</td>\n",
       "      <td>2021-08-25 18:03:19.082879</td>\n",
       "      <td>2021-08-25 18:04:27.557391</td>\n",
       "      <td>0 days 00:01:08.474512</td>\n",
       "      <td>0.408690</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.744086</td>\n",
       "      <td>68.455954</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>bagging</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>0.708772</td>\n",
       "      <td>2021-08-25 18:11:32.990483</td>\n",
       "      <td>2021-08-25 18:12:32.468036</td>\n",
       "      <td>0 days 00:00:59.477553</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.816</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.837467</td>\n",
       "      <td>59.460146</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>feature_fraction_stage2</td>\n",
       "      <td>{'feature_fraction': [0.7200000000000001, 0.75...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>61</td>\n",
       "      <td>0.709443</td>\n",
       "      <td>2021-08-25 18:36:27.485896</td>\n",
       "      <td>2021-08-25 18:37:26.560396</td>\n",
       "      <td>0 days 00:00:59.074500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.365064e-05</td>\n",
       "      <td>2.804216e-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.855889</td>\n",
       "      <td>59.056315</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>regularization_factors</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>59</td>\n",
       "      <td>0.709512</td>\n",
       "      <td>2021-08-25 18:34:32.695754</td>\n",
       "      <td>2021-08-25 18:35:27.822213</td>\n",
       "      <td>0 days 00:00:55.126459</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.371261e-01</td>\n",
       "      <td>8.137655e-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.984089</td>\n",
       "      <td>55.108969</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>regularization_factors</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>55</td>\n",
       "      <td>0.709615</td>\n",
       "      <td>2021-08-25 18:30:02.463824</td>\n",
       "      <td>2021-08-25 18:31:13.870719</td>\n",
       "      <td>0 days 00:01:11.406895</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.442263e-03</td>\n",
       "      <td>1.470337e-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.610200</td>\n",
       "      <td>71.393346</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>regularization_factors</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.709652</td>\n",
       "      <td>2021-08-25 17:30:49.610758</td>\n",
       "      <td>2021-08-25 17:32:39.568482</td>\n",
       "      <td>0 days 00:01:49.957724</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>128.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.635539</td>\n",
       "      <td>109.948234</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>num_leaves</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>63</td>\n",
       "      <td>0.709667</td>\n",
       "      <td>2021-08-25 18:38:28.745276</td>\n",
       "      <td>2021-08-25 18:39:26.191914</td>\n",
       "      <td>0 days 00:00:57.446638</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.990301</td>\n",
       "      <td>57.437471</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>min_data_in_leaf</td>\n",
       "      <td>{'min_child_samples': [5, 10, 25, 50, 100]}</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>58</td>\n",
       "      <td>0.709749</td>\n",
       "      <td>2021-08-25 18:33:12.316200</td>\n",
       "      <td>2021-08-25 18:34:32.694899</td>\n",
       "      <td>0 days 00:01:20.378699</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.592574e-05</td>\n",
       "      <td>1.968098e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.550432</td>\n",
       "      <td>80.363129</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>regularization_factors</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>0.710248</td>\n",
       "      <td>2021-08-25 18:21:20.130650</td>\n",
       "      <td>2021-08-25 18:22:19.868845</td>\n",
       "      <td>0 days 00:00:59.738195</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.231091e-06</td>\n",
       "      <td>8.691219e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.029774</td>\n",
       "      <td>59.726886</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>regularization_factors</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.710559</td>\n",
       "      <td>2021-08-25 17:24:57.790696</td>\n",
       "      <td>2021-08-25 17:26:28.657642</td>\n",
       "      <td>0 days 00:01:30.866946</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.658395</td>\n",
       "      <td>90.858442</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>num_leaves</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>0.710781</td>\n",
       "      <td>2021-08-25 18:05:47.028922</td>\n",
       "      <td>2021-08-25 18:07:23.460678</td>\n",
       "      <td>0 days 00:01:36.431756</td>\n",
       "      <td>0.979813</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.973903</td>\n",
       "      <td>96.416374</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>bagging</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>66</td>\n",
       "      <td>0.711052</td>\n",
       "      <td>2021-08-25 18:41:43.993531</td>\n",
       "      <td>2021-08-25 18:42:46.535504</td>\n",
       "      <td>0 days 00:01:02.541973</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.762576</td>\n",
       "      <td>62.531250</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>min_data_in_leaf</td>\n",
       "      <td>{'min_child_samples': [5, 10, 25, 50, 100]}</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>56</td>\n",
       "      <td>0.711122</td>\n",
       "      <td>2021-08-25 18:31:13.871513</td>\n",
       "      <td>2021-08-25 18:32:12.581554</td>\n",
       "      <td>0 days 00:00:58.710041</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.368635e-02</td>\n",
       "      <td>7.611364e-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.962160</td>\n",
       "      <td>58.691790</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>regularization_factors</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50</td>\n",
       "      <td>0.711145</td>\n",
       "      <td>2021-08-25 18:24:30.460951</td>\n",
       "      <td>2021-08-25 18:25:26.744155</td>\n",
       "      <td>0 days 00:00:56.283204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.879536e-01</td>\n",
       "      <td>7.422945e-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.839806</td>\n",
       "      <td>56.267018</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>regularization_factors</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>0.711536</td>\n",
       "      <td>2021-08-25 18:04:27.558287</td>\n",
       "      <td>2021-08-25 18:05:47.028061</td>\n",
       "      <td>0 days 00:01:19.469774</td>\n",
       "      <td>0.652023</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.764105</td>\n",
       "      <td>79.466893</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>bagging</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>0.711612</td>\n",
       "      <td>2021-08-25 18:08:39.867913</td>\n",
       "      <td>2021-08-25 18:10:36.313304</td>\n",
       "      <td>0 days 00:01:56.445391</td>\n",
       "      <td>0.994879</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.786774</td>\n",
       "      <td>116.442538</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>bagging</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>67</td>\n",
       "      <td>0.711765</td>\n",
       "      <td>2021-08-25 18:42:46.536315</td>\n",
       "      <td>2021-08-25 18:43:47.180808</td>\n",
       "      <td>0 days 00:01:00.644493</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.878870</td>\n",
       "      <td>60.642050</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>min_data_in_leaf</td>\n",
       "      <td>{'min_child_samples': [5, 10, 25, 50, 100]}</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0.711832</td>\n",
       "      <td>2021-08-25 17:49:32.378055</td>\n",
       "      <td>2021-08-25 17:51:01.009332</td>\n",
       "      <td>0 days 00:01:28.631277</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>117.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.720495</td>\n",
       "      <td>88.620888</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>num_leaves</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>53</td>\n",
       "      <td>0.711987</td>\n",
       "      <td>2021-08-25 18:27:28.716039</td>\n",
       "      <td>2021-08-25 18:28:49.270659</td>\n",
       "      <td>0 days 00:01:20.554620</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.568009e+00</td>\n",
       "      <td>7.191665e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.567192</td>\n",
       "      <td>80.541294</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>regularization_factors</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>52</td>\n",
       "      <td>0.712085</td>\n",
       "      <td>2021-08-25 18:26:25.679082</td>\n",
       "      <td>2021-08-25 18:27:28.715200</td>\n",
       "      <td>0 days 00:01:03.036118</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.647334e-07</td>\n",
       "      <td>1.327121e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.851571</td>\n",
       "      <td>63.016257</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>regularization_factors</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.712092</td>\n",
       "      <td>2021-08-25 17:42:00.482140</td>\n",
       "      <td>2021-08-25 17:43:35.053938</td>\n",
       "      <td>0 days 00:01:34.571798</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.587324</td>\n",
       "      <td>94.559108</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>num_leaves</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>0.712877</td>\n",
       "      <td>2021-08-25 18:13:58.067545</td>\n",
       "      <td>2021-08-25 18:15:00.476591</td>\n",
       "      <td>0 days 00:01:02.409046</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.784</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.770432</td>\n",
       "      <td>62.404973</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>feature_fraction_stage2</td>\n",
       "      <td>{'feature_fraction': [0.7200000000000001, 0.75...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0.713037</td>\n",
       "      <td>2021-08-25 17:57:41.435847</td>\n",
       "      <td>2021-08-25 17:59:24.347228</td>\n",
       "      <td>0 days 00:01:42.911381</td>\n",
       "      <td>0.840767</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.850437</td>\n",
       "      <td>102.902828</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>bagging</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>0.713070</td>\n",
       "      <td>2021-08-25 18:01:46.108088</td>\n",
       "      <td>2021-08-25 18:03:19.081938</td>\n",
       "      <td>0 days 00:01:32.973850</td>\n",
       "      <td>0.908806</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.958413</td>\n",
       "      <td>92.966079</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>bagging</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0.713386</td>\n",
       "      <td>2021-08-25 17:52:31.104978</td>\n",
       "      <td>2021-08-25 17:54:10.282222</td>\n",
       "      <td>0 days 00:01:39.177244</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.688645</td>\n",
       "      <td>99.164855</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>num_leaves</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>0.713581</td>\n",
       "      <td>2021-08-25 17:51:01.010371</td>\n",
       "      <td>2021-08-25 17:52:31.104005</td>\n",
       "      <td>0 days 00:01:30.093634</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>174.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.047458</td>\n",
       "      <td>90.081375</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>num_leaves</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>0.713657</td>\n",
       "      <td>2021-08-25 18:12:32.469133</td>\n",
       "      <td>2021-08-25 18:13:58.066593</td>\n",
       "      <td>0 days 00:01:25.597460</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.848</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.559365</td>\n",
       "      <td>85.582839</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>feature_fraction_stage2</td>\n",
       "      <td>{'feature_fraction': [0.7200000000000001, 0.75...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.714151</td>\n",
       "      <td>2021-08-25 17:36:19.902697</td>\n",
       "      <td>2021-08-25 17:37:46.249675</td>\n",
       "      <td>0 days 00:01:26.346978</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>255.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.136000</td>\n",
       "      <td>86.335987</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>num_leaves</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.714232</td>\n",
       "      <td>2021-08-25 17:23:22.081870</td>\n",
       "      <td>2021-08-25 17:24:57.788086</td>\n",
       "      <td>0 days 00:01:35.706216</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.429128</td>\n",
       "      <td>95.695437</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>feature_fraction</td>\n",
       "      <td>{'feature_fraction': [0.4, 0.5, 0.6, 0.7, 0.8,...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.714271</td>\n",
       "      <td>2021-08-25 17:40:37.481229</td>\n",
       "      <td>2021-08-25 17:42:00.481341</td>\n",
       "      <td>0 days 00:01:23.000112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>108.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.797963</td>\n",
       "      <td>82.988151</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>num_leaves</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.714632</td>\n",
       "      <td>2021-08-25 17:39:07.416871</td>\n",
       "      <td>2021-08-25 17:40:37.480324</td>\n",
       "      <td>0 days 00:01:30.063453</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>249.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.891657</td>\n",
       "      <td>90.057328</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>num_leaves</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>65</td>\n",
       "      <td>0.714972</td>\n",
       "      <td>2021-08-25 18:40:42.062408</td>\n",
       "      <td>2021-08-25 18:41:43.992632</td>\n",
       "      <td>0 days 00:01:01.930224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.884540</td>\n",
       "      <td>61.917783</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>min_data_in_leaf</td>\n",
       "      <td>{'min_child_samples': [5, 10, 25, 50, 100]}</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>57</td>\n",
       "      <td>0.715428</td>\n",
       "      <td>2021-08-25 18:32:12.582640</td>\n",
       "      <td>2021-08-25 18:33:12.315306</td>\n",
       "      <td>0 days 00:00:59.732666</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.982110e+00</td>\n",
       "      <td>3.910097e-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.841097</td>\n",
       "      <td>59.717869</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>regularization_factors</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>0.715568</td>\n",
       "      <td>2021-08-25 18:15:54.566751</td>\n",
       "      <td>2021-08-25 18:16:50.332717</td>\n",
       "      <td>0 days 00:00:55.765966</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.752</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.914150</td>\n",
       "      <td>55.763153</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>feature_fraction_stage2</td>\n",
       "      <td>{'feature_fraction': [0.7200000000000001, 0.75...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>60</td>\n",
       "      <td>0.715979</td>\n",
       "      <td>2021-08-25 18:35:27.823271</td>\n",
       "      <td>2021-08-25 18:36:27.485032</td>\n",
       "      <td>0 days 00:00:59.661761</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.197588e-03</td>\n",
       "      <td>1.859895e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.795280</td>\n",
       "      <td>59.646016</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>regularization_factors</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.716119</td>\n",
       "      <td>2021-08-25 17:17:35.067031</td>\n",
       "      <td>2021-08-25 17:19:55.218210</td>\n",
       "      <td>0 days 00:02:20.151179</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.491705</td>\n",
       "      <td>140.135919</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>feature_fraction</td>\n",
       "      <td>{'feature_fraction': [0.4, 0.5, 0.6, 0.7, 0.8,...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.716175</td>\n",
       "      <td>2021-08-25 17:43:35.054760</td>\n",
       "      <td>2021-08-25 17:45:02.371082</td>\n",
       "      <td>0 days 00:01:27.316322</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656429</td>\n",
       "      <td>87.305004</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>num_leaves</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.716324</td>\n",
       "      <td>2021-08-25 17:14:06.153348</td>\n",
       "      <td>2021-08-25 17:15:20.301700</td>\n",
       "      <td>0 days 00:01:14.148352</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.617863</td>\n",
       "      <td>74.143594</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>feature_fraction</td>\n",
       "      <td>{'feature_fraction': [0.4, 0.5, 0.6, 0.7, 0.8,...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.716652</td>\n",
       "      <td>2021-08-25 17:19:55.219017</td>\n",
       "      <td>2021-08-25 17:21:20.240540</td>\n",
       "      <td>0 days 00:01:25.021523</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.534659</td>\n",
       "      <td>85.010712</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>feature_fraction</td>\n",
       "      <td>{'feature_fraction': [0.4, 0.5, 0.6, 0.7, 0.8,...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.716766</td>\n",
       "      <td>2021-08-25 17:34:38.921587</td>\n",
       "      <td>2021-08-25 17:36:19.901956</td>\n",
       "      <td>0 days 00:01:40.980369</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>231.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.961633</td>\n",
       "      <td>100.971512</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>num_leaves</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>51</td>\n",
       "      <td>0.717261</td>\n",
       "      <td>2021-08-25 18:25:26.745032</td>\n",
       "      <td>2021-08-25 18:26:25.678246</td>\n",
       "      <td>0 days 00:00:58.933214</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.407804e-02</td>\n",
       "      <td>7.568133e-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.998553</td>\n",
       "      <td>58.914634</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>regularization_factors</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>0.717607</td>\n",
       "      <td>2021-08-25 18:15:00.477533</td>\n",
       "      <td>2021-08-25 18:15:54.565933</td>\n",
       "      <td>0 days 00:00:54.088400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.720</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.948876</td>\n",
       "      <td>54.085920</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>feature_fraction_stage2</td>\n",
       "      <td>{'feature_fraction': [0.7200000000000001, 0.75...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0.717651</td>\n",
       "      <td>2021-08-25 17:47:44.205873</td>\n",
       "      <td>2021-08-25 17:49:32.377198</td>\n",
       "      <td>0 days 00:01:48.171325</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.540790</td>\n",
       "      <td>108.157914</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>num_leaves</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.717912</td>\n",
       "      <td>2021-08-25 17:21:20.241248</td>\n",
       "      <td>2021-08-25 17:23:22.081017</td>\n",
       "      <td>0 days 00:02:01.839769</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.654963</td>\n",
       "      <td>121.823104</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>feature_fraction</td>\n",
       "      <td>{'feature_fraction': [0.4, 0.5, 0.6, 0.7, 0.8,...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>0.718198</td>\n",
       "      <td>2021-08-25 18:10:36.317953</td>\n",
       "      <td>2021-08-25 18:11:32.989556</td>\n",
       "      <td>0 days 00:00:56.671603</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.880</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.833013</td>\n",
       "      <td>56.644893</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>feature_fraction_stage2</td>\n",
       "      <td>{'feature_fraction': [0.7200000000000001, 0.75...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>0.718527</td>\n",
       "      <td>2021-08-25 17:59:24.348140</td>\n",
       "      <td>2021-08-25 18:00:42.855523</td>\n",
       "      <td>0 days 00:01:18.507383</td>\n",
       "      <td>0.679668</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.844130</td>\n",
       "      <td>78.504086</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>bagging</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>0.718764</td>\n",
       "      <td>2021-08-25 18:00:42.856320</td>\n",
       "      <td>2021-08-25 18:01:46.105941</td>\n",
       "      <td>0 days 00:01:03.249621</td>\n",
       "      <td>0.434772</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.916619</td>\n",
       "      <td>63.246688</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>bagging</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>0.718965</td>\n",
       "      <td>2021-08-25 17:54:10.283050</td>\n",
       "      <td>2021-08-25 17:55:46.871615</td>\n",
       "      <td>0 days 00:01:36.588565</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.551856</td>\n",
       "      <td>96.574873</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>num_leaves</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0.719255</td>\n",
       "      <td>2021-08-25 17:45:02.372049</td>\n",
       "      <td>2021-08-25 17:46:22.443238</td>\n",
       "      <td>0 days 00:01:20.071189</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>148.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.111886</td>\n",
       "      <td>80.055824</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>num_leaves</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.719293</td>\n",
       "      <td>2021-08-25 17:37:46.250681</td>\n",
       "      <td>2021-08-25 17:39:07.415887</td>\n",
       "      <td>0 days 00:01:21.165206</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>145.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.977786</td>\n",
       "      <td>81.156205</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>num_leaves</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>0.719522</td>\n",
       "      <td>2021-08-25 17:55:46.874800</td>\n",
       "      <td>2021-08-25 17:57:41.435035</td>\n",
       "      <td>0 days 00:01:54.560235</td>\n",
       "      <td>0.920586</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.753506</td>\n",
       "      <td>114.532971</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>bagging</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.720194</td>\n",
       "      <td>2021-08-25 17:32:39.569204</td>\n",
       "      <td>2021-08-25 17:34:38.920613</td>\n",
       "      <td>0 days 00:01:59.351409</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.387475</td>\n",
       "      <td>119.342433</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>num_leaves</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>0.720748</td>\n",
       "      <td>2021-08-25 18:07:23.461541</td>\n",
       "      <td>2021-08-25 18:08:39.866827</td>\n",
       "      <td>0 days 00:01:16.405286</td>\n",
       "      <td>0.429070</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.992108</td>\n",
       "      <td>76.392290</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>bagging</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>64</td>\n",
       "      <td>0.721089</td>\n",
       "      <td>2021-08-25 18:39:26.192882</td>\n",
       "      <td>2021-08-25 18:40:42.061688</td>\n",
       "      <td>0 days 00:01:15.868806</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.683397</td>\n",
       "      <td>75.857064</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>min_data_in_leaf</td>\n",
       "      <td>{'min_child_samples': [5, 10, 25, 50, 100]}</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.722377</td>\n",
       "      <td>2021-08-25 17:28:02.830192</td>\n",
       "      <td>2021-08-25 17:29:31.456878</td>\n",
       "      <td>0 days 00:01:28.626686</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>182.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.877365</td>\n",
       "      <td>88.613841</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>num_leaves</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.722520</td>\n",
       "      <td>2021-08-25 17:12:54.487311</td>\n",
       "      <td>2021-08-25 17:14:06.152527</td>\n",
       "      <td>0 days 00:01:11.665216</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.542839</td>\n",
       "      <td>71.654730</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>feature_fraction</td>\n",
       "      <td>{'feature_fraction': [0.4, 0.5, 0.6, 0.7, 0.8,...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.722933</td>\n",
       "      <td>2021-08-25 17:29:31.457721</td>\n",
       "      <td>2021-08-25 17:30:49.609970</td>\n",
       "      <td>0 days 00:01:18.152249</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.591980</td>\n",
       "      <td>78.141294</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>num_leaves</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0.723618</td>\n",
       "      <td>2021-08-25 17:46:22.444243</td>\n",
       "      <td>2021-08-25 17:47:44.205001</td>\n",
       "      <td>0 days 00:01:21.760758</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>180.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.089989</td>\n",
       "      <td>81.749196</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>num_leaves</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.723806</td>\n",
       "      <td>2021-08-25 17:15:20.302637</td>\n",
       "      <td>2021-08-25 17:17:35.066228</td>\n",
       "      <td>0 days 00:02:14.763591</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.774488</td>\n",
       "      <td>134.760955</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>feature_fraction</td>\n",
       "      <td>{'feature_fraction': [0.4, 0.5, 0.6, 0.7, 0.8,...</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.728288</td>\n",
       "      <td>2021-08-25 17:26:28.658620</td>\n",
       "      <td>2021-08-25 17:28:02.829495</td>\n",
       "      <td>0 days 00:01:34.170875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.376631</td>\n",
       "      <td>94.157679</td>\n",
       "      <td>{\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...</td>\n",
       "      <td>num_leaves</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    number     value             datetime_start          datetime_complete  \\\n",
       "43      43  0.707381 2021-08-25 18:16:50.337707 2021-08-25 18:17:52.681070   \n",
       "46      46  0.707480 2021-08-25 18:20:21.418959 2021-08-25 18:21:20.129669   \n",
       "45      45  0.707709 2021-08-25 18:19:01.529329 2021-08-25 18:20:21.418086   \n",
       "54      54  0.707709 2021-08-25 18:28:49.271554 2021-08-25 18:30:02.462917   \n",
       "62      62  0.707856 2021-08-25 18:37:26.561179 2021-08-25 18:38:28.740617   \n",
       "44      44  0.708586 2021-08-25 18:17:52.682001 2021-08-25 18:19:01.528375   \n",
       "48      48  0.708586 2021-08-25 18:22:19.870215 2021-08-25 18:23:29.940327   \n",
       "49      49  0.708598 2021-08-25 18:23:29.941159 2021-08-25 18:24:30.460053   \n",
       "32      32  0.708682 2021-08-25 18:03:19.082879 2021-08-25 18:04:27.557391   \n",
       "38      38  0.708772 2021-08-25 18:11:32.990483 2021-08-25 18:12:32.468036   \n",
       "61      61  0.709443 2021-08-25 18:36:27.485896 2021-08-25 18:37:26.560396   \n",
       "59      59  0.709512 2021-08-25 18:34:32.695754 2021-08-25 18:35:27.822213   \n",
       "55      55  0.709615 2021-08-25 18:30:02.463824 2021-08-25 18:31:13.870719   \n",
       "11      11  0.709652 2021-08-25 17:30:49.610758 2021-08-25 17:32:39.568482   \n",
       "63      63  0.709667 2021-08-25 18:38:28.745276 2021-08-25 18:39:26.191914   \n",
       "58      58  0.709749 2021-08-25 18:33:12.316200 2021-08-25 18:34:32.694899   \n",
       "47      47  0.710248 2021-08-25 18:21:20.130650 2021-08-25 18:22:19.868845   \n",
       "7        7  0.710559 2021-08-25 17:24:57.790696 2021-08-25 17:26:28.657642   \n",
       "34      34  0.710781 2021-08-25 18:05:47.028922 2021-08-25 18:07:23.460678   \n",
       "66      66  0.711052 2021-08-25 18:41:43.993531 2021-08-25 18:42:46.535504   \n",
       "56      56  0.711122 2021-08-25 18:31:13.871513 2021-08-25 18:32:12.581554   \n",
       "50      50  0.711145 2021-08-25 18:24:30.460951 2021-08-25 18:25:26.744155   \n",
       "33      33  0.711536 2021-08-25 18:04:27.558287 2021-08-25 18:05:47.028061   \n",
       "36      36  0.711612 2021-08-25 18:08:39.867913 2021-08-25 18:10:36.313304   \n",
       "67      67  0.711765 2021-08-25 18:42:46.536315 2021-08-25 18:43:47.180808   \n",
       "23      23  0.711832 2021-08-25 17:49:32.378055 2021-08-25 17:51:01.009332   \n",
       "53      53  0.711987 2021-08-25 18:27:28.716039 2021-08-25 18:28:49.270659   \n",
       "52      52  0.712085 2021-08-25 18:26:25.679082 2021-08-25 18:27:28.715200   \n",
       "18      18  0.712092 2021-08-25 17:42:00.482140 2021-08-25 17:43:35.053938   \n",
       "40      40  0.712877 2021-08-25 18:13:58.067545 2021-08-25 18:15:00.476591   \n",
       "28      28  0.713037 2021-08-25 17:57:41.435847 2021-08-25 17:59:24.347228   \n",
       "31      31  0.713070 2021-08-25 18:01:46.108088 2021-08-25 18:03:19.081938   \n",
       "25      25  0.713386 2021-08-25 17:52:31.104978 2021-08-25 17:54:10.282222   \n",
       "24      24  0.713581 2021-08-25 17:51:01.010371 2021-08-25 17:52:31.104005   \n",
       "39      39  0.713657 2021-08-25 18:12:32.469133 2021-08-25 18:13:58.066593   \n",
       "14      14  0.714151 2021-08-25 17:36:19.902697 2021-08-25 17:37:46.249675   \n",
       "6        6  0.714232 2021-08-25 17:23:22.081870 2021-08-25 17:24:57.788086   \n",
       "17      17  0.714271 2021-08-25 17:40:37.481229 2021-08-25 17:42:00.481341   \n",
       "16      16  0.714632 2021-08-25 17:39:07.416871 2021-08-25 17:40:37.480324   \n",
       "65      65  0.714972 2021-08-25 18:40:42.062408 2021-08-25 18:41:43.992632   \n",
       "57      57  0.715428 2021-08-25 18:32:12.582640 2021-08-25 18:33:12.315306   \n",
       "42      42  0.715568 2021-08-25 18:15:54.566751 2021-08-25 18:16:50.332717   \n",
       "60      60  0.715979 2021-08-25 18:35:27.823271 2021-08-25 18:36:27.485032   \n",
       "3        3  0.716119 2021-08-25 17:17:35.067031 2021-08-25 17:19:55.218210   \n",
       "19      19  0.716175 2021-08-25 17:43:35.054760 2021-08-25 17:45:02.371082   \n",
       "1        1  0.716324 2021-08-25 17:14:06.153348 2021-08-25 17:15:20.301700   \n",
       "4        4  0.716652 2021-08-25 17:19:55.219017 2021-08-25 17:21:20.240540   \n",
       "13      13  0.716766 2021-08-25 17:34:38.921587 2021-08-25 17:36:19.901956   \n",
       "51      51  0.717261 2021-08-25 18:25:26.745032 2021-08-25 18:26:25.678246   \n",
       "41      41  0.717607 2021-08-25 18:15:00.477533 2021-08-25 18:15:54.565933   \n",
       "22      22  0.717651 2021-08-25 17:47:44.205873 2021-08-25 17:49:32.377198   \n",
       "5        5  0.717912 2021-08-25 17:21:20.241248 2021-08-25 17:23:22.081017   \n",
       "37      37  0.718198 2021-08-25 18:10:36.317953 2021-08-25 18:11:32.989556   \n",
       "29      29  0.718527 2021-08-25 17:59:24.348140 2021-08-25 18:00:42.855523   \n",
       "30      30  0.718764 2021-08-25 18:00:42.856320 2021-08-25 18:01:46.105941   \n",
       "26      26  0.718965 2021-08-25 17:54:10.283050 2021-08-25 17:55:46.871615   \n",
       "20      20  0.719255 2021-08-25 17:45:02.372049 2021-08-25 17:46:22.443238   \n",
       "15      15  0.719293 2021-08-25 17:37:46.250681 2021-08-25 17:39:07.415887   \n",
       "27      27  0.719522 2021-08-25 17:55:46.874800 2021-08-25 17:57:41.435035   \n",
       "12      12  0.720194 2021-08-25 17:32:39.569204 2021-08-25 17:34:38.920613   \n",
       "35      35  0.720748 2021-08-25 18:07:23.461541 2021-08-25 18:08:39.866827   \n",
       "64      64  0.721089 2021-08-25 18:39:26.192882 2021-08-25 18:40:42.061688   \n",
       "9        9  0.722377 2021-08-25 17:28:02.830192 2021-08-25 17:29:31.456878   \n",
       "0        0  0.722520 2021-08-25 17:12:54.487311 2021-08-25 17:14:06.152527   \n",
       "10      10  0.722933 2021-08-25 17:29:31.457721 2021-08-25 17:30:49.609970   \n",
       "21      21  0.723618 2021-08-25 17:46:22.444243 2021-08-25 17:47:44.205001   \n",
       "2        2  0.723806 2021-08-25 17:15:20.302637 2021-08-25 17:17:35.066228   \n",
       "8        8  0.728288 2021-08-25 17:26:28.658620 2021-08-25 17:28:02.829495   \n",
       "\n",
       "                 duration  params_bagging_fraction  params_bagging_freq  \\\n",
       "43 0 days 00:01:02.343363                      NaN                  NaN   \n",
       "46 0 days 00:00:58.710710                      NaN                  NaN   \n",
       "45 0 days 00:01:19.888757                      NaN                  NaN   \n",
       "54 0 days 00:01:13.191363                      NaN                  NaN   \n",
       "62 0 days 00:01:02.179438                      NaN                  NaN   \n",
       "44 0 days 00:01:08.846374                      NaN                  NaN   \n",
       "48 0 days 00:01:10.070112                      NaN                  NaN   \n",
       "49 0 days 00:01:00.518894                      NaN                  NaN   \n",
       "32 0 days 00:01:08.474512                 0.408690                  5.0   \n",
       "38 0 days 00:00:59.477553                      NaN                  NaN   \n",
       "61 0 days 00:00:59.074500                      NaN                  NaN   \n",
       "59 0 days 00:00:55.126459                      NaN                  NaN   \n",
       "55 0 days 00:01:11.406895                      NaN                  NaN   \n",
       "11 0 days 00:01:49.957724                      NaN                  NaN   \n",
       "63 0 days 00:00:57.446638                      NaN                  NaN   \n",
       "58 0 days 00:01:20.378699                      NaN                  NaN   \n",
       "47 0 days 00:00:59.738195                      NaN                  NaN   \n",
       "7  0 days 00:01:30.866946                      NaN                  NaN   \n",
       "34 0 days 00:01:36.431756                 0.979813                  5.0   \n",
       "66 0 days 00:01:02.541973                      NaN                  NaN   \n",
       "56 0 days 00:00:58.710041                      NaN                  NaN   \n",
       "50 0 days 00:00:56.283204                      NaN                  NaN   \n",
       "33 0 days 00:01:19.469774                 0.652023                  7.0   \n",
       "36 0 days 00:01:56.445391                 0.994879                  5.0   \n",
       "67 0 days 00:01:00.644493                      NaN                  NaN   \n",
       "23 0 days 00:01:28.631277                      NaN                  NaN   \n",
       "53 0 days 00:01:20.554620                      NaN                  NaN   \n",
       "52 0 days 00:01:03.036118                      NaN                  NaN   \n",
       "18 0 days 00:01:34.571798                      NaN                  NaN   \n",
       "40 0 days 00:01:02.409046                      NaN                  NaN   \n",
       "28 0 days 00:01:42.911381                 0.840767                  4.0   \n",
       "31 0 days 00:01:32.973850                 0.908806                  6.0   \n",
       "25 0 days 00:01:39.177244                      NaN                  NaN   \n",
       "24 0 days 00:01:30.093634                      NaN                  NaN   \n",
       "39 0 days 00:01:25.597460                      NaN                  NaN   \n",
       "14 0 days 00:01:26.346978                      NaN                  NaN   \n",
       "6  0 days 00:01:35.706216                      NaN                  NaN   \n",
       "17 0 days 00:01:23.000112                      NaN                  NaN   \n",
       "16 0 days 00:01:30.063453                      NaN                  NaN   \n",
       "65 0 days 00:01:01.930224                      NaN                  NaN   \n",
       "57 0 days 00:00:59.732666                      NaN                  NaN   \n",
       "42 0 days 00:00:55.765966                      NaN                  NaN   \n",
       "60 0 days 00:00:59.661761                      NaN                  NaN   \n",
       "3  0 days 00:02:20.151179                      NaN                  NaN   \n",
       "19 0 days 00:01:27.316322                      NaN                  NaN   \n",
       "1  0 days 00:01:14.148352                      NaN                  NaN   \n",
       "4  0 days 00:01:25.021523                      NaN                  NaN   \n",
       "13 0 days 00:01:40.980369                      NaN                  NaN   \n",
       "51 0 days 00:00:58.933214                      NaN                  NaN   \n",
       "41 0 days 00:00:54.088400                      NaN                  NaN   \n",
       "22 0 days 00:01:48.171325                      NaN                  NaN   \n",
       "5  0 days 00:02:01.839769                      NaN                  NaN   \n",
       "37 0 days 00:00:56.671603                      NaN                  NaN   \n",
       "29 0 days 00:01:18.507383                 0.679668                  1.0   \n",
       "30 0 days 00:01:03.249621                 0.434772                  3.0   \n",
       "26 0 days 00:01:36.588565                      NaN                  NaN   \n",
       "20 0 days 00:01:20.071189                      NaN                  NaN   \n",
       "15 0 days 00:01:21.165206                      NaN                  NaN   \n",
       "27 0 days 00:01:54.560235                 0.920586                  6.0   \n",
       "12 0 days 00:01:59.351409                      NaN                  NaN   \n",
       "35 0 days 00:01:16.405286                 0.429070                  1.0   \n",
       "64 0 days 00:01:15.868806                      NaN                  NaN   \n",
       "9  0 days 00:01:28.626686                      NaN                  NaN   \n",
       "0  0 days 00:01:11.665216                      NaN                  NaN   \n",
       "10 0 days 00:01:18.152249                      NaN                  NaN   \n",
       "21 0 days 00:01:21.760758                      NaN                  NaN   \n",
       "2  0 days 00:02:14.763591                      NaN                  NaN   \n",
       "8  0 days 00:01:34.170875                      NaN                  NaN   \n",
       "\n",
       "    params_feature_fraction  params_lambda_l1  params_lambda_l2  \\\n",
       "43                      NaN      2.359563e-01      5.422400e-02   \n",
       "46                      NaN      1.834887e-03      1.646967e-04   \n",
       "45                      NaN      3.642911e-08      7.973800e-05   \n",
       "54                      NaN      5.768050e-04      5.534236e-02   \n",
       "62                      NaN      5.711378e-01      6.798656e-03   \n",
       "44                      NaN      2.001941e-06      8.557431e-05   \n",
       "48                      NaN      1.105133e-08      3.858593e-08   \n",
       "49                      NaN      1.078578e-07      1.023588e-03   \n",
       "32                      NaN               NaN               NaN   \n",
       "38                    0.816               NaN               NaN   \n",
       "61                      NaN      3.365064e-05      2.804216e-05   \n",
       "59                      NaN      4.371261e-01      8.137655e-07   \n",
       "55                      NaN      1.442263e-03      1.470337e-02   \n",
       "11                      NaN               NaN               NaN   \n",
       "63                      NaN               NaN               NaN   \n",
       "58                      NaN      3.592574e-05      1.968098e+00   \n",
       "47                      NaN      2.231091e-06      8.691219e-01   \n",
       "7                       NaN               NaN               NaN   \n",
       "34                      NaN               NaN               NaN   \n",
       "66                      NaN               NaN               NaN   \n",
       "56                      NaN      2.368635e-02      7.611364e-07   \n",
       "50                      NaN      3.879536e-01      7.422945e-04   \n",
       "33                      NaN               NaN               NaN   \n",
       "36                      NaN               NaN               NaN   \n",
       "67                      NaN               NaN               NaN   \n",
       "23                      NaN               NaN               NaN   \n",
       "53                      NaN      9.568009e+00      7.191665e+00   \n",
       "52                      NaN      3.647334e-07      1.327121e-01   \n",
       "18                      NaN               NaN               NaN   \n",
       "40                    0.784               NaN               NaN   \n",
       "28                      NaN               NaN               NaN   \n",
       "31                      NaN               NaN               NaN   \n",
       "25                      NaN               NaN               NaN   \n",
       "24                      NaN               NaN               NaN   \n",
       "39                    0.848               NaN               NaN   \n",
       "14                      NaN               NaN               NaN   \n",
       "6                     0.800               NaN               NaN   \n",
       "17                      NaN               NaN               NaN   \n",
       "16                      NaN               NaN               NaN   \n",
       "65                      NaN               NaN               NaN   \n",
       "57                      NaN      6.982110e+00      3.910097e-03   \n",
       "42                    0.752               NaN               NaN   \n",
       "60                      NaN      5.197588e-03      1.859895e-01   \n",
       "3                     1.000               NaN               NaN   \n",
       "19                      NaN               NaN               NaN   \n",
       "1                     0.900               NaN               NaN   \n",
       "4                     0.700               NaN               NaN   \n",
       "13                      NaN               NaN               NaN   \n",
       "51                      NaN      4.407804e-02      7.568133e-06   \n",
       "41                    0.720               NaN               NaN   \n",
       "22                      NaN               NaN               NaN   \n",
       "5                     0.400               NaN               NaN   \n",
       "37                    0.880               NaN               NaN   \n",
       "29                      NaN               NaN               NaN   \n",
       "30                      NaN               NaN               NaN   \n",
       "26                      NaN               NaN               NaN   \n",
       "20                      NaN               NaN               NaN   \n",
       "15                      NaN               NaN               NaN   \n",
       "27                      NaN               NaN               NaN   \n",
       "12                      NaN               NaN               NaN   \n",
       "35                      NaN               NaN               NaN   \n",
       "64                      NaN               NaN               NaN   \n",
       "9                       NaN               NaN               NaN   \n",
       "0                     0.600               NaN               NaN   \n",
       "10                      NaN               NaN               NaN   \n",
       "21                      NaN               NaN               NaN   \n",
       "2                     0.500               NaN               NaN   \n",
       "8                       NaN               NaN               NaN   \n",
       "\n",
       "    params_min_child_samples  params_num_leaves  system_attrs_grid_id  \\\n",
       "43                       NaN                NaN                   NaN   \n",
       "46                       NaN                NaN                   NaN   \n",
       "45                       NaN                NaN                   NaN   \n",
       "54                       NaN                NaN                   NaN   \n",
       "62                       NaN                NaN                   NaN   \n",
       "44                       NaN                NaN                   NaN   \n",
       "48                       NaN                NaN                   NaN   \n",
       "49                       NaN                NaN                   NaN   \n",
       "32                       NaN                NaN                   NaN   \n",
       "38                       NaN                NaN                   3.0   \n",
       "61                       NaN                NaN                   NaN   \n",
       "59                       NaN                NaN                   NaN   \n",
       "55                       NaN                NaN                   NaN   \n",
       "11                       NaN              128.0                   NaN   \n",
       "63                      50.0                NaN                   3.0   \n",
       "58                       NaN                NaN                   NaN   \n",
       "47                       NaN                NaN                   NaN   \n",
       "7                        NaN               84.0                   NaN   \n",
       "34                       NaN                NaN                   NaN   \n",
       "66                       5.0                NaN                   0.0   \n",
       "56                       NaN                NaN                   NaN   \n",
       "50                       NaN                NaN                   NaN   \n",
       "33                       NaN                NaN                   NaN   \n",
       "36                       NaN                NaN                   NaN   \n",
       "67                      25.0                NaN                   2.0   \n",
       "23                       NaN              117.0                   NaN   \n",
       "53                       NaN                NaN                   NaN   \n",
       "52                       NaN                NaN                   NaN   \n",
       "18                       NaN               87.0                   NaN   \n",
       "40                       NaN                NaN                   2.0   \n",
       "28                       NaN                NaN                   NaN   \n",
       "31                       NaN                NaN                   NaN   \n",
       "25                       NaN               95.0                   NaN   \n",
       "24                       NaN              174.0                   NaN   \n",
       "39                       NaN                NaN                   4.0   \n",
       "14                       NaN              255.0                   NaN   \n",
       "6                        NaN                NaN                   4.0   \n",
       "17                       NaN              108.0                   NaN   \n",
       "16                       NaN              249.0                   NaN   \n",
       "65                      10.0                NaN                   1.0   \n",
       "57                       NaN                NaN                   NaN   \n",
       "42                       NaN                NaN                   1.0   \n",
       "60                       NaN                NaN                   NaN   \n",
       "3                        NaN                NaN                   6.0   \n",
       "19                       NaN               69.0                   NaN   \n",
       "1                        NaN                NaN                   5.0   \n",
       "4                        NaN                NaN                   3.0   \n",
       "13                       NaN              231.0                   NaN   \n",
       "51                       NaN                NaN                   NaN   \n",
       "41                       NaN                NaN                   0.0   \n",
       "22                       NaN               71.0                   NaN   \n",
       "5                        NaN                NaN                   0.0   \n",
       "37                       NaN                NaN                   5.0   \n",
       "29                       NaN                NaN                   NaN   \n",
       "30                       NaN                NaN                   NaN   \n",
       "26                       NaN               52.0                   NaN   \n",
       "20                       NaN              148.0                   NaN   \n",
       "15                       NaN              145.0                   NaN   \n",
       "27                       NaN                NaN                   NaN   \n",
       "12                       NaN               22.0                   NaN   \n",
       "35                       NaN                NaN                   NaN   \n",
       "64                     100.0                NaN                   4.0   \n",
       "9                        NaN              182.0                   NaN   \n",
       "0                        NaN                NaN                   2.0   \n",
       "10                       NaN               40.0                   NaN   \n",
       "21                       NaN              180.0                   NaN   \n",
       "2                        NaN                NaN                   1.0   \n",
       "8                        NaN               10.0                   NaN   \n",
       "\n",
       "    system_attrs_lightgbm_tuner:average_iteration_time  \\\n",
       "43                                           0.741982    \n",
       "46                                           0.850741    \n",
       "45                                           0.583057    \n",
       "54                                           0.665252    \n",
       "62                                           0.777018    \n",
       "44                                           0.748137    \n",
       "48                                           0.761501    \n",
       "49                                           0.828889    \n",
       "32                                           0.744086    \n",
       "38                                           0.837467    \n",
       "61                                           0.855889    \n",
       "59                                           0.984089    \n",
       "55                                           0.610200    \n",
       "11                                           0.635539    \n",
       "63                                           0.990301    \n",
       "58                                           0.550432    \n",
       "47                                           1.029774    \n",
       "7                                            0.658395    \n",
       "34                                           0.973903    \n",
       "66                                           0.762576    \n",
       "56                                           0.962160    \n",
       "50                                           0.839806    \n",
       "33                                           0.764105    \n",
       "36                                           0.786774    \n",
       "67                                           0.878870    \n",
       "23                                           0.720495    \n",
       "53                                           0.567192    \n",
       "52                                           0.851571    \n",
       "18                                           0.587324    \n",
       "40                                           0.770432    \n",
       "28                                           0.850437    \n",
       "31                                           0.958413    \n",
       "25                                           0.688645    \n",
       "24                                           1.047458    \n",
       "39                                           0.559365    \n",
       "14                                           1.136000    \n",
       "6                                            0.429128    \n",
       "17                                           0.797963    \n",
       "16                                           0.891657    \n",
       "65                                           0.884540    \n",
       "57                                           0.841097    \n",
       "42                                           0.914150    \n",
       "60                                           0.795280    \n",
       "3                                            0.491705    \n",
       "19                                           0.656429    \n",
       "1                                            0.617863    \n",
       "4                                            0.534659    \n",
       "13                                           0.961633    \n",
       "51                                           0.998553    \n",
       "41                                           0.948876    \n",
       "22                                           0.540790    \n",
       "5                                            0.654963    \n",
       "37                                           0.833013    \n",
       "29                                           0.844130    \n",
       "30                                           0.916619    \n",
       "26                                           0.551856    \n",
       "20                                           1.111886    \n",
       "15                                           0.977786    \n",
       "27                                           0.753506    \n",
       "12                                           0.387475    \n",
       "35                                           0.992108    \n",
       "64                                           0.683397    \n",
       "9                                            0.877365    \n",
       "0                                            0.542839    \n",
       "10                                           0.591980    \n",
       "21                                           1.089989    \n",
       "2                                            0.774488    \n",
       "8                                            0.376631    \n",
       "\n",
       "    system_attrs_lightgbm_tuner:elapsed_secs  \\\n",
       "43                                 62.326452   \n",
       "46                                 58.701117   \n",
       "45                                 79.878837   \n",
       "54                                 73.177722   \n",
       "62                                 62.161449   \n",
       "44                                 68.828604   \n",
       "48                                 70.058116   \n",
       "49                                 60.508918   \n",
       "32                                 68.455954   \n",
       "38                                 59.460146   \n",
       "61                                 59.056315   \n",
       "59                                 55.108969   \n",
       "55                                 71.393346   \n",
       "11                                109.948234   \n",
       "63                                 57.437471   \n",
       "58                                 80.363129   \n",
       "47                                 59.726886   \n",
       "7                                  90.858442   \n",
       "34                                 96.416374   \n",
       "66                                 62.531250   \n",
       "56                                 58.691790   \n",
       "50                                 56.267018   \n",
       "33                                 79.466893   \n",
       "36                                116.442538   \n",
       "67                                 60.642050   \n",
       "23                                 88.620888   \n",
       "53                                 80.541294   \n",
       "52                                 63.016257   \n",
       "18                                 94.559108   \n",
       "40                                 62.404973   \n",
       "28                                102.902828   \n",
       "31                                 92.966079   \n",
       "25                                 99.164855   \n",
       "24                                 90.081375   \n",
       "39                                 85.582839   \n",
       "14                                 86.335987   \n",
       "6                                  95.695437   \n",
       "17                                 82.988151   \n",
       "16                                 90.057328   \n",
       "65                                 61.917783   \n",
       "57                                 59.717869   \n",
       "42                                 55.763153   \n",
       "60                                 59.646016   \n",
       "3                                 140.135919   \n",
       "19                                 87.305004   \n",
       "1                                  74.143594   \n",
       "4                                  85.010712   \n",
       "13                                100.971512   \n",
       "51                                 58.914634   \n",
       "41                                 54.085920   \n",
       "22                                108.157914   \n",
       "5                                 121.823104   \n",
       "37                                 56.644893   \n",
       "29                                 78.504086   \n",
       "30                                 63.246688   \n",
       "26                                 96.574873   \n",
       "20                                 80.055824   \n",
       "15                                 81.156205   \n",
       "27                                114.532971   \n",
       "12                                119.342433   \n",
       "35                                 76.392290   \n",
       "64                                 75.857064   \n",
       "9                                  88.613841   \n",
       "0                                  71.654730   \n",
       "10                                 78.141294   \n",
       "21                                 81.749196   \n",
       "2                                 134.760955   \n",
       "8                                  94.157679   \n",
       "\n",
       "              system_attrs_lightgbm_tuner:lgbm_params  \\\n",
       "43  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "46  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "45  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "54  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "62  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "44  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "48  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "49  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "32  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "38  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "61  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "59  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "55  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "11  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "63  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "58  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "47  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "7   {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "34  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "66  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "56  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "50  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "33  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "36  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "67  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "23  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "53  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "52  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "18  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "40  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "28  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "31  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "25  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "24  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "39  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "14  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "6   {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "17  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "16  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "65  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "57  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "42  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "60  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "3   {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "19  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "1   {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "4   {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "13  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "51  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "41  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "22  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "5   {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "37  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "29  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "30  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "26  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "20  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "15  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "27  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "12  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "35  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "64  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "9   {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "0   {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "10  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "21  {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "2   {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "8   {\"objective\": \"mse\", \"metric\": \"rmse\", \"verbos...   \n",
       "\n",
       "   system_attrs_lightgbm_tuner:step_name  \\\n",
       "43                regularization_factors   \n",
       "46                regularization_factors   \n",
       "45                regularization_factors   \n",
       "54                regularization_factors   \n",
       "62                regularization_factors   \n",
       "44                regularization_factors   \n",
       "48                regularization_factors   \n",
       "49                regularization_factors   \n",
       "32                               bagging   \n",
       "38               feature_fraction_stage2   \n",
       "61                regularization_factors   \n",
       "59                regularization_factors   \n",
       "55                regularization_factors   \n",
       "11                            num_leaves   \n",
       "63                      min_data_in_leaf   \n",
       "58                regularization_factors   \n",
       "47                regularization_factors   \n",
       "7                             num_leaves   \n",
       "34                               bagging   \n",
       "66                      min_data_in_leaf   \n",
       "56                regularization_factors   \n",
       "50                regularization_factors   \n",
       "33                               bagging   \n",
       "36                               bagging   \n",
       "67                      min_data_in_leaf   \n",
       "23                            num_leaves   \n",
       "53                regularization_factors   \n",
       "52                regularization_factors   \n",
       "18                            num_leaves   \n",
       "40               feature_fraction_stage2   \n",
       "28                               bagging   \n",
       "31                               bagging   \n",
       "25                            num_leaves   \n",
       "24                            num_leaves   \n",
       "39               feature_fraction_stage2   \n",
       "14                            num_leaves   \n",
       "6                       feature_fraction   \n",
       "17                            num_leaves   \n",
       "16                            num_leaves   \n",
       "65                      min_data_in_leaf   \n",
       "57                regularization_factors   \n",
       "42               feature_fraction_stage2   \n",
       "60                regularization_factors   \n",
       "3                       feature_fraction   \n",
       "19                            num_leaves   \n",
       "1                       feature_fraction   \n",
       "4                       feature_fraction   \n",
       "13                            num_leaves   \n",
       "51                regularization_factors   \n",
       "41               feature_fraction_stage2   \n",
       "22                            num_leaves   \n",
       "5                       feature_fraction   \n",
       "37               feature_fraction_stage2   \n",
       "29                               bagging   \n",
       "30                               bagging   \n",
       "26                            num_leaves   \n",
       "20                            num_leaves   \n",
       "15                            num_leaves   \n",
       "27                               bagging   \n",
       "12                            num_leaves   \n",
       "35                               bagging   \n",
       "64                      min_data_in_leaf   \n",
       "9                             num_leaves   \n",
       "0                       feature_fraction   \n",
       "10                            num_leaves   \n",
       "21                            num_leaves   \n",
       "2                       feature_fraction   \n",
       "8                             num_leaves   \n",
       "\n",
       "                            system_attrs_search_space     state  \n",
       "43                                                NaN  COMPLETE  \n",
       "46                                                NaN  COMPLETE  \n",
       "45                                                NaN  COMPLETE  \n",
       "54                                                NaN  COMPLETE  \n",
       "62                                                NaN  COMPLETE  \n",
       "44                                                NaN  COMPLETE  \n",
       "48                                                NaN  COMPLETE  \n",
       "49                                                NaN  COMPLETE  \n",
       "32                                                NaN  COMPLETE  \n",
       "38  {'feature_fraction': [0.7200000000000001, 0.75...  COMPLETE  \n",
       "61                                                NaN  COMPLETE  \n",
       "59                                                NaN  COMPLETE  \n",
       "55                                                NaN  COMPLETE  \n",
       "11                                                NaN  COMPLETE  \n",
       "63        {'min_child_samples': [5, 10, 25, 50, 100]}  COMPLETE  \n",
       "58                                                NaN  COMPLETE  \n",
       "47                                                NaN  COMPLETE  \n",
       "7                                                 NaN  COMPLETE  \n",
       "34                                                NaN  COMPLETE  \n",
       "66        {'min_child_samples': [5, 10, 25, 50, 100]}  COMPLETE  \n",
       "56                                                NaN  COMPLETE  \n",
       "50                                                NaN  COMPLETE  \n",
       "33                                                NaN  COMPLETE  \n",
       "36                                                NaN  COMPLETE  \n",
       "67        {'min_child_samples': [5, 10, 25, 50, 100]}  COMPLETE  \n",
       "23                                                NaN  COMPLETE  \n",
       "53                                                NaN  COMPLETE  \n",
       "52                                                NaN  COMPLETE  \n",
       "18                                                NaN  COMPLETE  \n",
       "40  {'feature_fraction': [0.7200000000000001, 0.75...  COMPLETE  \n",
       "28                                                NaN  COMPLETE  \n",
       "31                                                NaN  COMPLETE  \n",
       "25                                                NaN  COMPLETE  \n",
       "24                                                NaN  COMPLETE  \n",
       "39  {'feature_fraction': [0.7200000000000001, 0.75...  COMPLETE  \n",
       "14                                                NaN  COMPLETE  \n",
       "6   {'feature_fraction': [0.4, 0.5, 0.6, 0.7, 0.8,...  COMPLETE  \n",
       "17                                                NaN  COMPLETE  \n",
       "16                                                NaN  COMPLETE  \n",
       "65        {'min_child_samples': [5, 10, 25, 50, 100]}  COMPLETE  \n",
       "57                                                NaN  COMPLETE  \n",
       "42  {'feature_fraction': [0.7200000000000001, 0.75...  COMPLETE  \n",
       "60                                                NaN  COMPLETE  \n",
       "3   {'feature_fraction': [0.4, 0.5, 0.6, 0.7, 0.8,...  COMPLETE  \n",
       "19                                                NaN  COMPLETE  \n",
       "1   {'feature_fraction': [0.4, 0.5, 0.6, 0.7, 0.8,...  COMPLETE  \n",
       "4   {'feature_fraction': [0.4, 0.5, 0.6, 0.7, 0.8,...  COMPLETE  \n",
       "13                                                NaN  COMPLETE  \n",
       "51                                                NaN  COMPLETE  \n",
       "41  {'feature_fraction': [0.7200000000000001, 0.75...  COMPLETE  \n",
       "22                                                NaN  COMPLETE  \n",
       "5   {'feature_fraction': [0.4, 0.5, 0.6, 0.7, 0.8,...  COMPLETE  \n",
       "37  {'feature_fraction': [0.7200000000000001, 0.75...  COMPLETE  \n",
       "29                                                NaN  COMPLETE  \n",
       "30                                                NaN  COMPLETE  \n",
       "26                                                NaN  COMPLETE  \n",
       "20                                                NaN  COMPLETE  \n",
       "15                                                NaN  COMPLETE  \n",
       "27                                                NaN  COMPLETE  \n",
       "12                                                NaN  COMPLETE  \n",
       "35                                                NaN  COMPLETE  \n",
       "64        {'min_child_samples': [5, 10, 25, 50, 100]}  COMPLETE  \n",
       "9                                                 NaN  COMPLETE  \n",
       "0   {'feature_fraction': [0.4, 0.5, 0.6, 0.7, 0.8,...  COMPLETE  \n",
       "10                                                NaN  COMPLETE  \n",
       "21                                                NaN  COMPLETE  \n",
       "2   {'feature_fraction': [0.4, 0.5, 0.6, 0.7, 0.8,...  COMPLETE  \n",
       "8                                                 NaN  COMPLETE  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study_df = study.trials_dataframe()\n",
    "study_df.sort_values('value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68, 19)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/.local/lib/python3.8/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/alex/.local/lib/python3.8/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.021463 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 20956\n",
      "[LightGBM] [Info] Number of data points in the train set: 8098633, number of used features: 151\n",
      "[LightGBM] [Info] Start training from score 0.308742\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's rmse: 0.756968\n",
      "[100]\ttraining's rmse: 0.721302\n",
      "[150]\ttraining's rmse: 0.703159\n",
      "[200]\ttraining's rmse: 0.689526\n",
      "[250]\ttraining's rmse: 0.678681\n",
      "[300]\ttraining's rmse: 0.668148\n",
      "[350]\ttraining's rmse: 0.660531\n",
      "[400]\ttraining's rmse: 0.653051\n",
      "[450]\ttraining's rmse: 0.646402\n",
      "[500]\ttraining's rmse: 0.641079\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's rmse: 0.641079\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "params = {\n",
    "     'objective': 'mse',\n",
    "     'metric': 'rmse',\n",
    "     'verbose': 1,\n",
    "     'feature_pre_filter': False,\n",
    "     'lambda_l1': 1.2271425307979717e-06,\n",
    "     'lambda_l2': 0.011281292748567182,\n",
    "     'num_leaves': 67,\n",
    "     'feature_fraction': 0.9840000000000001,\n",
    "     'bagging_fraction': 1.0,\n",
    "     'bagging_freq': 0,\n",
    "     'min_child_samples': 20,\n",
    "     'num_iterations': 500,\n",
    "     'early_stopping_round': 50,\n",
    "     'categorical_column': [7, 12]\n",
    "    }\n",
    "cat_feats = ['item_category_id', 'month']#, 'season']\n",
    "\n",
    "last_block = 34\n",
    "dates = matrix['date_block_num']\n",
    "\n",
    "# drop target and some features that lead to overfitting\n",
    "cols_to_drop = ['item_cnt_month', 'new_item', 'shop_id', 'item_id']\n",
    "\n",
    "# split dataset on train and test sets for model training\n",
    "X_train = matrix.loc[dates <  last_block].drop(cols_to_drop, axis=1)\n",
    "X_val = matrix.loc[dates ==  last_block].drop(cols_to_drop, axis=1)\n",
    "X_test = matrix.loc[dates ==  34].drop(cols_to_drop, axis=1)\n",
    "\n",
    "y_train = matrix.loc[dates <  last_block, 'item_cnt_month']\n",
    "y_val = matrix.loc[dates ==  last_block, 'item_cnt_month']\n",
    "\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_eval = lgb.Dataset(X_val, y_val, reference=lgb_train)\n",
    "\n",
    "evals_result = dict()\n",
    "\n",
    "gbm = lgb.train(\n",
    "        params, \n",
    "        lgb_train,\n",
    "#         valid_sets=(lgb_train, lgb_eval), \n",
    "        valid_sets=lgb_train,\n",
    "#         categorical_feature = cat_feats,\n",
    "        verbose_eval=50, \n",
    "        evals_result = evals_result,\n",
    "        early_stopping_rounds = 50)\n",
    "\n",
    "test_pred_lgb = gbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previous RMSE on the train set except validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training until validation scores don't improve for 30 rounds\n",
    "# [50]\ttraining's rmse: 0.968815\ttraining's l2: 0.938602\tvalid_1's rmse: 0.873901\tvalid_1's l2: 0.763703\n",
    "# [100]\ttraining's rmse: 0.829555\ttraining's l2: 0.688162\tvalid_1's rmse: 0.780026\tvalid_1's l2: 0.608441\n",
    "# [150]\ttraining's rmse: 0.757286\ttraining's l2: 0.573481\tvalid_1's rmse: 0.740559\tvalid_1's l2: 0.548427\n",
    "# [200]\ttraining's rmse: 0.717651\ttraining's l2: 0.515023\tvalid_1's rmse: 0.722095\tvalid_1's l2: 0.521421\n",
    "# [250]\ttraining's rmse: 0.693096\ttraining's l2: 0.480382\tvalid_1's rmse: 0.715246\tvalid_1's l2: 0.511577\n",
    "# [300]\ttraining's rmse: 0.675777\ttraining's l2: 0.456675\tvalid_1's rmse: 0.711053\tvalid_1's l2: 0.505596\n",
    "# [350]\ttraining's rmse: 0.662477\ttraining's l2: 0.438876\tvalid_1's rmse: 0.709262\tvalid_1's l2: 0.503052\n",
    "# [400]\ttraining's rmse: 0.651249\ttraining's l2: 0.424126\tvalid_1's rmse: 0.708145\tvalid_1's l2: 0.50147\n",
    "# [450]\ttraining's rmse: 0.641991\ttraining's l2: 0.412152\tvalid_1's rmse: 0.707486\tvalid_1's l2: 0.500537\n",
    "# [500]\ttraining's rmse: 0.634088\ttraining's l2: 0.402068\tvalid_1's rmse: 0.706936\tvalid_1's l2: 0.499758\n",
    "# [550]\ttraining's rmse: 0.626927\ttraining's l2: 0.393038\tvalid_1's rmse: 0.706606\tvalid_1's l2: 0.499292\n",
    "# [600]\ttraining's rmse: 0.620879\ttraining's l2: 0.385491\tvalid_1's rmse: 0.706248\tvalid_1's l2: 0.498786\n",
    "# [650]\ttraining's rmse: 0.615213\ttraining's l2: 0.378488\tvalid_1's rmse: 0.706163\tvalid_1's l2: 0.498666\n",
    "# Early stopping, best iteration is:\n",
    "# [630]\ttraining's rmse: 0.617487\ttraining's l2: 0.38129\tvalid_1's rmse: 0.706027\tvalid_1's l2: 0.498474\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previous RMSE on the full train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training until validation scores don't improve for 30 rounds\n",
    "# [50]\ttraining's rmse: 0.96647\ttraining's l2: 0.934064\n",
    "# [100]\ttraining's rmse: 0.827901\ttraining's l2: 0.68542\n",
    "# [150]\ttraining's rmse: 0.756018\ttraining's l2: 0.571563\n",
    "# [200]\ttraining's rmse: 0.716688\ttraining's l2: 0.513642\n",
    "# [250]\ttraining's rmse: 0.692276\ttraining's l2: 0.479246\n",
    "# [300]\ttraining's rmse: 0.675353\ttraining's l2: 0.456102\n",
    "# [350]\ttraining's rmse: 0.66207\ttraining's l2: 0.438337\n",
    "# [400]\ttraining's rmse: 0.650908\ttraining's l2: 0.423681\n",
    "# [450]\ttraining's rmse: 0.641561\ttraining's l2: 0.4116\n",
    "# [500]\ttraining's rmse: 0.633598\ttraining's l2: 0.401446\n",
    "# [550]\ttraining's rmse: 0.626378\ttraining's l2: 0.392349\n",
    "# [600]\ttraining's rmse: 0.620459\ttraining's l2: 0.38497\n",
    "# [650]\ttraining's rmse: 0.614824\ttraining's l2: 0.378008\n",
    "# [700]\ttraining's rmse: 0.609965\ttraining's l2: 0.372057\n",
    "# [750]\ttraining's rmse: 0.605311\ttraining's l2: 0.366401\n",
    "# [800]\ttraining's rmse: 0.600958\ttraining's l2: 0.361151\n",
    "# [850]\ttraining's rmse: 0.597002\ttraining's l2: 0.356412\n",
    "# [900]\ttraining's rmse: 0.593272\ttraining's l2: 0.351971\n",
    "# [950]\ttraining's rmse: 0.58962\ttraining's l2: 0.347652\n",
    "# [1000]\ttraining's rmse: 0.586284\ttraining's l2: 0.343729\n",
    "# Did not meet early stopping. Best iteration is:\n",
    "# [1000]\ttraining's rmse: 0.586284\ttraining's l2: 0.343729\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the feature importances ranked by error reduction on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 3.892104,
     "end_time": "2021-04-28T19:37:25.679539",
     "exception": false,
     "start_time": "2021-04-28T19:37:21.787435",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "lgb.plot_importance(booster, figsize=(10,50), height=0.7, importance_type=\"gain\", max_num_features=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>item_cnt_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.898209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.069530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.055448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.636663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.219784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.581302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.517342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.173869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.742169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.440061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  item_cnt_month\n",
       "0   0        0.898209\n",
       "1   1        2.069530\n",
       "2   2        1.055448\n",
       "3   3        0.636663\n",
       "4   4        1.219784\n",
       "5   5        0.581302\n",
       "6   6        0.517342\n",
       "7   7        0.173869\n",
       "8   8        0.742169\n",
       "9   9        0.440061"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "submission = pd.read_csv(\"sample_submission.csv.zip\")\n",
    "submission['item_cnt_month'] = test_pred_lgb\n",
    "submission.item_cnt_month.clip(0, 20, inplace=True)\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "_ = joblib.dump(booster, \"trained_lgbooster.pkl\")\n",
    "print(\"Saved single booster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Futher ideas\n",
    "\n",
    "- increase number of training rounds\n",
    "- fill NaNs with zeros\n",
    "\n",
    "- optimize with Optuna\n",
    "\n",
    "- use VotingRegressor\n",
    "- use LAMA\n",
    "- you can also blend your submission with submissions from other kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple ensembling with VotingRegressor  \n",
    "\n",
    "Here we make a simple ensembling predictor with the scikit-learn [VotingRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingRegressor.html) predictor. This wraps a list of predictors and outputs a linear combination of their predictions. In principle any scikit-learn compatible regression model can be used, but here we just use LightGBM models, as no other model types were efficient enough to run in a Kaggle notebook without memory allocation errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and split the data for fitting. For the ensemble predictor the LightGBM models are fit on all the training data with a pre-set number of estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 9.884487,
     "end_time": "2021-04-28T19:16:59.734499",
     "exception": false,
     "start_time": "2021-04-28T19:16:49.850012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "matrix = pd.read_pickle(\"checkpoint_final.pkl\")\n",
    "# Downcast the float columns to reduce RAM usage\n",
    "floatcols = [c for c in matrix.columns if matrix[c].dtype==\"float32\"]\n",
    "matrix[floatcols] = matrix[floatcols].astype(\"float16\")\n",
    "matrix['item_cnt_month'] = matrix['item_cnt_month'].clip(0,20)\n",
    "keep_from_month = 2  # The first couple of months are dropped because of distortions to their features (e.g. wrong item age)\n",
    "test_month = 34\n",
    "dropcols = [\n",
    "    \"shop_id\",\n",
    "    \"item_id\",\n",
    "    \"new_item\",\n",
    "]  # The features are dropped to reduce overfitting\n",
    "categoricals = [\n",
    "    \"item_category_id\",\n",
    "    \"month\",\n",
    "]\n",
    "matrix[categoricals] = matrix[categoricals].astype(\"category\") \n",
    "test = matrix.drop(columns=dropcols).loc[matrix.date_block_num == test_month, :]\n",
    "train = matrix.drop(columns=dropcols).loc[matrix.date_block_num < test_month, :]\n",
    "train = train[train.date_block_num >= keep_from_month]\n",
    "X_train = train.drop(columns=\"item_cnt_month\")\n",
    "y_train = train.item_cnt_month\n",
    "X_test = test.drop(columns=\"item_cnt_month\")\n",
    "y_test = test.item_cnt_month\n",
    "del(matrix, test, train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different parameters are used for each of 5 LightGBM models used in the ensemble. These parameters were the highest scoring parameters found by Optuna when optimizing on the validation date block 33."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = [\n",
    "    {\n",
    "        \"num_leaves\": 966,\n",
    "        \"cat_smooth\": 45.01680827234465,\n",
    "        \"min_child_samples\": 27,\n",
    "        \"min_child_weight\": 0.021144950289224463,\n",
    "        \"max_bin\": 214,\n",
    "        \"n_estimators\": 500,\n",
    "        \"subsample_for_bin\": 300000,\n",
    "        \"learning_rate\": 0.01,\n",
    "        \"force_col_wise\": True\n",
    "    },\n",
    "    {\n",
    "        \"num_leaves\": 940,\n",
    "        \"cat_smooth\": 43.418286701105615,\n",
    "        \"min_child_samples\": 29,\n",
    "        \"min_child_weight\": 0.003944267312494195,\n",
    "        \"max_bin\": 133,\n",
    "        \"n_estimators\": 572,\n",
    "        \"subsample_for_bin\": 300000,\n",
    "        \"learning_rate\": 0.01,\n",
    "        \"force_col_wise\": True\n",
    "    },\n",
    "    {\n",
    "        \"num_leaves\": 971,\n",
    "        \"cat_smooth\": 40.103611531065525,\n",
    "        \"min_child_samples\": 30,\n",
    "        \"min_child_weight\": 0.03951287458923346,\n",
    "        \"max_bin\": 212,\n",
    "        \"n_estimators\": 828,\n",
    "        \"subsample_for_bin\": 300000,\n",
    "        \"learning_rate\": 0.01,\n",
    "        \"force_col_wise\": True\n",
    "    },\n",
    "    {\n",
    "        \"num_leaves\": 965,\n",
    "        \"cat_smooth\": 40.05144976454027,\n",
    "        \"min_child_samples\": 27,\n",
    "        \"min_child_weight\": 0.029220951478909872,\n",
    "        \"max_bin\": 211,\n",
    "        \"n_estimators\": 870,\n",
    "        \"subsample_for_bin\": 300000,\n",
    "        \"learning_rate\": 0.01,\n",
    "        \"force_col_wise\": True\n",
    "    },\n",
    "    {\n",
    "        \"num_leaves\": 961,\n",
    "        \"cat_smooth\": 40.013529776221134,\n",
    "        \"min_child_samples\": 29,\n",
    "        \"min_child_weight\": 0.026526521644599493,\n",
    "        \"max_bin\": 210,\n",
    "        \"n_estimators\": 897,\n",
    "        \"subsample_for_bin\": 300000,\n",
    "        \"learning_rate\": 0.01,\n",
    "        \"force_col_wise\": True\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and fit the VotingRegressor ensemble on the training data. This takes a long time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "regressors = []\n",
    "for i, params in enumerate(best_params):\n",
    "    booster = LGBMRegressor(**params)\n",
    "    regressors.append((f\"lgbr_{i}\", booster))\n",
    "vr = VotingRegressor(regressors, verbose=True)\n",
    "print(\"Fitting voting regressor\")\n",
    "vr = vr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Serialize the trained regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "_ = joblib.dump(vr, \"trained_votingregressor.pkl\")\n",
    "print(\"Voting regressor trained and saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.111863,
     "end_time": "2021-04-28T19:37:25.904072",
     "exception": false,
     "start_time": "2021-04-28T19:37:25.792209",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Create the test submission  \n",
    "Split the test items from the data matrix and use the trained voting regressor to predict the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "booster = joblib.load(\"trained_votingregressor.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 50.515225,
     "end_time": "2021-04-28T19:38:16.529825",
     "exception": false,
     "start_time": "2021-04-28T19:37:26.0146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "matrix = pd.read_pickle(\"checkpoint_final.pkl\")\n",
    "keep_from_month = 2\n",
    "test_month = 34\n",
    "dropcols = [\n",
    "    \"shop_id\",\n",
    "    \"item_id\",\n",
    "    \"new_item\",\n",
    "]  # The features are dropped to reduce overfitting\n",
    "categoricals = [\n",
    "    \"item_category_id\",\n",
    "    \"month\",\n",
    "]\n",
    "matrix[categoricals] = matrix[categoricals].astype(\"category\")\n",
    "test = matrix.loc[matrix.date_block_num == test_month, :]\n",
    "X_test = test.drop(columns=\"item_cnt_month\")\n",
    "y_test = test.item_cnt_month\n",
    "del matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 9.884487,
     "end_time": "2021-04-28T19:16:59.734499",
     "exception": false,
     "start_time": "2021-04-28T19:16:49.850012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_test[\"item_cnt_month\"] = booster.predict(X_test.drop(columns=dropcols)).clip(0, 20)\n",
    "# Merge the predictions with the provided template\n",
    "test_orig = pd.read_csv(\"../input/competitive-data-science-predict-future-sales/test.csv\")\n",
    "test = test_orig.merge(\n",
    "    X_test[[\"shop_id\", \"item_id\", \"item_cnt_month\"]],\n",
    "    on=[\"shop_id\", \"item_id\"],\n",
    "    how=\"inner\",\n",
    "    copy=True,\n",
    ")\n",
    "# Verify that the indices of the submission match the original\n",
    "assert test_orig.equals(test[[\"ID\", \"shop_id\", \"item_id\"]])\n",
    "test[[\"ID\", \"item_cnt_month\"]].to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.122639,
     "end_time": "2021-04-28T19:38:27.697031",
     "exception": false,
     "start_time": "2021-04-28T19:38:27.574392",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from os import remove\n",
    "# remove(\"checkpoint_final.pkl\")\n",
    "# remove(\"matrixcheckpoint.pkl\")\n",
    "# print(\"Finished everything!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
